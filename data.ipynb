{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b14da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Crime Classification Pipeline...\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Starting Crime Classification Pipeline...\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fc8c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Loading CSV files from: C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\n",
      "📄 Found 57 CSV files:\n",
      "   - 01_District_wise_crimes_committed_IPC_2001_2012.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2013.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2014.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2001_2012.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2013.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2014.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2001_2012.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2013.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2014.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2001_2012.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv\n",
      "   - 08_01_Juvenile_apprehended_state_IPC.csv\n",
      "   - 08_02_Juvenile_apprehended_state_SLL.csv\n",
      "   - 09_Juveniles_arrested_and_their_disposal.csv\n",
      "   - 11_Property_stolen_and_recovered_nature_of_property.csv\n",
      "   - 12_Police_strength_actual_and_sanctioned.csv\n",
      "   - 13_Police_killed_or_injured_on_duty.csv\n",
      "   - 14_Age_profile_of_police_personnel_killed_on_duty.csv\n",
      "   - 15_Police_natural_death_and_suicide.csv\n",
      "   - 16_Casualties_under_police_firing_and_lathi_charge.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2014.csv\n",
      "   - 18_01_Juveniles_arrested_Education.csv\n",
      "   - 18_02_Juveniles_arrested_Economic_setup.csv\n",
      "   - 18_03_Juveniles_arrested_Family_background.csv\n",
      "   - 18_04_Juveniles_arrested_Recidivism.csv\n",
      "   - 19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv\n",
      "   - 21_Offenders_known_to_the_victim.csv\n",
      "   - 22_Persons_arrested_under_recidivism.csv\n",
      "   - 23_Anti_corruprion_cases.csv\n",
      "   - 24_Anti_corruption_arrests.csv\n",
      "   - 27_Nature_of_complaints_received_by_police.csv\n",
      "   - 34_Use_of_fire_arms_in_murder_cases.csv\n",
      "   - 37_Home_guards_and_auxilliary_force.csv\n",
      "   - 38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv\n",
      "   - 41_Escapes_from_police_custody.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2001_2012.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2013.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2014.csv\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2014.csv: 838 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2001_2012.csv: 9015 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv: 2028 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv: 418 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_01_Juvenile_apprehended_state_IPC.csv: 10500 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_02_Juvenile_apprehended_state_SLL.csv: 9450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\09_Juveniles_arrested_and_their_disposal.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\11_Property_stolen_and_recovered_nature_of_property.csv: 4550 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\12_Police_strength_actual_and_sanctioned.csv: 4188 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\13_Police_killed_or_injured_on_duty.csv: 2450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\14_Age_profile_of_police_personnel_killed_on_duty.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\15_Police_natural_death_and_suicide.csv: 700 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\16_Casualties_under_police_firing_and_lathi_charge.csv: 1749 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv: 4344 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv: 385 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2001_2012.csv: 456 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2013.csv: 38 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2014.csv: 39 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_01_Juveniles_arrested_Education.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_02_Juveniles_arrested_Economic_setup.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_03_Juveniles_arrested_Family_background.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_04_Juveniles_arrested_Recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\21_Offenders_known_to_the_victim.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\22_Persons_arrested_under_recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\23_Anti_corruprion_cases.csv: 346 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\24_Anti_corruption_arrests.csv: 347 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\27_Nature_of_complaints_received_by_police.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\34_Use_of_fire_arms_in_murder_cases.csv: 284 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\37_Home_guards_and_auxilliary_force.csv: 333 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv: 314 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\41_Escapes_from_police_custody.csv: 311 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2014.csv: 837 rows\n",
      "🔗 Combined dataset shape: (120227, 659)\n",
      "\n",
      "📊 Dataset Overview:\n",
      "Total samples: 120227\n",
      "Columns: ['STATE/UT', 'DISTRICT', 'YEAR', 'MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE', 'OTHER RAPE', 'KIDNAPPING & ABDUCTION', 'KIDNAPPING AND ABDUCTION OF WOMEN AND GIRLS', 'KIDNAPPING AND ABDUCTION OF OTHERS', 'DACOITY', 'PREPARATION AND ASSEMBLY FOR DACOITY', 'ROBBERY', 'BURGLARY', 'THEFT', 'AUTO THEFT', 'OTHER THEFT', 'RIOTS', 'CRIMINAL BREACH OF TRUST', 'CHEATING', 'COUNTERFIETING', 'ARSON', 'HURT/GREVIOUS HURT', 'DOWRY DEATHS', 'ASSAULT ON WOMEN WITH INTENT TO OUTRAGE HER MODESTY', 'INSULT TO MODESTY OF WOMEN', 'CRUELTY BY HUSBAND OR HIS RELATIVES', 'IMPORTATION OF GIRLS FROM FOREIGN COUNTRIES', 'CAUSING DEATH BY NEGLIGENCE', 'OTHER IPC CRIMES', 'TOTAL IPC CRIMES', 'States/UTs', 'District', 'Year', 'Murder', 'Attempt to commit Murder', 'Culpable Homicide not amounting to Murder', 'Attempt to commit Culpable Homicide', 'Rape', 'Custodial Rape', 'Custodial_Gang Rape', 'Custodial_Other Rape', 'Rape other than Custodial', 'Rape_Gang Rape', 'Rape_Others', 'Attempt to commit Rape', 'Kidnapping & Abduction_Total', 'Kidnapping & Abduction', 'Kidnapping & Abduction in order to Murder', 'Kidnapping for Ransom', 'Kidnapping & Abduction of Women to compel her for marriage', 'Other Kidnapping', 'Dacoity', 'Dacoity with Murder', 'Other Dacoity', 'Making Preparation and Assembly for committing Dacoity', 'Robbery', 'Criminal Trespass/Burglary', 'Criminal Trespass or Burglary', 'House Trespass & House Breaking', 'Theft', 'Auto Theft', 'Other Thefts', 'Unlawful Assembly', 'Riots', 'Riots_Communal', 'Riots_Industrial', 'Riots_Political', 'Riots_Caste Conflict', 'Riots_SC/STs Vs Non-SCs/STs', 'Riots_Other Caste Conflict', 'Riots_Agrarian', 'Riots_Students', 'Riots_Sectarian', 'Riots_Others', 'Criminal Breach of Trust', 'Cheating', 'Forgery', 'Counterfeiting', 'Counterfeit Offences related to Counterfeit Coin', 'Counterfeiting Government Stamp', 'Counterfeit currency & Bank notes', 'Counterfeiting currency notes/Bank notes', 'Using forged or counterfeiting currency/Bank notes', 'Possession of forged or counterfeiting currency/Bank notes', 'Making or Possessing materials for forged currency/Bank notes', 'Making or Using documents resembling currency', 'Arson', 'Grievous Hurt', 'Hurt', 'Acid attack', 'Attempt to Acid Attack', 'Dowry Deaths', 'Assault on Women with intent to outrage her Modesty', 'Sexual Harassment', 'Assault or use of criminal force to women with intent to Disrobe', 'Voyeurism', 'Stalking', 'Other Assault on Women', 'Insult to the Modesty of Women', 'At Office premises', 'Other places related to work', 'In Public Transport system', 'Places other than 231, 232 & 233', 'Cruelty by Husband or his Relatives', 'Importation of Girls from Foreign Country', 'Causing Death by Negligence', 'Deaths due to negligent driving/act', 'Deaths due to Other Causes', 'Offences against State', 'Sedition', 'Other offences against State', 'Offences promoting enmity between different groups', 'Promoting enmity between different groups', 'Imputation, assertions prejudicial to national integration', 'Extortion', 'Disclosure of Identity of Victims', 'Incidence of Rash Driving', 'HumanTrafficking', 'Unnatural Offence', 'Other IPC crimes', 'Total Cognizable IPC crimes', 'Kidnapping and Abduction', 'Prevention of atrocities (POA) Act', 'Protection of Civil Rights (PCR) Act', 'Other Crimes Against SCs', 'Protection of Civil Rights Act, 1955', 'POA_Murder', 'POA_Attempt to commit Murder', 'POA_Rape', 'POA_Attempt to commit Rape', 'POA_Assault on women with intent to outrage her Modesty', 'POA_Sexual Harassment', 'POA_Assault on women with intent to Disrobe', 'POA_Voyeurism', 'POA_Stalking', 'POA_Other Sexual Harassment', 'POA_Insult to the Modesty of women', 'POA_Kidnapping & Abduction_GrandTotal', 'POA_Kidnaping & Abduction_Total', 'POA_Kidnaping & Abduction in order to Murder', 'POA_Kidnapping for Ransom', 'POA_Kidnapping & Abduction of Women to compel her for marriage', 'POA_Other Kidnapping', 'POA_Dacoity', 'POA_Dacoity with Murder', 'POA_Other Dacoity', 'POA_Robbery', 'POA_Arson', 'POA_Grievous Hurt', 'POA_Hurt', 'POA_Acid attack', 'POA_Attempt to Acid Attack', 'POA_Riots', 'POA_Other IPC crimes', 'POA_SC / ST (Prevention of Atrocities) Act only', 'Total of SC/ST (Prevention of Atrocities) Act ,1989', 'IPC_Murder', 'IPC_Attempt to commit Murder', 'IPC_Rape', 'IPC_Attempt to commit Rape', 'IPC_Assault on women with intent to outrage her Modesty', 'IPC_Sexual Harassment', 'IPC_Assault on women with intent to Disrobe', 'IPC_Voyeurism', 'IPC_Stalking', 'IPC_Other Sexual Harassment', 'IPC_Insult to the Modesty of women', 'IPC_Kidnapping & Abduction', 'IPC_Kidnaping & Abduction', 'IPC_Kidnaping & Abduction in order to Murder', 'IPC_Kidnapping for Ransom', 'IPC_Kidnapping & Abduction of Women to compel her for marriage', 'IPC_Other Kidnapping', 'IPC_Dacoity', 'IPC_Dacoity with Murder', 'IPC_Other Dacoity', 'IPC_Robbery', 'IPC_Arson', 'IPC_Grievous Hurt', 'IPC_Hurt', 'IPC_Acid attack', 'IPC_Attempt to Acid Attack', 'IPC_Riots', 'IPC_Other IPC crimes', 'Total IPC Crimes against SCs', 'Manual Scavengers and Construction of Dry Latrines (P) Act, 1993', 'Other SLL Crime against SCs', 'Total crimes against SCs', 'Kidnapping Abduction', 'Other Crimes Against STs', 'Total IPC Crimes against STs', 'Other SLL Crime against STs', 'Total crimes against STs', 'Foeticide', 'Abetment of suicide', 'Exposure and abandonment', 'Procuration of minor girls', 'Buying of girls for prostitution', 'Selling of girls for prostitution', 'Prohibition of child marriage act', 'Other Crimes', 'Total', 'Infanticid', 'Other murder', 'CRIME HEAD', 'Persons in custody or on bail during the stage of investigation at the beginning of the year', 'Persons arrested during the year', 'Persons released or freed by Police or Magistrate before trial for want of evidence or any other reason', 'Persons in custody or on bail during the stage of investigation at the end of the year', 'Persons in whose cases charge sheets were laid during the year', 'Persons under trial at the beginning of the year', 'Total number of persons under trial during the year', 'Persons against whom cases were compounded or withdrawn', 'Persons in custody or on bail during the stage of trial at the end of the year', 'Persons in whose cases trials were completed during the year', 'Persons convicted', 'Persons acquitted', 'Crime Head', 'Persons in custody during inv stage at beginning of Year_Male', 'Persons in custody during inv stage at beginning of Year_Female', 'Persons in custody during inv stage at beginning of Year_Total', 'Persons on bail during inv stage at beginning of Year_Male', 'Persons on bail during inv stage at beginning of Year_Female', 'Persons on bail during inv stage at beginning of Year_Total', 'Persons arrested during the year_Male', 'Persons arrested during the year_Female', 'Persons arrested during the year_Total', 'Persons released or freed before trial for want of evidence_Male', 'Persons released or freed before trial for want of evidence_Fem', 'Persons released or freed before trial for want of evidence_Tot', 'Persons in custody during inv stage at year end_Male', 'Persons in custody during inv stage at year end_Female', 'Persons in custody during inv stage at year end_Total', 'Persons on Bail during inv stage at year end_Male', 'Persons on Bail during inv stage at Year end_Female', 'Persons on Bail during inv stage at year end_Total', 'Persons charge sheeted_Male', 'Persons charge sheeted_Female', 'Persons charge sheeted_Total', 'Persons in custody during trial stage at begin of year_Male', 'Persons in custody during trial stage at begin of year_Female', 'Persons in custody during trial stage at begin of year_Total', 'Persons on Bail during trial stage at begin of year_Male', 'Persons on Bail during trial stage at begin of year_Female', 'Persons on Bail during trial stage at begin of year_Total', 'Total number of persons under Trial_Male', 'Total number of persons under Trial_Female', 'Total number of persons under Trial_Total', 'Persons against whom cases were compounded by Courts_Male', 'Persons against whom cases were compounded by Courts_Female', 'Persons against whom cases were compounded by Courts_Total', 'Persons against whom cases were withdrawn_Male', 'Persons against whom cases were withdrawn_Female', 'Persons against whom cases were withdrawn_Total', 'Persons in custody during trial stage at Year end_Male', 'Persons in custody during trial stage at Year end_Female', 'Persons in custody during trial stage at Year end_Total', 'Persons on bail during trial stage at Year End_Male', 'Persons on bail during trial stage at Year End_Female', 'Persons on bail during trial stage at Year End_Total', 'Persons whose cases trials were completed during the year_Male', 'Persons whose cases trials were completed during the year_Female', 'Persons whose cases trials were completed during the year_Total', 'Persons convicted_Male', 'Persons convicted_Female', 'Persons convicted_Total', 'Persons acquitted_Male', 'Persons acquitted_Female', 'Persons acquitted_Total', 'Persons Discharged by Court_Male', 'Persons Discharged by Court_Female', 'Persons Discharged by Court_Total', 'Male Below 18 Years', 'Female Below 18 Years', 'Male Between 18-30 Years', 'Female Between 18-30 Years', 'Male Between 30-45 Years', 'Female Between 30-45 Years', 'Male Between 45-60 Years', 'Female Between 45-60 Years', 'Male Above 60 Years', 'Female Above 60 Years', 'Male Total', 'Female Total', 'Grand Total', '18 and above and below 30 years_Male', '18 and above and below 30 years_Female', '18 and above and below 30 years_Total', '30 and above and below 45 years_Male', '30 and above and below 45 years_Female', '30 and above and below 45 years_Total', '45 and above and below 60 years_Male', '45 and above and below 60 years_Female', '45 and above and below 60 years_Total', '60 years and above_Male', '60 years and above_Female', '60 years and above_Total', 'Total Male', 'Total Female', 'Total Persons Arrested by age and Sex', 'CRIME', 'Boys 7-12 Years', 'Girls 7-12 Years', 'Boys 12-16 Years', 'Girls 12-16 Years', 'Boys 16-18 Years', 'Girls 16-18 Years', 'Total for boys all Age Groups', 'Total for girls all Age Groups', 'Grand total', 'Area_Name', 'Juveniles_Acquitted_or_Otherwise_Disposed_of', 'Juveniles_Arrested', 'Juveniles_Dealt_with_Fine', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Fit_Institutions', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Parent_Guardian', 'Juveniles_Sent_Home_after_Advice_or_Admonition', 'Juveniles_Sent_to_Special_Home', 'Juveniles_whose_Cases_Pending_Disposal', 'Group_Name', 'Sub_Group_Name', 'Cases_Property_Recovered', 'Cases_Property_Stolen', 'Value_of_Property_Recovered', 'Value_of_Property_Stolen', 'Rank_All_Ranks_Total', 'Rank_ASI_Equivalent', 'Rank_ASPDySPAssttCommandant', 'Rank_Below_HC_and_Above_Constables', 'Rank_Constables', 'Rank_DGAddl_DG', 'Rank_DIG', 'Rank_Head_Constables', 'Rank_IGSplIG', 'Rank_Inspectors_Equivalent', 'Rank_SI_Equivalent', 'Rank_SSPSPAddlSPCommandant', 'Police_Injured_By_Criminals', 'Police_Injured_By_Riotous_Mobs', 'Police_Injured_In_Accidents', 'Police_Injured_In_Dacoity_OperationsOther_raids', 'Police_Injured_In_TerroristsExtremists_Operations', 'Police_Injured_On_Border_Duties', 'Police_Injured_Total_Policemen', 'Police_Killed_By_Criminals', 'Police_Killed_By_Riotous_Mobs', 'Police_Killed_In_Accidents', 'Police_Killed_In_Dacoity_OperationsOther_raids', 'Police_Killed_In_TerroristsExtremists_Operations', 'Police_Killed_On_Border_Duties', 'Police_Killed_Total_Policemen', 'Age_18_25_Yrs', 'Age_25_35_Yrs', 'Age_35_45_Yrs', 'Age_45_55_Yrs', 'Age_Above_55_Yrs', 'Age_Total', 'Civilians_Injured', 'Civilians_Killed', 'No_of_Firings', 'Policemen_Injured', 'Policemen_Killed', 'Place Of Occurrence', 'Dacoity (Section 395-398 IPC) - Number of cases registered', 'Dacoity (Section 395-398 IPC) - Value Of Property Stolen (in rupees)', 'Robbery(Section 392-394, 397, 398 IPC) - Number of cases registered', 'Robbery(Section 392-394, 397, 398 IPC) - Value Of Property Stolen (in rupees)', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Number of cases registered', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Value Of Property Stolen (in rupees)', 'Theft (Section 379-382 IPC) - Number of cases registered', 'Theft (Section 379-382 IPC) - Value Of Property Stolen (in rupees)', 'RESIDENTIAL PREMISES - Dacoity', 'RESIDENTIAL PREMISES - Robbery', 'RESIDENTIAL PREMISES - Burglary', 'RESIDENTIAL PREMISES - Theft', 'HIGHWAYS - Dacoity', 'HIGHWAYS - Robbery', 'HIGHWAYS - Burglary', 'HIGHWAYS - Theft', 'RIVER and SEA - Dacoity', 'RIVER and SEA - Robbery', 'RIVER and SEA - Burglary', 'RIVER and SEA - Theft', 'RAILWAYS - Dacoity', 'RAILWAYS - Robbery', 'RAILWAYS - Burglary', 'RAILWAYS - Theft', 'BANKS - Dacoity', 'BANKS - Robbery', 'BANKS - Burglary', 'BANKS - Theft', 'COMMERCIAL ESTABLISHMENTS - Dacoity', 'COMMERCIAL ESTABLISHMENTS - Robbery', 'COMMERCIAL ESTABLISHMENTS - Burglary', 'COMMERCIAL ESTABLISHMENTS - Theft', 'OTHER PLACES - Dacoity', 'OTHER PLACES - Robbery', 'OTHER PLACES - Burglary', 'OTHER PLACES - Theft', 'TOTAL - Dacoity', 'TOTAL - Robbery', 'TOTAL - Burglary', 'TOTAL - Theft', 'Residence_Dacoity_Cases reported', 'Residence_Dacoity_Value of property stolen', 'Residence_Robbery_Cases reported', 'Residence_Robbery_Value of property stolen', 'Residence_Burglary_Cases reported', 'Residence_Burglary_Value of property stolen', 'Residence_Theft_Cases reported', 'Residence_Theft_Value of property stolen', 'Highways_Dacoity_Cases reported', 'Highways_Dacoity_Value of property stolen', 'Highways_Robbery_Cases reported', 'Highways_Robbery_Value of property stolen', 'Highways_Burglary_Cases reported', 'Highways_Burglary_Value of property stolen', 'Highways_Theft_Cases reported', 'Highways_Theft_Value of property stolen', 'RiverOrSea_Dacoity_Cases reported', 'RiverOrSea_Dacoity_Value of property stolen', 'RiverOrSea_Robbery_Cases reported', 'RiverOrSea_Robbery_Value of property stolen', 'RiverOrSea_Burglary_Cases reported', 'RiverOrSea_Burglary_Value of property stolen', 'RiverOrSea_Theft_Cases reported', 'RiverOrSea_Theft_Value of property stolen', 'Railways_Dacoity_Cases reported', 'Railways_Dacoity_Value of property stolen', 'Railways_Robbery_Cases reported', 'Railways_Robbery_Value of property stolen', 'Railways_Burglary_Cases reported', 'Railways_Burglary_Value of property stolen', 'Railways_Theft_Cases reported', 'Railways_Theft_Value of property stolen', 'Religious Places_Dacoity_Cases reported', 'Religious Places_Dacoity_Value of property stolen', 'Religious Places_Robbery_Cases reported', 'Religious Places_Robbery_Value of property stolen', 'Religious Places_Burglary_Cases reported', 'Religious Places_Burglary_Value of property stolen', 'Religious Places_Theft_Cases reported', 'Religious Places_Theft_Value of property stolen', 'ATM_Dacoity_Cases reported', 'ATM_Dacoity_Value of property stolen', 'ATM_Robbery_Cases reported', 'ATM_Robbery_Value of property stolen', 'ATM_Burglary_Cases reported', 'ATM_Burglary_Value of property stolen', 'ATM_Theft_Cases reported', 'ATM_Theft_Value of property stolen', 'Bank_Dacoity_Cases reported', 'Bank_Dacoity_Value of property stolen', 'Bank_Robbery_Cases reported', 'Bank_Robbery_Value of property stolen', 'Bank_Burglary_Cases reported', 'Bank_Burglary_Value of property stolen', 'Bank_Theft_Cases reported', 'Bank_Theft_Value of property stolen', 'CommEst_Dacoity_Cases reported', 'CommEst_Dacoity_Value of property stolen', 'CommEst_Robbery_Cases reported', 'CommEst_Robbery_Value of property stolen', 'CommEst_Burglary_Cases reported', 'CommEst_Burglary_Value of property stolen', 'CommEst_Theft_Cases reported', 'CommEst_Theft_Value of property stolen', 'OtherPlaces_Dacoity_Cases reported', 'OtherPlaces_Dacoity_Value of property stolen', 'OtherPlaces_Robbery_Cases reported', 'OtherPlaces_Robbery_Value of property stolen', 'OtherPlaces_Burglary_Cases reported', 'OtherPlaces_Burglary_Value of property stolen', 'OtherPlaces_Theft_Cases reported', 'OtherPlaces_Theft_Value of property stolen', 'Total_Dacoity_Cases reported', 'Total_Dacoity_Value of property stolen', 'Total_Robbery_Cases reported', 'Total_Robbery_Value of property stolen', 'Total_Burglary_Cases reported', 'Total_Burglary_Value of property stolen', 'Total_Theft_Cases reported', 'Total_Theft_Value of property stolen', 'Education_Above_Primary_but_below_Matric_or_Higher_Secondary', 'Education_Illiterate', 'Education_Matric_or_Higher_Secondary_&_above', 'Education_Total', 'Education_Upto_primary', 'Economic_Set_up_Annual_Income_250001_to_50000', 'Economic_Set_up_Annual_Income_upto_Rs_25000', 'Economic_Set_up_Middle_income_from_100001_to_200000', 'Economic_Set_up_Middle_income_from_50001_to_100000', 'Economic_Set_up_Total', 'Economic_Set_up_Upper_income_above_Rs_300000', 'Economic_Set_up_Upper_middle_income_from_200001_to_300000', 'Family_back_ground_Homeless', 'Family_back_ground_Living_with_guardian', 'Family_back_ground_Living_with_parents', 'Family_back_ground_Total', 'Recidivism_New_Delinquent', 'Recidivism_Old_Delinquent', 'Recidivism_Total', 'CHNAMurder_Cause_By_TerroristExtremist', 'CHNAMurder_Cause_Casteism', 'CHNAMurder_Cause_Class_Conflict', 'CHNAMurder_Cause_Communalism', 'CHNAMurder_Cause_Dowry', 'CHNAMurder_Cause_For_Political_reason', 'CHNAMurder_Cause_Gain', 'CHNAMurder_Cause_Love_AffairsSexual_Relations', 'CHNAMurder_Cause_Lunacy', 'CHNAMurder_Cause_Other_Causes_or_Motives', 'CHNAMurder_Cause_Personal_Vendetta_or_Enmity', 'CHNAMurder_Cause_Property_Dispute', 'CHNAMurder_Cause_Total', 'CHNAMurder_Cause_Witchcraft', 'Murder_Cause_By_TerroristExtremist', 'Murder_Cause_Casteism', 'Murder_Cause_Class_Conflict', 'Murder_Cause_Communalism', 'Murder_Cause_Dowry', 'Murder_Cause_For_Political_reason', 'Murder_Cause_Gain', 'Murder_Cause_Love_AffairsSexual_Relations', 'Murder_Cause_Lunacy', 'Murder_Cause_Other_Causes_or_Motives', 'Murder_Cause_Personal_Vendetta_or_Enmity', 'Murder_Cause_Property_Dispute', 'Murder_Cause_Total', 'Murder_Cause_Witchcraft', 'No_of_Cases_in_which_offenders_were_known_to_the_Victims', 'No_of_Cases_in_which_offenders_were_Neighbours', 'No_of_Cases_in_which_offenders_were_Other_Known_persons', 'No_of_Cases_in_which_offenders_were_Parentsclose_family_members', 'No_of_Cases_in_which_offenders_were_Relatives', 'Offenders_Arrested', 'Offenders_Arrested_for_the_First_time', 'Offenders_Conviction_in_the_past_Once', 'Offenders_Conviction_in_the_past_Three_times_or_More', 'Offenders_Conviction_in_the_past_Twice', 'AC01_No_of_cases_pending_investigation_from_previous_year', 'AC02_No_of_cases_registered_during_the_year', 'AC03_Total_No_of_cases_for_investigation_during_the_year', 'AC04_No_of_cases_investigated_during_the_year', 'AC05_No_of_cases_not_investigatedor_in_which_investigation_was_dropped_due_to_any_reason_during_the_year', 'AC06_No_of_cases_transferred_to_local_police_during_the_year', 'AC07_No_of_cases_declared_false_mistake_of_fact_or_of_law_or_non_cognizable_or_civil_in_nature', 'AC08_No_of_cases_in_which_charge_sheets_were_laid_during_the_year', 'AC09_No_of_cases_pending_departmental_sanction_for_prosecution_during_the_year', 'AC10_No_of_cases_sent_up_for_trial_and_also_reported_for_departmental_action_during_the_year', 'AC11_No_of_cases_reported_for_regular_departmental_action_during_the_year', 'AC12_No_of_cases_reported_for_suitable_action_during_the_year', 'AC13_No_of_cases_in_which_charge_sheets_were_not_laid_but_final_report_submitted_during_the_year', 'AC14_No_of_cases_pending_investigation_at_the_end_of_the_year', 'AC15_No_of_cases_resulted_in_recoveries_or_seizures_during_the_year', 'AC16_Value_of_property_recoveredseized_during_the_year_in_Rs', 'AC17_Percentage_of_cases_charge_sheeted_to_total_cases_investigated', 'AC18_No_of_cases_pending_trial_from_the_previous_year', 'AC19_No_of_cases_sent_up_for_trial_during_the_year', 'AC20_Total_No_of_cases_for_trial_during_the_year', 'AC21_No_of_cases_withdrawn_or_other_wise_disposed_off_on_account_of_death_of_the_accused_during_the_year', 'AC22_No_of_cases_in_which_trials_were_completed_during_the_year', 'AC23_No_of_cases_convicted_during_the_year', 'AC24_No_of_cases_acquitted_or_discharged_during_the_year', 'AC25_No_of_cases_pending_trial_at_the_end_of_the_year', 'AC26_Percentage_of_cases_convicted_to_cases_in_which_trials_were_completed_during_the_year', 'AC27_Total_amount_of_fine_imposed_during_the_year_in_Rs', 'ACA01_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_beginning_of_the_year', 'ACA02_No_of_persons_arrested_during_the_year', 'ACA04_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_end_of_the_year', 'ACA05_No_of_persons_in_whose_cases_charge_sheets_were_laid_during_the_year', 'ACA06_No_of_persons_under_trial_at_the_beginning_of_the_year', 'ACA07_Total_No_of_persons_under_trial_during_the_year', 'ACA08_No_of_persons_whose_cases_were_withdrawn_or_otherwise_disposed_off_during_the_year', 'ACA09_No_of_persons_in_custody_or_on_bail_during_the_stage_of_trial_at_the_end_of_the_year', 'ACA10_No_of_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA11_No_of_persons_convicted_during_the_year', 'ACA12_No_of_persons_acquitted_during_the_year', 'ACA13_Percentage_of_persons_convicted_to_total_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA14_No_of_persons_involved_in_the_cases_reported_for_Regular_Departmental_Action_during_the_year', 'ACA15_No_of_persons_involved_in_the_cases_reported_for_suitable_action_during_the_year', 'ACA16_No_of_persons_punished_departmentally_during_the_year:', 'ACA161_No_of_persons_dismissed_from_Service_during_the_year', 'ACA162_No_of_persons_removed_from_service_during_the_year', 'ACA163_No_of_persons_awarded_other_major_punishments_during_the_year', 'ACA164_No_of_persons_awarded_minor_punishments_during_the_year', \"ACA171_No_of_Group_`A'_Officers_out_of_above\", \"ACA172_No_of_Group_`B'_Officers_out_of_above\", 'ACA19_No_of_private_persons_involved_during_the_year', 'PC1_Oral_Complaints', 'PC2_Written_Complaints', 'PC3_Distress_call_over_phoneNo_100_etc', 'PC4_Complaints_initiated_sue_motto_by_Police', 'PC5_Total_Complaints_Sum_of_1_4_Above', 'PC6_Total_Complaints_as_recorded_in_GD', 'PC7_IPC_Cases_Registered', 'PC8_SLL_Cases_Registered', 'Victims_of_Murder_by_Fire_arms', 'Victims_of_Murder_by_Licensed_arms', 'Victims_of_Murder_by_Un_licensedImprovisedCrudeCountry_made_Arms_Etc', 'HG_Lower_Subordinates_Actual_Strength', 'HG_Lower_Subordinates_Sanctioned_Strength', 'HG_Officers_Actual_Strength', 'HG_Officers_Sanctioned_Strength', 'HG_Upper_Subordinates_Actual_Strength', 'HG_Upper_Subordinates_Sanctioned_Strength', 'Unidentified_Dead_bodies_Recovered_Inquest_Conducted', 'EPC_Cases_Cases_Acquitted', 'EPC_Cases_Cases_Convicted', 'EPC_Cases_Cases_Pending_for_Trial', 'EPC_Cases_Registered', 'EPC_Cases_Trial_Completed', 'EPC_Escapees_Re_Arrested_from_Lockup', 'EPC_Escapees_Re_Arrested_from_Others', 'EPC_FR_Submitted', 'EPC_Persons_Awarded_more_than_3_Years_Imprisonment', 'EPC_Persons_Awarded_upto_3_Years_Imprisonment', 'EPC_Persons_Cases_Acquitted', 'EPC_Persons_Cases_Convicted', 'EPC_Persons_Cases_Pending_for_Trial', 'EPC_Persons_Chargesheeted_for_Escape', 'EPC_Persons_Escaped', 'EPC_Persons_Escaped_from_Lockup', 'EPC_Persons_Escaped_Outside_the_Lockup', 'EPC_Persons_Escaped_Total', 'EPC_Persons_Trial_Completed', 'Assault on women with intent to outrage her modesty', 'Insult to modesty of Women', 'Importation of Girls', 'Kidnaping & Abduction', 'Kidnaping & Abduction in order to Murder', 'Kidnaping & Abduction_Others', 'Assault on Women with intent to outrage her Modesty_Total', 'Assault on women with intent to Disrobe', 'Others', 'Insult to the Modesty of Women_Total', 'In places related to work', 'In other Places', 'Deaths caused with intent to cause miscarriage', 'Causing miscarriage without consent of women', 'Dacoity_Total', 'Abetment of Suicides of Women', 'UnNatural Offences', 'Other IPC Crimes', 'Dowry Prohibition Act, 1961', 'Indecent Representation of Women (P) Act, 1986', 'Commission of Sati Prevention Act, 1987', 'Protection of Women from Domestic Violence Act, 2005', 'Immoral Traffic Prevention Act', 'ITP Under Section 5', 'ITP Under Section 6', 'ITP Under Section 7', 'ITP Under Section 8', 'ITP Under Other Sections', 'Other SLL Crimes against Women', 'Total Crimes against Women']\n",
      "Missing values:\n",
      "STATE/UT                           36810\n",
      "DISTRICT                           71027\n",
      "YEAR                              105164\n",
      "MURDER                            110387\n",
      "ATTEMPT TO MURDER                 110387\n",
      "                                   ...  \n",
      "ITP Under Section 7               119390\n",
      "ITP Under Section 8               119390\n",
      "ITP Under Other Sections          119390\n",
      "Other SLL Crimes against Women    119390\n",
      "Total Crimes against Women        119390\n",
      "Length: 659, dtype: int64\n",
      "\n",
      "🏷️ Crime Category Distribution:\n",
      "DISTRICT\n",
      "TOTAL              2140\n",
      "G.R.P.              245\n",
      "NORTH               205\n",
      "SOUTH               205\n",
      "WEST                195\n",
      "                   ... \n",
      "BADWANI               1\n",
      "KANCHEEPURAM          1\n",
      "GARI HILLS EAST       1\n",
      "AMBEDKARNAGAR         1\n",
      "RAILWAYSJMU           1\n",
      "Name: count, Length: 844, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_and_merge_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Read all CSV files from the specified folder and merge them into one DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"📂 Loading CSV files from: {folder_path}\")\n",
    "    \n",
    "    # Get all CSV files in the crime folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    print(f\"📄 Found {len(csv_files)} CSV files:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"   - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Read and combine all CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"   ✅ Loaded {file}: {len(df)} rows\")\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error loading {file}: {e}\")\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"🔗 Combined dataset shape: {combined_df.shape}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Load the data - Update this path to match your system\n",
    "crime_folder = r\"C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\"\n",
    "df = load_and_merge_csv_files(crime_folder)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\n📊 Dataset Overview:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['STATE/UT', 'DISTRICT']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' not found in dataset\")\n",
    "\n",
    "# Display label distribution\n",
    "print(f\"\\n🏷️ Crime Category Distribution:\")\n",
    "print(df['DISTRICT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a69ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧹 Cleaning and preprocessing text data...\n",
      "✅ After cleaning: 83417 samples remaining\n",
      "\n",
      "📝 Sample data after cleaning:\n",
      "     text_cleaned   DISTRICT\n",
      "0  andhra pradesh   ADILABAD\n",
      "1  andhra pradesh  ANANTAPUR\n",
      "2  andhra pradesh   CHITTOOR\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters and digits (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"\\n🧹 Cleaning and preprocessing text data...\")\n",
    "\n",
    "# Clean the text column\n",
    "df['text_cleaned'] = df['STATE/UT'].apply(clean_text)\n",
    "\n",
    "# Remove empty text entries\n",
    "df = df[df['text_cleaned'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ After cleaning: {len(df)} samples remaining\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n📝 Sample data after cleaning:\")\n",
    "print(df[['text_cleaned', 'DISTRICT']].head(3).to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfca47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Crime Classification Pipeline...\n",
      "==================================================\n",
      "📂 Loading CSV files from: C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\n",
      "📄 Found 57 CSV files:\n",
      "   - 01_District_wise_crimes_committed_IPC_2001_2012.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2013.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2014.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2001_2012.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2013.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2014.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2001_2012.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2013.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2014.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2001_2012.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv\n",
      "   - 08_01_Juvenile_apprehended_state_IPC.csv\n",
      "   - 08_02_Juvenile_apprehended_state_SLL.csv\n",
      "   - 09_Juveniles_arrested_and_their_disposal.csv\n",
      "   - 11_Property_stolen_and_recovered_nature_of_property.csv\n",
      "   - 12_Police_strength_actual_and_sanctioned.csv\n",
      "   - 13_Police_killed_or_injured_on_duty.csv\n",
      "   - 14_Age_profile_of_police_personnel_killed_on_duty.csv\n",
      "   - 15_Police_natural_death_and_suicide.csv\n",
      "   - 16_Casualties_under_police_firing_and_lathi_charge.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2014.csv\n",
      "   - 18_01_Juveniles_arrested_Education.csv\n",
      "   - 18_02_Juveniles_arrested_Economic_setup.csv\n",
      "   - 18_03_Juveniles_arrested_Family_background.csv\n",
      "   - 18_04_Juveniles_arrested_Recidivism.csv\n",
      "   - 19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv\n",
      "   - 21_Offenders_known_to_the_victim.csv\n",
      "   - 22_Persons_arrested_under_recidivism.csv\n",
      "   - 23_Anti_corruprion_cases.csv\n",
      "   - 24_Anti_corruption_arrests.csv\n",
      "   - 27_Nature_of_complaints_received_by_police.csv\n",
      "   - 34_Use_of_fire_arms_in_murder_cases.csv\n",
      "   - 37_Home_guards_and_auxilliary_force.csv\n",
      "   - 38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv\n",
      "   - 41_Escapes_from_police_custody.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2001_2012.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2013.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2014.csv\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2014.csv: 838 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2001_2012.csv: 9015 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv: 2028 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv: 418 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_01_Juvenile_apprehended_state_IPC.csv: 10500 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_02_Juvenile_apprehended_state_SLL.csv: 9450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\09_Juveniles_arrested_and_their_disposal.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\11_Property_stolen_and_recovered_nature_of_property.csv: 4550 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\12_Police_strength_actual_and_sanctioned.csv: 4188 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\13_Police_killed_or_injured_on_duty.csv: 2450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\14_Age_profile_of_police_personnel_killed_on_duty.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\15_Police_natural_death_and_suicide.csv: 700 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\16_Casualties_under_police_firing_and_lathi_charge.csv: 1749 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv: 4344 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv: 385 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2001_2012.csv: 456 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2013.csv: 38 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2014.csv: 39 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_01_Juveniles_arrested_Education.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_02_Juveniles_arrested_Economic_setup.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_03_Juveniles_arrested_Family_background.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_04_Juveniles_arrested_Recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\21_Offenders_known_to_the_victim.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\22_Persons_arrested_under_recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\23_Anti_corruprion_cases.csv: 346 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\24_Anti_corruption_arrests.csv: 347 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\27_Nature_of_complaints_received_by_police.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\34_Use_of_fire_arms_in_murder_cases.csv: 284 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\37_Home_guards_and_auxilliary_force.csv: 333 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv: 314 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\41_Escapes_from_police_custody.csv: 311 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2014.csv: 837 rows\n",
      "🔗 Combined dataset shape: (120227, 659)\n",
      "\n",
      "📊 Dataset Overview:\n",
      "Total samples: 120227\n",
      "Columns: ['STATE/UT', 'DISTRICT', 'YEAR', 'MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE', 'OTHER RAPE', 'KIDNAPPING & ABDUCTION', 'KIDNAPPING AND ABDUCTION OF WOMEN AND GIRLS', 'KIDNAPPING AND ABDUCTION OF OTHERS', 'DACOITY', 'PREPARATION AND ASSEMBLY FOR DACOITY', 'ROBBERY', 'BURGLARY', 'THEFT', 'AUTO THEFT', 'OTHER THEFT', 'RIOTS', 'CRIMINAL BREACH OF TRUST', 'CHEATING', 'COUNTERFIETING', 'ARSON', 'HURT/GREVIOUS HURT', 'DOWRY DEATHS', 'ASSAULT ON WOMEN WITH INTENT TO OUTRAGE HER MODESTY', 'INSULT TO MODESTY OF WOMEN', 'CRUELTY BY HUSBAND OR HIS RELATIVES', 'IMPORTATION OF GIRLS FROM FOREIGN COUNTRIES', 'CAUSING DEATH BY NEGLIGENCE', 'OTHER IPC CRIMES', 'TOTAL IPC CRIMES', 'States/UTs', 'District', 'Year', 'Murder', 'Attempt to commit Murder', 'Culpable Homicide not amounting to Murder', 'Attempt to commit Culpable Homicide', 'Rape', 'Custodial Rape', 'Custodial_Gang Rape', 'Custodial_Other Rape', 'Rape other than Custodial', 'Rape_Gang Rape', 'Rape_Others', 'Attempt to commit Rape', 'Kidnapping & Abduction_Total', 'Kidnapping & Abduction', 'Kidnapping & Abduction in order to Murder', 'Kidnapping for Ransom', 'Kidnapping & Abduction of Women to compel her for marriage', 'Other Kidnapping', 'Dacoity', 'Dacoity with Murder', 'Other Dacoity', 'Making Preparation and Assembly for committing Dacoity', 'Robbery', 'Criminal Trespass/Burglary', 'Criminal Trespass or Burglary', 'House Trespass & House Breaking', 'Theft', 'Auto Theft', 'Other Thefts', 'Unlawful Assembly', 'Riots', 'Riots_Communal', 'Riots_Industrial', 'Riots_Political', 'Riots_Caste Conflict', 'Riots_SC/STs Vs Non-SCs/STs', 'Riots_Other Caste Conflict', 'Riots_Agrarian', 'Riots_Students', 'Riots_Sectarian', 'Riots_Others', 'Criminal Breach of Trust', 'Cheating', 'Forgery', 'Counterfeiting', 'Counterfeit Offences related to Counterfeit Coin', 'Counterfeiting Government Stamp', 'Counterfeit currency & Bank notes', 'Counterfeiting currency notes/Bank notes', 'Using forged or counterfeiting currency/Bank notes', 'Possession of forged or counterfeiting currency/Bank notes', 'Making or Possessing materials for forged currency/Bank notes', 'Making or Using documents resembling currency', 'Arson', 'Grievous Hurt', 'Hurt', 'Acid attack', 'Attempt to Acid Attack', 'Dowry Deaths', 'Assault on Women with intent to outrage her Modesty', 'Sexual Harassment', 'Assault or use of criminal force to women with intent to Disrobe', 'Voyeurism', 'Stalking', 'Other Assault on Women', 'Insult to the Modesty of Women', 'At Office premises', 'Other places related to work', 'In Public Transport system', 'Places other than 231, 232 & 233', 'Cruelty by Husband or his Relatives', 'Importation of Girls from Foreign Country', 'Causing Death by Negligence', 'Deaths due to negligent driving/act', 'Deaths due to Other Causes', 'Offences against State', 'Sedition', 'Other offences against State', 'Offences promoting enmity between different groups', 'Promoting enmity between different groups', 'Imputation, assertions prejudicial to national integration', 'Extortion', 'Disclosure of Identity of Victims', 'Incidence of Rash Driving', 'HumanTrafficking', 'Unnatural Offence', 'Other IPC crimes', 'Total Cognizable IPC crimes', 'Kidnapping and Abduction', 'Prevention of atrocities (POA) Act', 'Protection of Civil Rights (PCR) Act', 'Other Crimes Against SCs', 'Protection of Civil Rights Act, 1955', 'POA_Murder', 'POA_Attempt to commit Murder', 'POA_Rape', 'POA_Attempt to commit Rape', 'POA_Assault on women with intent to outrage her Modesty', 'POA_Sexual Harassment', 'POA_Assault on women with intent to Disrobe', 'POA_Voyeurism', 'POA_Stalking', 'POA_Other Sexual Harassment', 'POA_Insult to the Modesty of women', 'POA_Kidnapping & Abduction_GrandTotal', 'POA_Kidnaping & Abduction_Total', 'POA_Kidnaping & Abduction in order to Murder', 'POA_Kidnapping for Ransom', 'POA_Kidnapping & Abduction of Women to compel her for marriage', 'POA_Other Kidnapping', 'POA_Dacoity', 'POA_Dacoity with Murder', 'POA_Other Dacoity', 'POA_Robbery', 'POA_Arson', 'POA_Grievous Hurt', 'POA_Hurt', 'POA_Acid attack', 'POA_Attempt to Acid Attack', 'POA_Riots', 'POA_Other IPC crimes', 'POA_SC / ST (Prevention of Atrocities) Act only', 'Total of SC/ST (Prevention of Atrocities) Act ,1989', 'IPC_Murder', 'IPC_Attempt to commit Murder', 'IPC_Rape', 'IPC_Attempt to commit Rape', 'IPC_Assault on women with intent to outrage her Modesty', 'IPC_Sexual Harassment', 'IPC_Assault on women with intent to Disrobe', 'IPC_Voyeurism', 'IPC_Stalking', 'IPC_Other Sexual Harassment', 'IPC_Insult to the Modesty of women', 'IPC_Kidnapping & Abduction', 'IPC_Kidnaping & Abduction', 'IPC_Kidnaping & Abduction in order to Murder', 'IPC_Kidnapping for Ransom', 'IPC_Kidnapping & Abduction of Women to compel her for marriage', 'IPC_Other Kidnapping', 'IPC_Dacoity', 'IPC_Dacoity with Murder', 'IPC_Other Dacoity', 'IPC_Robbery', 'IPC_Arson', 'IPC_Grievous Hurt', 'IPC_Hurt', 'IPC_Acid attack', 'IPC_Attempt to Acid Attack', 'IPC_Riots', 'IPC_Other IPC crimes', 'Total IPC Crimes against SCs', 'Manual Scavengers and Construction of Dry Latrines (P) Act, 1993', 'Other SLL Crime against SCs', 'Total crimes against SCs', 'Kidnapping Abduction', 'Other Crimes Against STs', 'Total IPC Crimes against STs', 'Other SLL Crime against STs', 'Total crimes against STs', 'Foeticide', 'Abetment of suicide', 'Exposure and abandonment', 'Procuration of minor girls', 'Buying of girls for prostitution', 'Selling of girls for prostitution', 'Prohibition of child marriage act', 'Other Crimes', 'Total', 'Infanticid', 'Other murder', 'CRIME HEAD', 'Persons in custody or on bail during the stage of investigation at the beginning of the year', 'Persons arrested during the year', 'Persons released or freed by Police or Magistrate before trial for want of evidence or any other reason', 'Persons in custody or on bail during the stage of investigation at the end of the year', 'Persons in whose cases charge sheets were laid during the year', 'Persons under trial at the beginning of the year', 'Total number of persons under trial during the year', 'Persons against whom cases were compounded or withdrawn', 'Persons in custody or on bail during the stage of trial at the end of the year', 'Persons in whose cases trials were completed during the year', 'Persons convicted', 'Persons acquitted', 'Crime Head', 'Persons in custody during inv stage at beginning of Year_Male', 'Persons in custody during inv stage at beginning of Year_Female', 'Persons in custody during inv stage at beginning of Year_Total', 'Persons on bail during inv stage at beginning of Year_Male', 'Persons on bail during inv stage at beginning of Year_Female', 'Persons on bail during inv stage at beginning of Year_Total', 'Persons arrested during the year_Male', 'Persons arrested during the year_Female', 'Persons arrested during the year_Total', 'Persons released or freed before trial for want of evidence_Male', 'Persons released or freed before trial for want of evidence_Fem', 'Persons released or freed before trial for want of evidence_Tot', 'Persons in custody during inv stage at year end_Male', 'Persons in custody during inv stage at year end_Female', 'Persons in custody during inv stage at year end_Total', 'Persons on Bail during inv stage at year end_Male', 'Persons on Bail during inv stage at Year end_Female', 'Persons on Bail during inv stage at year end_Total', 'Persons charge sheeted_Male', 'Persons charge sheeted_Female', 'Persons charge sheeted_Total', 'Persons in custody during trial stage at begin of year_Male', 'Persons in custody during trial stage at begin of year_Female', 'Persons in custody during trial stage at begin of year_Total', 'Persons on Bail during trial stage at begin of year_Male', 'Persons on Bail during trial stage at begin of year_Female', 'Persons on Bail during trial stage at begin of year_Total', 'Total number of persons under Trial_Male', 'Total number of persons under Trial_Female', 'Total number of persons under Trial_Total', 'Persons against whom cases were compounded by Courts_Male', 'Persons against whom cases were compounded by Courts_Female', 'Persons against whom cases were compounded by Courts_Total', 'Persons against whom cases were withdrawn_Male', 'Persons against whom cases were withdrawn_Female', 'Persons against whom cases were withdrawn_Total', 'Persons in custody during trial stage at Year end_Male', 'Persons in custody during trial stage at Year end_Female', 'Persons in custody during trial stage at Year end_Total', 'Persons on bail during trial stage at Year End_Male', 'Persons on bail during trial stage at Year End_Female', 'Persons on bail during trial stage at Year End_Total', 'Persons whose cases trials were completed during the year_Male', 'Persons whose cases trials were completed during the year_Female', 'Persons whose cases trials were completed during the year_Total', 'Persons convicted_Male', 'Persons convicted_Female', 'Persons convicted_Total', 'Persons acquitted_Male', 'Persons acquitted_Female', 'Persons acquitted_Total', 'Persons Discharged by Court_Male', 'Persons Discharged by Court_Female', 'Persons Discharged by Court_Total', 'Male Below 18 Years', 'Female Below 18 Years', 'Male Between 18-30 Years', 'Female Between 18-30 Years', 'Male Between 30-45 Years', 'Female Between 30-45 Years', 'Male Between 45-60 Years', 'Female Between 45-60 Years', 'Male Above 60 Years', 'Female Above 60 Years', 'Male Total', 'Female Total', 'Grand Total', '18 and above and below 30 years_Male', '18 and above and below 30 years_Female', '18 and above and below 30 years_Total', '30 and above and below 45 years_Male', '30 and above and below 45 years_Female', '30 and above and below 45 years_Total', '45 and above and below 60 years_Male', '45 and above and below 60 years_Female', '45 and above and below 60 years_Total', '60 years and above_Male', '60 years and above_Female', '60 years and above_Total', 'Total Male', 'Total Female', 'Total Persons Arrested by age and Sex', 'CRIME', 'Boys 7-12 Years', 'Girls 7-12 Years', 'Boys 12-16 Years', 'Girls 12-16 Years', 'Boys 16-18 Years', 'Girls 16-18 Years', 'Total for boys all Age Groups', 'Total for girls all Age Groups', 'Grand total', 'Area_Name', 'Juveniles_Acquitted_or_Otherwise_Disposed_of', 'Juveniles_Arrested', 'Juveniles_Dealt_with_Fine', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Fit_Institutions', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Parent_Guardian', 'Juveniles_Sent_Home_after_Advice_or_Admonition', 'Juveniles_Sent_to_Special_Home', 'Juveniles_whose_Cases_Pending_Disposal', 'Group_Name', 'Sub_Group_Name', 'Cases_Property_Recovered', 'Cases_Property_Stolen', 'Value_of_Property_Recovered', 'Value_of_Property_Stolen', 'Rank_All_Ranks_Total', 'Rank_ASI_Equivalent', 'Rank_ASPDySPAssttCommandant', 'Rank_Below_HC_and_Above_Constables', 'Rank_Constables', 'Rank_DGAddl_DG', 'Rank_DIG', 'Rank_Head_Constables', 'Rank_IGSplIG', 'Rank_Inspectors_Equivalent', 'Rank_SI_Equivalent', 'Rank_SSPSPAddlSPCommandant', 'Police_Injured_By_Criminals', 'Police_Injured_By_Riotous_Mobs', 'Police_Injured_In_Accidents', 'Police_Injured_In_Dacoity_OperationsOther_raids', 'Police_Injured_In_TerroristsExtremists_Operations', 'Police_Injured_On_Border_Duties', 'Police_Injured_Total_Policemen', 'Police_Killed_By_Criminals', 'Police_Killed_By_Riotous_Mobs', 'Police_Killed_In_Accidents', 'Police_Killed_In_Dacoity_OperationsOther_raids', 'Police_Killed_In_TerroristsExtremists_Operations', 'Police_Killed_On_Border_Duties', 'Police_Killed_Total_Policemen', 'Age_18_25_Yrs', 'Age_25_35_Yrs', 'Age_35_45_Yrs', 'Age_45_55_Yrs', 'Age_Above_55_Yrs', 'Age_Total', 'Civilians_Injured', 'Civilians_Killed', 'No_of_Firings', 'Policemen_Injured', 'Policemen_Killed', 'Place Of Occurrence', 'Dacoity (Section 395-398 IPC) - Number of cases registered', 'Dacoity (Section 395-398 IPC) - Value Of Property Stolen (in rupees)', 'Robbery(Section 392-394, 397, 398 IPC) - Number of cases registered', 'Robbery(Section 392-394, 397, 398 IPC) - Value Of Property Stolen (in rupees)', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Number of cases registered', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Value Of Property Stolen (in rupees)', 'Theft (Section 379-382 IPC) - Number of cases registered', 'Theft (Section 379-382 IPC) - Value Of Property Stolen (in rupees)', 'RESIDENTIAL PREMISES - Dacoity', 'RESIDENTIAL PREMISES - Robbery', 'RESIDENTIAL PREMISES - Burglary', 'RESIDENTIAL PREMISES - Theft', 'HIGHWAYS - Dacoity', 'HIGHWAYS - Robbery', 'HIGHWAYS - Burglary', 'HIGHWAYS - Theft', 'RIVER and SEA - Dacoity', 'RIVER and SEA - Robbery', 'RIVER and SEA - Burglary', 'RIVER and SEA - Theft', 'RAILWAYS - Dacoity', 'RAILWAYS - Robbery', 'RAILWAYS - Burglary', 'RAILWAYS - Theft', 'BANKS - Dacoity', 'BANKS - Robbery', 'BANKS - Burglary', 'BANKS - Theft', 'COMMERCIAL ESTABLISHMENTS - Dacoity', 'COMMERCIAL ESTABLISHMENTS - Robbery', 'COMMERCIAL ESTABLISHMENTS - Burglary', 'COMMERCIAL ESTABLISHMENTS - Theft', 'OTHER PLACES - Dacoity', 'OTHER PLACES - Robbery', 'OTHER PLACES - Burglary', 'OTHER PLACES - Theft', 'TOTAL - Dacoity', 'TOTAL - Robbery', 'TOTAL - Burglary', 'TOTAL - Theft', 'Residence_Dacoity_Cases reported', 'Residence_Dacoity_Value of property stolen', 'Residence_Robbery_Cases reported', 'Residence_Robbery_Value of property stolen', 'Residence_Burglary_Cases reported', 'Residence_Burglary_Value of property stolen', 'Residence_Theft_Cases reported', 'Residence_Theft_Value of property stolen', 'Highways_Dacoity_Cases reported', 'Highways_Dacoity_Value of property stolen', 'Highways_Robbery_Cases reported', 'Highways_Robbery_Value of property stolen', 'Highways_Burglary_Cases reported', 'Highways_Burglary_Value of property stolen', 'Highways_Theft_Cases reported', 'Highways_Theft_Value of property stolen', 'RiverOrSea_Dacoity_Cases reported', 'RiverOrSea_Dacoity_Value of property stolen', 'RiverOrSea_Robbery_Cases reported', 'RiverOrSea_Robbery_Value of property stolen', 'RiverOrSea_Burglary_Cases reported', 'RiverOrSea_Burglary_Value of property stolen', 'RiverOrSea_Theft_Cases reported', 'RiverOrSea_Theft_Value of property stolen', 'Railways_Dacoity_Cases reported', 'Railways_Dacoity_Value of property stolen', 'Railways_Robbery_Cases reported', 'Railways_Robbery_Value of property stolen', 'Railways_Burglary_Cases reported', 'Railways_Burglary_Value of property stolen', 'Railways_Theft_Cases reported', 'Railways_Theft_Value of property stolen', 'Religious Places_Dacoity_Cases reported', 'Religious Places_Dacoity_Value of property stolen', 'Religious Places_Robbery_Cases reported', 'Religious Places_Robbery_Value of property stolen', 'Religious Places_Burglary_Cases reported', 'Religious Places_Burglary_Value of property stolen', 'Religious Places_Theft_Cases reported', 'Religious Places_Theft_Value of property stolen', 'ATM_Dacoity_Cases reported', 'ATM_Dacoity_Value of property stolen', 'ATM_Robbery_Cases reported', 'ATM_Robbery_Value of property stolen', 'ATM_Burglary_Cases reported', 'ATM_Burglary_Value of property stolen', 'ATM_Theft_Cases reported', 'ATM_Theft_Value of property stolen', 'Bank_Dacoity_Cases reported', 'Bank_Dacoity_Value of property stolen', 'Bank_Robbery_Cases reported', 'Bank_Robbery_Value of property stolen', 'Bank_Burglary_Cases reported', 'Bank_Burglary_Value of property stolen', 'Bank_Theft_Cases reported', 'Bank_Theft_Value of property stolen', 'CommEst_Dacoity_Cases reported', 'CommEst_Dacoity_Value of property stolen', 'CommEst_Robbery_Cases reported', 'CommEst_Robbery_Value of property stolen', 'CommEst_Burglary_Cases reported', 'CommEst_Burglary_Value of property stolen', 'CommEst_Theft_Cases reported', 'CommEst_Theft_Value of property stolen', 'OtherPlaces_Dacoity_Cases reported', 'OtherPlaces_Dacoity_Value of property stolen', 'OtherPlaces_Robbery_Cases reported', 'OtherPlaces_Robbery_Value of property stolen', 'OtherPlaces_Burglary_Cases reported', 'OtherPlaces_Burglary_Value of property stolen', 'OtherPlaces_Theft_Cases reported', 'OtherPlaces_Theft_Value of property stolen', 'Total_Dacoity_Cases reported', 'Total_Dacoity_Value of property stolen', 'Total_Robbery_Cases reported', 'Total_Robbery_Value of property stolen', 'Total_Burglary_Cases reported', 'Total_Burglary_Value of property stolen', 'Total_Theft_Cases reported', 'Total_Theft_Value of property stolen', 'Education_Above_Primary_but_below_Matric_or_Higher_Secondary', 'Education_Illiterate', 'Education_Matric_or_Higher_Secondary_&_above', 'Education_Total', 'Education_Upto_primary', 'Economic_Set_up_Annual_Income_250001_to_50000', 'Economic_Set_up_Annual_Income_upto_Rs_25000', 'Economic_Set_up_Middle_income_from_100001_to_200000', 'Economic_Set_up_Middle_income_from_50001_to_100000', 'Economic_Set_up_Total', 'Economic_Set_up_Upper_income_above_Rs_300000', 'Economic_Set_up_Upper_middle_income_from_200001_to_300000', 'Family_back_ground_Homeless', 'Family_back_ground_Living_with_guardian', 'Family_back_ground_Living_with_parents', 'Family_back_ground_Total', 'Recidivism_New_Delinquent', 'Recidivism_Old_Delinquent', 'Recidivism_Total', 'CHNAMurder_Cause_By_TerroristExtremist', 'CHNAMurder_Cause_Casteism', 'CHNAMurder_Cause_Class_Conflict', 'CHNAMurder_Cause_Communalism', 'CHNAMurder_Cause_Dowry', 'CHNAMurder_Cause_For_Political_reason', 'CHNAMurder_Cause_Gain', 'CHNAMurder_Cause_Love_AffairsSexual_Relations', 'CHNAMurder_Cause_Lunacy', 'CHNAMurder_Cause_Other_Causes_or_Motives', 'CHNAMurder_Cause_Personal_Vendetta_or_Enmity', 'CHNAMurder_Cause_Property_Dispute', 'CHNAMurder_Cause_Total', 'CHNAMurder_Cause_Witchcraft', 'Murder_Cause_By_TerroristExtremist', 'Murder_Cause_Casteism', 'Murder_Cause_Class_Conflict', 'Murder_Cause_Communalism', 'Murder_Cause_Dowry', 'Murder_Cause_For_Political_reason', 'Murder_Cause_Gain', 'Murder_Cause_Love_AffairsSexual_Relations', 'Murder_Cause_Lunacy', 'Murder_Cause_Other_Causes_or_Motives', 'Murder_Cause_Personal_Vendetta_or_Enmity', 'Murder_Cause_Property_Dispute', 'Murder_Cause_Total', 'Murder_Cause_Witchcraft', 'No_of_Cases_in_which_offenders_were_known_to_the_Victims', 'No_of_Cases_in_which_offenders_were_Neighbours', 'No_of_Cases_in_which_offenders_were_Other_Known_persons', 'No_of_Cases_in_which_offenders_were_Parentsclose_family_members', 'No_of_Cases_in_which_offenders_were_Relatives', 'Offenders_Arrested', 'Offenders_Arrested_for_the_First_time', 'Offenders_Conviction_in_the_past_Once', 'Offenders_Conviction_in_the_past_Three_times_or_More', 'Offenders_Conviction_in_the_past_Twice', 'AC01_No_of_cases_pending_investigation_from_previous_year', 'AC02_No_of_cases_registered_during_the_year', 'AC03_Total_No_of_cases_for_investigation_during_the_year', 'AC04_No_of_cases_investigated_during_the_year', 'AC05_No_of_cases_not_investigatedor_in_which_investigation_was_dropped_due_to_any_reason_during_the_year', 'AC06_No_of_cases_transferred_to_local_police_during_the_year', 'AC07_No_of_cases_declared_false_mistake_of_fact_or_of_law_or_non_cognizable_or_civil_in_nature', 'AC08_No_of_cases_in_which_charge_sheets_were_laid_during_the_year', 'AC09_No_of_cases_pending_departmental_sanction_for_prosecution_during_the_year', 'AC10_No_of_cases_sent_up_for_trial_and_also_reported_for_departmental_action_during_the_year', 'AC11_No_of_cases_reported_for_regular_departmental_action_during_the_year', 'AC12_No_of_cases_reported_for_suitable_action_during_the_year', 'AC13_No_of_cases_in_which_charge_sheets_were_not_laid_but_final_report_submitted_during_the_year', 'AC14_No_of_cases_pending_investigation_at_the_end_of_the_year', 'AC15_No_of_cases_resulted_in_recoveries_or_seizures_during_the_year', 'AC16_Value_of_property_recoveredseized_during_the_year_in_Rs', 'AC17_Percentage_of_cases_charge_sheeted_to_total_cases_investigated', 'AC18_No_of_cases_pending_trial_from_the_previous_year', 'AC19_No_of_cases_sent_up_for_trial_during_the_year', 'AC20_Total_No_of_cases_for_trial_during_the_year', 'AC21_No_of_cases_withdrawn_or_other_wise_disposed_off_on_account_of_death_of_the_accused_during_the_year', 'AC22_No_of_cases_in_which_trials_were_completed_during_the_year', 'AC23_No_of_cases_convicted_during_the_year', 'AC24_No_of_cases_acquitted_or_discharged_during_the_year', 'AC25_No_of_cases_pending_trial_at_the_end_of_the_year', 'AC26_Percentage_of_cases_convicted_to_cases_in_which_trials_were_completed_during_the_year', 'AC27_Total_amount_of_fine_imposed_during_the_year_in_Rs', 'ACA01_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_beginning_of_the_year', 'ACA02_No_of_persons_arrested_during_the_year', 'ACA04_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_end_of_the_year', 'ACA05_No_of_persons_in_whose_cases_charge_sheets_were_laid_during_the_year', 'ACA06_No_of_persons_under_trial_at_the_beginning_of_the_year', 'ACA07_Total_No_of_persons_under_trial_during_the_year', 'ACA08_No_of_persons_whose_cases_were_withdrawn_or_otherwise_disposed_off_during_the_year', 'ACA09_No_of_persons_in_custody_or_on_bail_during_the_stage_of_trial_at_the_end_of_the_year', 'ACA10_No_of_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA11_No_of_persons_convicted_during_the_year', 'ACA12_No_of_persons_acquitted_during_the_year', 'ACA13_Percentage_of_persons_convicted_to_total_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA14_No_of_persons_involved_in_the_cases_reported_for_Regular_Departmental_Action_during_the_year', 'ACA15_No_of_persons_involved_in_the_cases_reported_for_suitable_action_during_the_year', 'ACA16_No_of_persons_punished_departmentally_during_the_year:', 'ACA161_No_of_persons_dismissed_from_Service_during_the_year', 'ACA162_No_of_persons_removed_from_service_during_the_year', 'ACA163_No_of_persons_awarded_other_major_punishments_during_the_year', 'ACA164_No_of_persons_awarded_minor_punishments_during_the_year', \"ACA171_No_of_Group_`A'_Officers_out_of_above\", \"ACA172_No_of_Group_`B'_Officers_out_of_above\", 'ACA19_No_of_private_persons_involved_during_the_year', 'PC1_Oral_Complaints', 'PC2_Written_Complaints', 'PC3_Distress_call_over_phoneNo_100_etc', 'PC4_Complaints_initiated_sue_motto_by_Police', 'PC5_Total_Complaints_Sum_of_1_4_Above', 'PC6_Total_Complaints_as_recorded_in_GD', 'PC7_IPC_Cases_Registered', 'PC8_SLL_Cases_Registered', 'Victims_of_Murder_by_Fire_arms', 'Victims_of_Murder_by_Licensed_arms', 'Victims_of_Murder_by_Un_licensedImprovisedCrudeCountry_made_Arms_Etc', 'HG_Lower_Subordinates_Actual_Strength', 'HG_Lower_Subordinates_Sanctioned_Strength', 'HG_Officers_Actual_Strength', 'HG_Officers_Sanctioned_Strength', 'HG_Upper_Subordinates_Actual_Strength', 'HG_Upper_Subordinates_Sanctioned_Strength', 'Unidentified_Dead_bodies_Recovered_Inquest_Conducted', 'EPC_Cases_Cases_Acquitted', 'EPC_Cases_Cases_Convicted', 'EPC_Cases_Cases_Pending_for_Trial', 'EPC_Cases_Registered', 'EPC_Cases_Trial_Completed', 'EPC_Escapees_Re_Arrested_from_Lockup', 'EPC_Escapees_Re_Arrested_from_Others', 'EPC_FR_Submitted', 'EPC_Persons_Awarded_more_than_3_Years_Imprisonment', 'EPC_Persons_Awarded_upto_3_Years_Imprisonment', 'EPC_Persons_Cases_Acquitted', 'EPC_Persons_Cases_Convicted', 'EPC_Persons_Cases_Pending_for_Trial', 'EPC_Persons_Chargesheeted_for_Escape', 'EPC_Persons_Escaped', 'EPC_Persons_Escaped_from_Lockup', 'EPC_Persons_Escaped_Outside_the_Lockup', 'EPC_Persons_Escaped_Total', 'EPC_Persons_Trial_Completed', 'Assault on women with intent to outrage her modesty', 'Insult to modesty of Women', 'Importation of Girls', 'Kidnaping & Abduction', 'Kidnaping & Abduction in order to Murder', 'Kidnaping & Abduction_Others', 'Assault on Women with intent to outrage her Modesty_Total', 'Assault on women with intent to Disrobe', 'Others', 'Insult to the Modesty of Women_Total', 'In places related to work', 'In other Places', 'Deaths caused with intent to cause miscarriage', 'Causing miscarriage without consent of women', 'Dacoity_Total', 'Abetment of Suicides of Women', 'UnNatural Offences', 'Other IPC Crimes', 'Dowry Prohibition Act, 1961', 'Indecent Representation of Women (P) Act, 1986', 'Commission of Sati Prevention Act, 1987', 'Protection of Women from Domestic Violence Act, 2005', 'Immoral Traffic Prevention Act', 'ITP Under Section 5', 'ITP Under Section 6', 'ITP Under Section 7', 'ITP Under Section 8', 'ITP Under Other Sections', 'Other SLL Crimes against Women', 'Total Crimes against Women']\n",
      "Missing values:\n",
      "STATE/UT                           36810\n",
      "DISTRICT                           71027\n",
      "YEAR                              105164\n",
      "MURDER                            110387\n",
      "ATTEMPT TO MURDER                 110387\n",
      "                                   ...  \n",
      "ITP Under Section 7               119390\n",
      "ITP Under Section 8               119390\n",
      "ITP Under Other Sections          119390\n",
      "Other SLL Crimes against Women    119390\n",
      "Total Crimes against Women        119390\n",
      "Length: 659, dtype: int64\n",
      "\n",
      "🏷️ Crime Category Distribution:\n",
      "DISTRICT\n",
      "TOTAL              2140\n",
      "G.R.P.              245\n",
      "NORTH               205\n",
      "SOUTH               205\n",
      "WEST                195\n",
      "                   ... \n",
      "BADWANI               1\n",
      "KANCHEEPURAM          1\n",
      "GARI HILLS EAST       1\n",
      "AMBEDKARNAGAR         1\n",
      "RAILWAYSJMU           1\n",
      "Name: count, Length: 844, dtype: int64\n",
      "\n",
      "🧹 Cleaning and preprocessing text data...\n",
      "🔍 Before cleaning - Total samples: 120227\n",
      "Missing values in STATE/UT: 36810\n",
      "Missing values in DISTRICT: 71027\n",
      "✅ After cleaning: 49200 samples remaining\n",
      "📊 Districts after cleaning: 844 unique districts\n",
      "District distribution:\n",
      "DISTRICT\n",
      "TOTAL              2140\n",
      "G.R.P.              245\n",
      "NORTH               205\n",
      "SOUTH               205\n",
      "WEST                195\n",
      "                   ... \n",
      "BADWANI               1\n",
      "KANCHEEPURAM          1\n",
      "GARI HILLS EAST       1\n",
      "AMBEDKARNAGAR         1\n",
      "RAILWAYSJMU           1\n",
      "Name: count, Length: 844, dtype: int64\n",
      "📊 After filtering rare districts: 49195 samples with 839 districts\n",
      "\n",
      "📝 Sample data after cleaning:\n",
      "     text_cleaned   DISTRICT\n",
      "0  andhra pradesh   ADILABAD\n",
      "1  andhra pradesh  ANANTAPUR\n",
      "2  andhra pradesh   CHITTOOR\n",
      "\n",
      "✂️ Splitting dataset into training and testing sets...\n",
      "🔍 Final check - Missing values in X: 0\n",
      "🔍 Final check - Missing values in y: 0\n",
      "📊 Minimum samples per district: 2\n",
      "✅ Using stratified split\n",
      "📈 Training set size: 39356 samples\n",
      "📉 Testing set size: 9839 samples\n",
      "🎯 Number of unique districts: 839\n",
      "\n",
      "🔤 Vectorizing text data using TF-IDF...\n",
      "✅ TF-IDF vectorization completed\n",
      "📊 Training features shape: (39356, 51)\n",
      "📊 Testing features shape: (9839, 51)\n",
      "📚 Vocabulary size: 51\n",
      "\n",
      "🤖 Training Logistic Regression classifier...\n",
      "✅ Model training completed!\n",
      "\n",
      "📈 Evaluating model performance...\n",
      "🎯 Model Accuracy: 0.0408 (4.08%)\n",
      "\n",
      "📋 Detailed Classification Report:\n",
      "============================================================\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "   24 PARGANAS NORTH       0.00      0.00      0.00        13\n",
      "   24 PARGANAS SOUTH       0.00      0.00      0.00        13\n",
      "     A and N ISLANDS       0.00      0.00      0.00         1\n",
      "            ADILABAD       0.00      0.00      0.00        13\n",
      "                AGAR       0.00      0.00      0.00         1\n",
      "                AGRA       0.00      0.00      0.00        13\n",
      "    AHMEDABAD COMMR.       0.00      0.00      0.00        13\n",
      "     AHMEDABAD RURAL       0.00      0.00      0.00        13\n",
      "          AHMEDNAGAR       0.00      0.00      0.00        13\n",
      "           AHWA-DANG       0.00      0.00      0.00        13\n",
      "              AIZAWL       0.00      0.00      0.00        13\n",
      "               AJMER       0.00      0.00      0.00        13\n",
      "               AKOLA       0.00      0.00      0.00        13\n",
      "            ALAPUZHA       0.00      0.00      0.00        13\n",
      "             ALIGARH       0.00      0.00      0.00        13\n",
      "           ALIRAJPUR       0.00      0.00      0.00         6\n",
      "           ALLAHABAD       0.00      0.00      0.00        13\n",
      "              ALMORA       0.00      0.00      0.00        13\n",
      "               ALWAR       0.00      0.00      0.00        13\n",
      "              AMBALA       0.00      0.00      0.00        11\n",
      "        AMBALA RURAL       0.00      0.00      0.00         2\n",
      "        AMBALA URBAN       0.00      0.00      0.00         2\n",
      "      AMBEDKAR NAGAR       0.00      0.00      0.00        13\n",
      "              AMETHI       0.00      0.00      0.00         1\n",
      "     AMRAVATI COMMR.       0.00      0.00      0.00        13\n",
      "      AMRAVATI RURAL       0.00      0.00      0.00        13\n",
      "              AMRELI       0.00      0.00      0.00        13\n",
      "            AMRITSAR       0.00      0.00      0.00        10\n",
      "      AMRITSAR RURAL       0.00      0.00      0.00         6\n",
      "              AMROHA       0.00      0.00      0.00         1\n",
      "               ANAND       0.00      0.00      0.00        13\n",
      "           ANANTAPUR       0.00      0.00      0.00        13\n",
      "            ANANTNAG       0.00      0.00      0.00        13\n",
      "             ANDAMAN       0.00      0.00      0.00        10\n",
      "               ANGUL       0.00      0.00      0.00        13\n",
      "               ANJAW       0.00      0.00      0.00         5\n",
      "             ANUPPUR       0.00      0.00      0.00        11\n",
      "              ARARIA       0.00      0.00      0.00        13\n",
      "            ARIYALUR       0.00      0.00      0.00         6\n",
      "               ARWAL       0.00      0.00      0.00        13\n",
      "             ASANSOL       0.00      0.00      0.00        13\n",
      "         ASHOK NAGAR       0.00      0.00      0.00        11\n",
      "             AURAIYA       0.00      0.00      0.00        13\n",
      "          AURANGABAD       0.00      0.00      0.00        13\n",
      "   AURANGABAD COMMR.       0.00      0.00      0.00        13\n",
      "    AURANGABAD RURAL       0.00      0.00      0.00        13\n",
      "          AWANTIPORA       0.00      0.00      0.00        13\n",
      "            AZAMGARH       0.00      0.00      0.00        13\n",
      "              BADAUN       0.00      0.00      0.00        13\n",
      "     BADDIPOLICEDIST       0.00      0.00      0.00         5\n",
      "              BAGAHA       0.00      0.00      0.00        13\n",
      "            BAGALKOT       0.00      0.00      0.00        13\n",
      "           BAGESHWAR       0.00      0.00      0.00        13\n",
      "             BAGHPAT       0.00      0.00      0.00        13\n",
      "            BAHRAICH       0.00      0.00      0.00        13\n",
      "               BAKSA       0.00      0.00      0.00         2\n",
      "            BALAGHAT       0.00      0.00      0.00        13\n",
      "            BALASORE       0.00      0.00      0.00        13\n",
      "              BALLIA       0.00      0.00      0.00        13\n",
      "               BALOD       0.00      0.00      0.00         2\n",
      "        BALODA BAZAR       0.00      0.00      0.00         2\n",
      "           BALRAMPUR       0.00      0.00      0.00        26\n",
      "               BANDA       0.00      0.00      0.00        13\n",
      "           BANDIPORA       0.00      0.00      0.00         6\n",
      "    BANGALORE COMMR.       0.00      0.00      0.00        13\n",
      "     BANGALORE RURAL       0.00      0.00      0.00        13\n",
      "               BANKA       0.00      0.00      0.00        13\n",
      "             BANKURA       0.00      0.00      0.00        13\n",
      "            BANSWARA       0.00      0.00      0.00        13\n",
      "           BARABANKI       0.00      0.00      0.00        13\n",
      "            BARAGARH       0.00      0.00      0.00        13\n",
      "           BARAMULLA       0.00      0.00      0.00        13\n",
      "               BARAN       0.00      0.00      0.00        13\n",
      "            BAREILLY       0.00      0.00      0.00        13\n",
      "              BARMER       0.00      0.00      0.00        13\n",
      "             BARNALA       0.00      0.00      0.00        13\n",
      "             BARPETA       0.00      0.00      0.00        13\n",
      "             BARWANI       0.00      0.00      0.00        13\n",
      "               BASKA       0.00      0.00      0.00         7\n",
      "               BASTI       0.00      0.00      0.00        13\n",
      "              BATALA       0.00      0.00      0.00        13\n",
      "              BDN CP       0.00      0.00      0.00         2\n",
      "                BEED       0.00      0.00      0.00        13\n",
      "           BEGUSARAI       0.00      0.00      0.00        13\n",
      "             BELGAUM       0.00      0.00      0.00        13\n",
      "             BELLARY       0.00      0.00      0.00        13\n",
      "            BEMETARA       0.00      0.00      0.00         2\n",
      "           BERHAMPUR       0.00      0.00      0.00        13\n",
      "             BETTIAH       0.00      0.00      0.00        13\n",
      "               BETUL       0.00      0.00      0.00        13\n",
      "             BHABHUA       0.00      0.00      0.00        13\n",
      "             BHADRAK       0.00      0.00      0.00        13\n",
      "           BHAGALPUR       0.00      0.00      0.00        13\n",
      "            BHANDARA       0.00      0.00      0.00        13\n",
      "           BHARATPUR       0.00      0.00      0.00        13\n",
      "             BHARUCH       0.00      0.00      0.00        13\n",
      "            BHATINDA       0.00      0.00      0.00        13\n",
      "           BHAVNAGAR       0.00      0.00      0.00        13\n",
      "            BHILWARA       0.00      0.00      0.00        13\n",
      "          BHIM NAGAR       0.00      0.00      0.00         2\n",
      "               BHIND       0.00      0.00      0.00        13\n",
      "             BHIWANI       0.00      0.00      0.00        13\n",
      "             BHOJPUR       0.00      0.00      0.00        13\n",
      "              BHOPAL       0.00      0.00      0.00        13\n",
      "         BHOPAL RLY.       0.00      0.00      0.00        13\n",
      "               BIDAR       0.00      0.00      0.00        13\n",
      "                BIEO       0.00      0.00      0.00         2\n",
      "             BIJAPUR       0.00      0.00      0.00        13\n",
      "              BIJNOR       0.00      0.00      0.00        13\n",
      "             BIKANER       0.00      0.00      0.00        13\n",
      "            BILASPUR       0.00      0.00      0.00        26\n",
      "             BIRBHUM       0.00      0.00      0.00        13\n",
      "           BISHNUPUR       0.00      0.00      0.00        13\n",
      "             BIZAPUR       0.00      0.00      0.00        13\n",
      "              BKP CP       0.00      0.00      0.00         2\n",
      "              BOKARO       0.00      0.00      0.00        13\n",
      "            BOLANGIR       0.00      0.00      0.00        13\n",
      "          BONGAIGAON       0.00      0.00      0.00        13\n",
      "              BORDER       0.00      0.00      0.00         5\n",
      "     BORDER DISTRICT       0.00      0.00      0.00         2\n",
      "               BOUDH       0.00      0.00      0.00        13\n",
      "              BUDGAM       0.00      0.00      0.00        13\n",
      "        BULANDSHAHAR       0.00      0.00      0.00        13\n",
      "            BULDHANA       0.00      0.00      0.00        13\n",
      "               BUNDI       0.00      0.00      0.00        13\n",
      "             BURDWAN       0.00      0.00      0.00        13\n",
      "           BURHANPUR       0.00      0.00      0.00        11\n",
      "               BUXAR       0.00      0.00      0.00        13\n",
      "              C.I.D.       0.00      0.00      0.00        13\n",
      "              CACHAR       0.00      0.00      0.00        13\n",
      "                 CAR       0.00      0.00      0.00         2\n",
      "                 CAW       0.00      0.00      0.00         6\n",
      "               CBCID       0.00      0.00      0.00         7\n",
      "              CBPURA       0.00      0.00      0.00         6\n",
      "             CENTRAL       0.00      0.00      0.00        13\n",
      "            CHAIBASA       0.00      0.00      0.00        13\n",
      "       CHAMARAJNAGAR       0.00      0.00      0.00        13\n",
      "              CHAMBA       0.00      0.00      0.00        13\n",
      "             CHAMOLI       0.00      0.00      0.00        13\n",
      "           CHAMPAWAT       0.00      0.00      0.00        13\n",
      "            CHAMPHAI       0.10      1.00      0.19        13\n",
      "             CHANDEL       0.00      0.00      0.00        13\n",
      "          CHANDIGARH       0.00      0.00      0.00        13\n",
      "            CHANDOLI       0.00      0.00      0.00        13\n",
      "          CHANDRAPUR       0.00      0.00      0.00        13\n",
      "           CHANGLANG       0.00      0.00      0.00        13\n",
      "              CHATRA       0.00      0.00      0.00        13\n",
      "             CHENGAI       0.00      0.00      0.00         4\n",
      "             CHENNAI       0.00      0.00      0.00        13\n",
      "        CHENNAI RLY.       0.00      0.00      0.00        13\n",
      "     CHENNAISUBURBAN       0.00      0.00      0.00         3\n",
      "          CHHATARPUR       0.00      0.00      0.00        13\n",
      "          CHHINDWARA       0.00      0.00      0.00        13\n",
      "        CHICKMAGALUR       0.00      0.00      0.00        13\n",
      "             CHIRANG       0.00      0.00      0.00         9\n",
      "         CHITRADURGA       0.00      0.00      0.00        13\n",
      "     CHITRAKOOT DHAM       0.00      0.00      0.00        13\n",
      "            CHITTOOR       0.00      0.00      0.00        13\n",
      "         CHITTORGARH       0.00      0.00      0.00        13\n",
      "       CHURACHANDPUR       0.00      0.00      0.00        13\n",
      "               CHURU       0.00      0.00      0.00        13\n",
      "                 CID       0.00      0.00      0.00        11\n",
      "           CID CRIME       0.00      0.00      0.00         4\n",
      "    COIMBATORE RURAL       0.00      0.00      0.00        13\n",
      "    COIMBATORE URBAN       0.00      0.00      0.00        13\n",
      "          COOCHBEHAR       0.00      0.00      0.00        13\n",
      "         CP AMRITSAR       0.00      0.00      0.00         4\n",
      "        CP JALANDHAR       0.00      0.00      0.00         4\n",
      "         CP LUDHIANA       0.00      0.00      0.00         4\n",
      "        CRIME BRANCH       0.00      0.00      0.00         6\n",
      "         CRIME JAMMU       0.00      0.00      0.00        13\n",
      "       CRIME KASHMIR       0.00      0.00      0.00         1\n",
      "      CRIME SRINAGAR       0.00      0.00      0.00        12\n",
      "           CSM NAGAR       0.00      0.00      0.00         3\n",
      "           CUDDALORE       0.00      0.00      0.00        13\n",
      "            CUDDAPAH       0.00      0.00      0.00        13\n",
      "             CUTTACK       0.00      0.00      0.00        13\n",
      "           CYBERABAD       0.00      0.00      0.00        11\n",
      "      D and N HAVELI       0.00      0.00      0.00        12\n",
      "          D&N HAVELI       0.00      0.00      0.00         1\n",
      "               DAHOD       0.00      0.00      0.00        13\n",
      "    DAKSHIN DINAJPUR       0.00      0.00      0.00        13\n",
      "     DAKSHIN KANNADA       0.00      0.00      0.00        13\n",
      "               DAMAN       0.00      0.00      0.00        13\n",
      "               DAMOH       0.00      0.00      0.00        13\n",
      "           DANTEWADA       0.00      0.00      0.00         2\n",
      "           DANTEWARA       0.00      0.00      0.00        11\n",
      "           DARBHANGA       0.00      0.00      0.00        13\n",
      "          DARJEELING       0.00      0.00      0.00        13\n",
      "             DARRANG       0.00      0.00      0.00        13\n",
      "              DATIYA       0.00      0.00      0.00        13\n",
      "               DAUSA       0.00      0.00      0.00        13\n",
      "          DAVANAGERE       0.00      0.00      0.00        13\n",
      "            DCP BBSR       0.00      0.00      0.00         6\n",
      "             DCP CTC       0.00      0.00      0.00         6\n",
      "            DEHRADUN       0.00      0.00      0.00        13\n",
      "      DELHI UT TOTAL       0.00      0.00      0.00         6\n",
      "             DEOGARH       0.00      0.00      0.00        13\n",
      "             DEOGHAR       0.00      0.00      0.00        13\n",
      "              DEORIA       0.00      0.00      0.00        13\n",
      "               DEWAS       0.00      0.00      0.00        13\n",
      "              DHALAI       0.15      1.00      0.26        13\n",
      "            DHAMTARI       0.00      0.00      0.00        13\n",
      "             DHANBAD       0.00      0.00      0.00        13\n",
      "        DHANBAD RLY.       0.00      0.00      0.00        13\n",
      "                DHAR       0.00      0.00      0.00        13\n",
      "          DHARMAPURI       0.00      0.00      0.00        13\n",
      "      DHARWAD COMMR.       0.00      0.00      0.00        13\n",
      "       DHARWAD RURAL       0.00      0.00      0.00        13\n",
      "             DHEMAJI       0.00      0.00      0.00        13\n",
      "           DHENKANAL       0.00      0.00      0.00        13\n",
      "             DHOLPUR       0.00      0.00      0.00        13\n",
      "              DHUBRI       0.00      0.00      0.00        13\n",
      "               DHULE       0.00      0.00      0.00        13\n",
      "       DIBANG VALLEY       0.00      0.00      0.00        13\n",
      "           DIBRUGARH       0.00      0.00      0.00        13\n",
      "             DIMAPUR       0.00      0.00      0.00        13\n",
      "            DINDIGUL       0.00      0.00      0.00        13\n",
      "             DINDORI       0.00      0.00      0.00        13\n",
      "              DISCOM       0.00      0.00      0.00         1\n",
      "                 DIU       0.00      0.00      0.00        13\n",
      "                DODA       0.00      0.00      0.00        13\n",
      "                 DRP       0.00      0.00      0.00         1\n",
      "               DUMKA       0.00      0.00      0.00        13\n",
      "           DUNGARPUR       0.00      0.00      0.00        13\n",
      "                DURG       0.00      0.00      0.00        13\n",
      "                EAST       0.00      0.00      0.00        26\n",
      "       EAST GODAVARI       0.00      0.00      0.00        13\n",
      "                 EOW       0.00      0.00      0.00         6\n",
      "           ERNAKULAM       0.00      0.00      0.00         2\n",
      "    ERNAKULAM COMMR.       0.00      0.00      0.00        11\n",
      "     ERNAKULAM RURAL       0.00      0.00      0.00        11\n",
      "               ERODE       0.00      0.00      0.00        13\n",
      "                ETAH       0.00      0.00      0.00        13\n",
      "              ETAWAH       0.00      0.00      0.00        13\n",
      "            FAIZABAD       0.00      0.00      0.00        13\n",
      "           FARIDABAD       0.00      0.00      0.00        13\n",
      "            FARIDKOT       0.00      0.00      0.00        13\n",
      "           FATEHABAD       0.00      0.00      0.00        13\n",
      "           FATEHGARH       0.00      0.00      0.00        13\n",
      "     FATEHGARH SAHIB       0.00      0.00      0.00        13\n",
      "            FATEHPUR       0.00      0.00      0.00        13\n",
      "             FAZILKA       0.00      0.00      0.00         3\n",
      "           FEROZEPUR       0.00      0.00      0.00         3\n",
      "            FEROZPUR       0.00      0.00      0.00        10\n",
      "           FIROZABAD       0.00      0.00      0.00        13\n",
      "               G.R.P       0.00      0.00      0.00        13\n",
      "              G.R.P.       0.01      0.18      0.02        49\n",
      "        G.R.P. AJMER       0.00      0.00      0.00         1\n",
      "      G.R.P. JODHPUR       0.00      0.00      0.00         1\n",
      "         G.R.P.(RLY)       0.00      0.00      0.00         2\n",
      "         G.R.P.AJMER       0.00      0.00      0.00         3\n",
      "       G.R.P.JODHPUR       0.00      0.00      0.00         3\n",
      "               GADAG       0.00      0.00      0.00        13\n",
      "          GADCHIROLI       0.00      0.00      0.00        13\n",
      "            GAJAPATI       0.00      0.00      0.00        13\n",
      "           GANDERBAL       0.00      0.00      0.00        13\n",
      "         GANDHINAGAR       0.00      0.00      0.00        13\n",
      "          GANGANAGAR       0.00      0.00      0.00        13\n",
      "              GANJAM       0.00      0.00      0.00        13\n",
      "              GARHWA       0.00      0.00      0.00        13\n",
      "          GARIYABAND       0.00      0.00      0.00         3\n",
      "     GARO HILLS EAST       0.00      0.00      0.00        13\n",
      "    GARO HILLS NORTH       0.00      0.00      0.00         1\n",
      "    GARO HILLS SOUTH       0.00      0.00      0.00        13\n",
      " GARO HILLS SOUTH W.       0.00      0.00      0.00         1\n",
      "     GARO HILLS WEST       0.00      0.00      0.00        13\n",
      "    GAUTAMBUDH NAGAR       0.00      0.00      0.00        13\n",
      "                GAYA       0.00      0.00      0.00        13\n",
      "           GHAZIABAD       0.00      0.00      0.00        13\n",
      "            GHAZIPUR       0.00      0.00      0.00        13\n",
      "             GIRIDIH       0.00      0.00      0.00        13\n",
      "            GOALPARA       0.00      0.00      0.00        13\n",
      "               GODDA       0.00      0.00      0.00        13\n",
      "            GOLAGHAT       0.00      0.00      0.00        13\n",
      "              GOMATI       0.00      0.00      0.00         2\n",
      "               GONDA       0.00      0.00      0.00        13\n",
      "              GONDIA       0.00      0.00      0.00        13\n",
      "           GOPALGANJ       0.00      0.00      0.00        13\n",
      "           GORAKHPUR       0.00      0.00      0.00        13\n",
      "                 GRP       0.00      0.00      0.00        16\n",
      "          GRP RAIPUR       0.00      0.00      0.00        13\n",
      "            GRP(RLY)       0.00      0.00      0.00         9\n",
      "            GULBARGA       0.00      0.00      0.00        13\n",
      "              GUMALA       0.00      0.00      0.00         1\n",
      "               GUMLA       0.00      0.00      0.00        12\n",
      "                GUNA       0.00      0.00      0.00        13\n",
      "       GUNTAKAL RLY.       0.00      0.00      0.00        13\n",
      "              GUNTUR       0.00      0.00      0.00        13\n",
      "        GUNTUR URBAN       0.00      0.00      0.00         4\n",
      "           GURDASPUR       0.00      0.00      0.00        13\n",
      "             GURGAON       0.00      0.00      0.00        13\n",
      "       GUWAHATI CITY       0.00      0.00      0.00        13\n",
      "             GWALIOR       0.00      0.00      0.00        13\n",
      "          HAILAKANDI       0.00      0.00      0.00        13\n",
      "            HAMIRPUR       0.00      0.00      0.00        26\n",
      "              HAMREN       0.00      0.00      0.00         2\n",
      "            HANDWARA       0.00      0.00      0.00        12\n",
      "         HANUMANGARH       0.00      0.00      0.00        13\n",
      "               HAPUR       0.00      0.00      0.00         1\n",
      "               HARDA       0.00      0.00      0.00        13\n",
      "              HARDOI       0.00      0.00      0.00        13\n",
      "            HARIDWAR       0.00      0.00      0.00        13\n",
      "              HASSAN       0.00      0.00      0.00        13\n",
      "             HATHRAS       0.00      0.00      0.00        13\n",
      "              HAVERI       0.00      0.00      0.00        13\n",
      "          HAZARIBAGH       0.00      0.00      0.00        13\n",
      "          HIMATNAGAR       0.00      0.00      0.00        13\n",
      "             HINGOLI       0.00      0.00      0.00        13\n",
      "               HISAR       0.00      0.00      0.00         1\n",
      "              HISSAR       0.00      0.00      0.00        12\n",
      "             HOOGHLY       0.00      0.00      0.00        13\n",
      "         HOSHANGABAD       0.00      0.00      0.00        13\n",
      "          HOSHIARPUR       0.00      0.00      0.00        13\n",
      "              HOWRAH       0.00      0.00      0.00        13\n",
      "         HOWRAH CITY       0.00      0.00      0.00         8\n",
      "       HOWRAH G.R.P.       0.00      0.00      0.00        13\n",
      "      HYDERABAD CITY       0.00      0.00      0.00        13\n",
      "         I&P HARYANA       0.00      0.00      0.00         1\n",
      "      I.G.I. AIRPORT       0.00      0.00      0.00         2\n",
      "       I.G.I.AIRPORT       0.00      0.00      0.00         1\n",
      "              IDUKKI       0.00      0.00      0.00        13\n",
      "         IGI AIRPORT       0.00      0.00      0.00        11\n",
      "         IMPHAL EAST       0.00      0.00      0.00         8\n",
      "         IMPHAL WEST       0.00      0.00      0.00         8\n",
      "        IMPHAL(EAST)       0.00      0.00      0.00         5\n",
      "        IMPHAL(WEST)       0.00      0.00      0.00         5\n",
      "              INDORE       0.00      0.00      0.00        13\n",
      "         INDORE RLY.       0.00      0.00      0.00        13\n",
      "           J.P.NAGAR       0.00      0.00      0.00        12\n",
      "            JABALPUR       0.00      0.00      0.00        13\n",
      "       JABALPUR RLY.       0.00      0.00      0.00        13\n",
      "       JAGATSINGHPUR       0.00      0.00      0.00        13\n",
      "           JAGDALPUR       0.00      0.00      0.00        13\n",
      "             JAGRAON       0.00      0.00      0.00         7\n",
      "       JAINTIA HILLS       0.00      0.00      0.00        12\n",
      "  JAINTIA HILLS EAST       0.00      0.00      0.00         1\n",
      "  JAINTIA HILLS WEST       0.00      0.00      0.00         1\n",
      "              JAIPUR       0.00      0.00      0.00         5\n",
      "         JAIPUR EAST       0.00      0.00      0.00         8\n",
      "        JAIPUR NORTH       0.00      0.00      0.00         8\n",
      "        JAIPUR RURAL       0.00      0.00      0.00         8\n",
      "        JAIPUR SOUTH       0.00      0.00      0.00         8\n",
      "         JAIPUR WEST       0.00      0.00      0.00         3\n",
      "           JAISALMER       0.00      0.00      0.00        13\n",
      "              JAJPUR       0.00      0.00      0.00        13\n",
      "           JALANDHAR       0.00      0.00      0.00        10\n",
      "     JALANDHAR RURAL       0.00      0.00      0.00         3\n",
      "              JALAUN       0.00      0.00      0.00        13\n",
      "             JALGAON       0.00      0.00      0.00        13\n",
      "               JALNA       0.00      0.00      0.00        13\n",
      "              JALORE       0.00      0.00      0.00        13\n",
      "          JALPAIGURI       0.00      0.00      0.00        13\n",
      "       JAMALPUR RLY.       0.00      0.00      0.00        13\n",
      "               JAMMU       0.00      0.00      0.00        13\n",
      "            JAMNAGAR       0.00      0.00      0.00        13\n",
      "          JAMSHEDPUR       0.00      0.00      0.00        13\n",
      "     JAMSHEDPUR RLY.       0.00      0.00      0.00        13\n",
      "             JAMTARA       0.00      0.00      0.00        13\n",
      "               JAMUI       0.00      0.00      0.00        13\n",
      "             JANJGIR       0.00      0.00      0.00        13\n",
      "             JASHPUR       0.00      0.00      0.00        13\n",
      "             JAUNPUR       0.00      0.00      0.00        13\n",
      "           JEHANABAD       0.00      0.00      0.00        13\n",
      "              JHABUA       0.00      0.00      0.00        13\n",
      "             JHAJJAR       0.00      0.00      0.00        13\n",
      "            JHALAWAR       0.00      0.00      0.00        13\n",
      "              JHANSI       0.00      0.00      0.00        13\n",
      "            JHARGRAM       0.00      0.00      0.00         2\n",
      "          JHARSUGUDA       0.00      0.00      0.00        13\n",
      "           JHUNJHUNU       0.00      0.00      0.00        13\n",
      "                JIND       0.00      0.00      0.00        13\n",
      "             JODHPUR       0.00      0.00      0.00         5\n",
      "        JODHPUR CITY       0.00      0.00      0.00         6\n",
      "        JODHPUR EAST       0.00      0.00      0.00         2\n",
      "       JODHPUR RURAL       0.00      0.00      0.00         8\n",
      "        JODHPUR WEST       0.00      0.00      0.00         2\n",
      "              JORHAT       0.00      0.00      0.00        13\n",
      "            JUNAGADH       0.00      0.00      0.00        13\n",
      "              K.G.F.       0.00      0.00      0.00        13\n",
      "             K/KUMEY       0.00      0.00      0.00        11\n",
      "           KABIRDHAM       0.00      0.00      0.00        12\n",
      "             KAITHAL       0.00      0.00      0.00        13\n",
      "           KALAHANDI       0.00      0.00      0.00        13\n",
      "         KAMENG EAST       0.00      0.00      0.00        13\n",
      "         KAMENG WEST       0.00      0.00      0.00        13\n",
      "              KAMRUP       0.00      0.00      0.00        13\n",
      "         KANCHIPURAM       0.00      0.00      0.00        13\n",
      "           KANDHAMAL       0.00      0.00      0.00        13\n",
      "              KANGRA       0.00      0.00      0.00        13\n",
      "              KANKER       0.00      0.00      0.00        13\n",
      "             KANNAUJ       0.00      0.00      0.00        13\n",
      "              KANNUR       0.00      0.00      0.00        13\n",
      "        KANPUR DEHAT       0.00      0.00      0.00        10\n",
      "        KANPUR NAGAR       0.00      0.00      0.00        13\n",
      "     KANSHIRAM NAGAR       0.00      0.00      0.00         5\n",
      "         KANYAKUMARI       0.00      0.00      0.00        13\n",
      "          KAPURTHALA       0.00      0.00      0.00        13\n",
      "            KARAIKAL       0.00      0.00      0.00         8\n",
      "             KARAULI       0.00      0.00      0.00        13\n",
      "       KARBI ANGLONG       0.00      0.00      0.00        13\n",
      "              KARGIL       0.00      0.00      0.00        13\n",
      "           KARIMGANJ       0.00      0.00      0.00        13\n",
      "          KARIMNAGAR       0.00      0.00      0.00        13\n",
      "              KARNAL       0.00      0.00      0.00        13\n",
      "               KARUR       0.00      0.00      0.00        13\n",
      "            KASARGOD       0.00      0.00      0.00        13\n",
      "             KASGANJ       0.00      0.00      0.00         1\n",
      "              KATHUA       0.00      0.00      0.00        13\n",
      "             KATIHAR       0.00      0.00      0.00        13\n",
      "        KATIHAR RLY.       0.00      0.00      0.00        13\n",
      "               KATNI       0.00      0.00      0.00        13\n",
      "           KAUSHAMBI       0.00      0.00      0.00        13\n",
      "            KAWARDHA       0.00      0.00      0.00         1\n",
      "          KENDRAPARA       0.00      0.00      0.00        13\n",
      "            KEONJHAR       0.00      0.00      0.00        13\n",
      "            KHAGARIA       0.00      0.00      0.00        13\n",
      "             KHAMMAM       0.00      0.00      0.00        13\n",
      "             KHANDWA       0.00      0.00      0.00        13\n",
      "              KHANNA       0.00      0.00      0.00        13\n",
      "    KHARAGPUR G.R.P.       0.00      0.00      0.00        12\n",
      "             KHARGON       0.00      0.00      0.00        13\n",
      "    KHASI HILLS EAST       0.00      0.00      0.00        13\n",
      "KHASI HILLS SOUTH W.       0.00      0.00      0.00         1\n",
      "    KHASI HILLS WEST       0.00      0.00      0.00        13\n",
      "         KHEDA NORTH       0.00      0.00      0.00        13\n",
      "               KHIRI       0.00      0.00      0.00        13\n",
      "              KHOWAI       0.00      0.00      0.00         2\n",
      "              KHUNTI       0.00      0.00      0.00         7\n",
      "              KHURDA       0.00      0.00      0.00        13\n",
      "             KINNAUR       0.00      0.00      0.00        13\n",
      "             KIPHIRE       0.00      0.00      0.00        13\n",
      "          KISHANGANJ       0.00      0.00      0.00        13\n",
      "            KISHTWAR       0.00      0.00      0.00         6\n",
      "              KODAGU       0.00      0.00      0.00        13\n",
      "             KODERMA       0.00      0.00      0.00        13\n",
      "              KOHIMA       0.00      0.00      0.00        13\n",
      "           KOKRAJHAR       0.00      0.00      0.00        13\n",
      "               KOLAR       0.00      0.00      0.00        13\n",
      "             KOLASIB       0.00      0.00      0.00        13\n",
      "            KOLHAPUR       0.00      0.00      0.00        13\n",
      "             KOLKATA       0.00      0.00      0.00        13\n",
      "              KOLLAM       0.00      0.00      0.00        10\n",
      "       KOLLAM COMMR.       0.00      0.00      0.00         3\n",
      "        KOLLAM RURAL       0.00      0.00      0.00         3\n",
      "           KONDAGAON       0.00      0.00      0.00         2\n",
      "              KOPPAL       0.00      0.00      0.00        13\n",
      "             KORAPUT       0.00      0.00      0.00        13\n",
      "               KORBA       0.00      0.00      0.00        13\n",
      "              KORIYA       0.00      0.00      0.00        13\n",
      "                KOTA       0.00      0.00      0.00         5\n",
      "           KOTA CITY       0.00      0.00      0.00         8\n",
      "          KOTA RURAL       0.00      0.00      0.00         8\n",
      "            KOTTAYAM       0.00      0.00      0.00        13\n",
      "           KOZHIKODE       0.00      0.00      0.00         2\n",
      "    KOZHIKODE COMMR.       0.00      0.00      0.00        11\n",
      "     KOZHIKODE RURAL       0.00      0.00      0.00        11\n",
      "             KRISHNA       0.00      0.00      0.00        13\n",
      "         KRISHNAGIRI       0.00      0.00      0.00        10\n",
      "              KULGAM       0.00      0.00      0.00        13\n",
      "               KULLU       0.00      0.00      0.00        13\n",
      "             KUPWARA       0.00      0.00      0.00        13\n",
      "             KURNOOL       0.00      0.00      0.00        13\n",
      "         KURUKSHETRA       0.00      0.00      0.00        13\n",
      "         KUSHI NAGAR       0.00      0.00      0.00        13\n",
      "               KUTCH       0.00      0.00      0.00        10\n",
      "     KUTCH (EAST(G))       0.00      0.00      0.00         3\n",
      "   KUTCH (WEST-BHUJ)       0.00      0.00      0.00         3\n",
      "        LAHAUL-SPITI       0.00      0.00      0.00        13\n",
      "           LAKHIMPUR       0.00      0.00      0.00        13\n",
      "          LAKHISARAI       0.00      0.00      0.00        13\n",
      "         LAKSHADWEEP       0.00      0.00      0.00        13\n",
      "            LALITPUR       0.00      0.00      0.00        13\n",
      "             LATEHAR       0.00      0.00      0.00        13\n",
      "               LATUR       0.00      0.00      0.00        13\n",
      "           LAWNGTLAI       0.00      0.00      0.00        13\n",
      "                 LEH       0.00      0.00      0.00        13\n",
      "          LOHARDAGGA       0.00      0.00      0.00        13\n",
      "               LOHIT       0.00      0.00      0.00        13\n",
      "            LONGDING       0.00      0.00      0.00         1\n",
      "            LONGLENG       0.00      0.00      0.00         7\n",
      "             LUCKNOW       0.00      0.00      0.00        13\n",
      "            LUDHIANA       0.00      0.00      0.00        10\n",
      "      LUDHIANA RURAL       0.00      0.00      0.00         5\n",
      "             LUNGLEI       0.00      0.00      0.00        13\n",
      "           MADHEPURA       0.00      0.00      0.00        13\n",
      "           MADHUBANI       0.00      0.00      0.00        13\n",
      "       MADURAI RURAL       0.00      0.00      0.00        13\n",
      "       MADURAI URBAN       0.00      0.00      0.00        13\n",
      "       MAHABOOBNAGAR       0.00      0.00      0.00        13\n",
      "         MAHARAJGANJ       0.00      0.00      0.00        13\n",
      "          MAHASAMUND       0.00      0.00      0.00        13\n",
      "        MAHENDERGARH       0.00      0.00      0.00         1\n",
      "        MAHENDRAGARH       0.00      0.00      0.00        12\n",
      "              MAHOBA       0.00      0.00      0.00        13\n",
      "            MAINPURI       0.00      0.00      0.00        13\n",
      "             MAJITHA       0.00      0.00      0.00         6\n",
      "          MALAPPURAM       0.00      0.00      0.00        13\n",
      "               MALDA       0.00      0.00      0.00        13\n",
      "           MALKANGIR       0.00      0.00      0.00        13\n",
      "               MAMIT       0.00      0.00      0.00        13\n",
      "               MANDI       0.00      0.00      0.00        13\n",
      "              MANDLA       0.00      0.00      0.00        13\n",
      "            MANDSAUR       0.00      0.00      0.00        13\n",
      "              MANDYA       0.00      0.00      0.00        13\n",
      "      MANGALORE CITY       0.00      0.00      0.00         3\n",
      "               MANSA       0.00      0.00      0.00        13\n",
      "             MATHURA       0.00      0.00      0.00        13\n",
      "                 MAU       0.00      0.00      0.00        13\n",
      "          MAYURBHANJ       0.00      0.00      0.00        13\n",
      "               MEDAK       0.00      0.00      0.00        13\n",
      "              MEERUT       0.00      0.00      0.00        13\n",
      "             MEHSANA       0.00      0.00      0.00        13\n",
      "          METRO RAIL       0.00      0.00      0.00         1\n",
      "               MEWAT       0.00      0.00      0.00         9\n",
      "            MIDNAPUR       0.00      0.00      0.00         1\n",
      "            MIRZAPUR       0.00      0.00      0.00        13\n",
      "                MOGA       0.00      0.00      0.00        13\n",
      "          MOKOKCHUNG       0.00      0.00      0.00        13\n",
      "                 MON       0.00      0.00      0.00        13\n",
      "           MORADABAD       0.00      0.00      0.00        13\n",
      "              MORENA       0.00      0.00      0.00        13\n",
      "            MORIGAON       0.00      0.00      0.00        13\n",
      "            MOTIHARI       0.00      0.00      0.00        13\n",
      "             MUKTSAR       0.00      0.00      0.00        13\n",
      "              MUMBAI       0.00      0.00      0.00         5\n",
      "       MUMBAI COMMR.       0.00      0.00      0.00         8\n",
      "         MUMBAI RLY.       0.00      0.00      0.00        13\n",
      "             MUNGELI       0.00      0.00      0.00         2\n",
      "              MUNGER       0.00      0.00      0.00        13\n",
      "         MURSHIDABAD       0.00      0.00      0.00        13\n",
      "       MUZAFFARNAGAR       0.00      0.00      0.00        13\n",
      "         MUZAFFARPUR       0.00      0.00      0.00        13\n",
      "    MUZAFFARPUR RLY.       0.00      0.00      0.00        13\n",
      "       MYSORE COMMR.       0.00      0.00      0.00        13\n",
      "        MYSORE RURAL       0.00      0.00      0.00        13\n",
      "          N.C. HILLS       0.00      0.00      0.00         1\n",
      "           N.C.HILLS       0.00      0.00      0.00        12\n",
      "               NADIA       0.00      0.00      0.00        13\n",
      "              NAGAON       0.00      0.00      0.00        13\n",
      "        NAGAPATTINAM       0.00      0.00      0.00        13\n",
      "              NAGAUR       0.00      0.00      0.00        13\n",
      "       NAGPUR COMMR.       0.00      0.00      0.00        13\n",
      "         NAGPUR RLY.       0.00      0.00      0.00        13\n",
      "        NAGPUR RURAL       0.00      0.00      0.00        13\n",
      "            NAINITAL       0.00      0.00      0.00        13\n",
      "             NALANDA       0.00      0.00      0.00        13\n",
      "             NALBARI       0.00      0.00      0.00        13\n",
      "            NALGONDA       0.00      0.00      0.00        13\n",
      "            NAMAKKAL       0.00      0.00      0.00        13\n",
      "              NANDED       0.00      0.00      0.00        13\n",
      "           NANDURBAR       0.00      0.00      0.00        13\n",
      "          NARAYANPUR       0.00      0.00      0.00        11\n",
      "             NARMADA       0.00      0.00      0.00        13\n",
      "         NARSINGHPUR       0.00      0.00      0.00        13\n",
      "        NASIK COMMR.       0.00      0.00      0.00        13\n",
      "         NASIK RURAL       0.00      0.00      0.00        13\n",
      "           NAUGACHIA       0.00      0.00      0.00        13\n",
      "         NAVI MUMBAI       0.00      0.00      0.00        13\n",
      "             NAVSARI       0.00      0.00      0.00        13\n",
      "             NAWADAH       0.00      0.00      0.00        13\n",
      "         NAWAN SHAHR       0.00      0.00      0.00         7\n",
      "            NAYAGARH       0.00      0.00      0.00        13\n",
      "             NEEMUCH       0.00      0.00      0.00        13\n",
      "             NELLORE       0.00      0.00      0.00        13\n",
      "           NEW DELHI       0.00      0.00      0.00        13\n",
      "             NICOBAR       0.00      0.00      0.00        10\n",
      "            NILGIRIS       0.00      0.00      0.00        13\n",
      "           NIZAMABAD       0.00      0.00      0.00        13\n",
      "               NORTH       0.04      0.15      0.06        41\n",
      "          NORTH EAST       0.00      0.00      0.00         2\n",
      "           NORTH GOA       0.00      0.00      0.00        13\n",
      "          NORTH WEST       0.00      0.00      0.00         2\n",
      "          NORTH-EAST       0.00      0.00      0.00        11\n",
      "          NORTH-WEST       0.00      0.00      0.00        11\n",
      "          NOWRANGPUR       0.00      0.00      0.00        13\n",
      "             NUAPADA       0.00      0.00      0.00        13\n",
      "           OSMANABAD       0.00      0.00      0.00        13\n",
      "               OUTER       0.00      0.00      0.00         7\n",
      "               PAKUR       0.00      0.00      0.00        13\n",
      "            PALAKKAD       0.00      0.00      0.00        13\n",
      "              PALAMU       0.00      0.00      0.00        13\n",
      "            PALANPUR       0.00      0.00      0.00        13\n",
      "                PALI       0.00      0.00      0.00        13\n",
      "              PALWAL       0.00      0.00      0.00         8\n",
      "           PANCHKULA       0.00      0.00      0.00        13\n",
      "          PANCHMAHAL       0.00      0.00      0.00        13\n",
      "     PANCHSHIL NAGAR       0.00      0.00      0.00         2\n",
      "             PANIPAT       0.00      0.00      0.00        13\n",
      "               PANNA       0.00      0.00      0.00        13\n",
      "          PAPUM PARE       0.00      0.00      0.00        13\n",
      "            PARBHANI       0.00      0.00      0.00        13\n",
      "    PASCHIM MIDNAPUR       0.00      0.00      0.00        12\n",
      "               PATAN       0.00      0.00      0.00        13\n",
      "      PATHANAMTHITTA       0.00      0.00      0.00        13\n",
      "           PATHANKOT       0.00      0.00      0.00         3\n",
      "             PATIALA       0.00      0.00      0.00        13\n",
      "               PATNA       0.00      0.00      0.00        13\n",
      "          PATNA RLY.       0.00      0.00      0.00        13\n",
      "       PAURI GARHWAL       0.00      0.00      0.00        13\n",
      "          PERAMBALUR       0.00      0.00      0.00        13\n",
      "               PEREN       0.00      0.00      0.00        13\n",
      "                PHEK       0.00      0.00      0.00        13\n",
      "            PILIBHIT       0.00      0.00      0.00        13\n",
      "         PITHORAGARH       0.00      0.00      0.00        13\n",
      "         PONDICHERRY       0.00      0.00      0.00         7\n",
      "              POONCH       0.00      0.00      0.00        13\n",
      "           PORBANDAR       0.00      0.00      0.00        13\n",
      "      PRABUDDH NAGAR       0.00      0.00      0.00         2\n",
      "           PRAKASHAM       0.00      0.00      0.00        13\n",
      "          PRATAPGARH       0.00      0.00      0.00        19\n",
      "          PUDUCHERRY       0.00      0.00      0.00         6\n",
      "          PUDUKOTTAI       0.00      0.00      0.00        13\n",
      "             PULWAMA       0.00      0.00      0.00        13\n",
      "         PUNE COMMR.       0.00      0.00      0.00        13\n",
      "           PUNE RLY.       0.00      0.00      0.00        13\n",
      "          PUNE RURAL       0.00      0.00      0.00        13\n",
      "      PURAB MIDNAPUR       0.00      0.00      0.00        12\n",
      "                PURI       0.00      0.00      0.00        13\n",
      "              PURNEA       0.00      0.00      0.00        13\n",
      "             PURULIA       0.00      0.00      0.00        13\n",
      "              R.P.O.       0.00      0.00      0.00        13\n",
      "         RAIBAREILLY       0.00      0.00      0.00        13\n",
      "             RAICHUR       0.00      0.00      0.00        13\n",
      "              RAIGAD       0.00      0.00      0.00        13\n",
      "             RAIGARH       0.00      0.00      0.00        13\n",
      "            RAILWAYS       0.04      0.25      0.06        36\n",
      "      RAILWAYS JAMMU       0.00      0.00      0.00         3\n",
      "    RAILWAYS KASHMIR       0.00      0.00      0.00         3\n",
      "      RAILWAYS KATRA       0.00      0.00      0.00         2\n",
      "        RAILWAYS KMR       0.00      0.00      0.00         1\n",
      "              RAIPUR       0.00      0.00      0.00        13\n",
      "              RAISEN       0.00      0.00      0.00        13\n",
      "         RAJAHMUNDRY       0.00      0.00      0.00         4\n",
      "             RAJGARH       0.00      0.00      0.00        13\n",
      "       RAJKOT COMMR.       0.00      0.00      0.00        13\n",
      "        RAJKOT RURAL       0.00      0.00      0.00        13\n",
      "         RAJNANDGAON       0.00      0.00      0.00        13\n",
      "             RAJOURI       0.00      0.00      0.00        13\n",
      "           RAJSAMAND       0.00      0.00      0.00        13\n",
      "       RAMABAI NAGAR       0.00      0.00      0.00         3\n",
      "           RAMANAGAR       0.00      0.00      0.00         6\n",
      "              RAMBAN       0.00      0.00      0.00        13\n",
      "             RAMGARH       0.00      0.00      0.00         7\n",
      "       RAMNATHAPURAM       0.00      0.00      0.00        13\n",
      "              RAMPUR       0.00      0.00      0.00        13\n",
      "              RANCHI       0.00      0.00      0.00        13\n",
      "         RANGA REDDY       0.00      0.00      0.00        13\n",
      "              RATLAM       0.00      0.00      0.00        13\n",
      "           RATNAGIRI       0.00      0.00      0.00        13\n",
      "            RAYAGADA       0.00      0.00      0.00        13\n",
      "               REASI       0.00      0.00      0.00        13\n",
      "                REWA       0.00      0.00      0.00        13\n",
      "              REWARI       0.00      0.00      0.00        13\n",
      "             RI-BHOI       0.00      0.00      0.00        13\n",
      "              ROHTAK       0.00      0.00      0.00        13\n",
      "              ROHTAS       0.00      0.00      0.00        13\n",
      "               ROPAR       0.00      0.00      0.00        13\n",
      "            ROURKELA       0.00      0.00      0.00        13\n",
      "        RUDRA PRAYAG       0.00      0.00      0.00        13\n",
      "               RURAL       0.00      0.00      0.00         4\n",
      "              S.T.F.       0.00      0.00      0.00         2\n",
      "               SAGAR       0.00      0.00      0.00        13\n",
      "          SAHARANPUR       0.00      0.00      0.00        13\n",
      "             SAHARSA       0.00      0.00      0.00        13\n",
      "           SAHEBGANJ       0.00      0.00      0.00        13\n",
      "               SAIHA       0.00      0.00      0.00        13\n",
      "         SALEM RURAL       0.00      0.00      0.00        13\n",
      "         SALEM URBAN       0.00      0.00      0.00        13\n",
      "          SAMASTIPUR       0.00      0.00      0.00        13\n",
      "               SAMBA       0.00      0.00      0.00         6\n",
      "           SAMBALPUR       0.00      0.00      0.00        13\n",
      "             SAMBHAL       0.00      0.00      0.00         1\n",
      "              SANGLI       0.00      0.00      0.00        13\n",
      "             SANGRUR       0.00      0.00      0.00        13\n",
      "     SANT KABIRNAGAR       0.00      0.00      0.00        13\n",
      "           SARAIKELA       0.00      0.00      0.00        13\n",
      "               SARAN       0.00      0.00      0.00        13\n",
      "             SARGUJA       0.00      0.00      0.00        13\n",
      "             SAS NGR       0.00      0.00      0.00         8\n",
      "              SATARA       0.00      0.00      0.00        13\n",
      "               SATNA       0.00      0.00      0.00        13\n",
      "      SAWAI MADHOPUR       0.00      0.00      0.00        13\n",
      "           SBS NAGAR       0.00      0.00      0.00         6\n",
      "      SEALDAH G.R.P.       0.00      0.00      0.00        13\n",
      "   SECUNDERABAD RLY.       0.00      0.00      0.00        13\n",
      "            SENAPATI       0.00      0.00      0.00        13\n",
      "               SEONI       0.00      0.00      0.00        13\n",
      "            SERCHHIP       0.00      0.00      0.00        13\n",
      "             SHAHDOL       0.00      0.00      0.00        13\n",
      "        SHAHJAHANPUR       0.00      0.00      0.00        13\n",
      "            SHAJAPUR       0.00      0.00      0.00        13\n",
      "              SHAMLI       0.00      0.00      0.00         1\n",
      "          SHEIKHPURA       0.00      0.00      0.00        13\n",
      "             SHEOHAR       0.00      0.00      0.00        13\n",
      "             SHEOPUR       0.00      0.00      0.00        13\n",
      "              SHIMLA       0.00      0.00      0.00        13\n",
      "             SHIMOGA       0.00      0.00      0.00        13\n",
      "            SHIVPURI       0.00      0.00      0.00        13\n",
      "             SHOPIAN       0.00      0.00      0.00         6\n",
      "           SHRAWASTI       0.00      0.00      0.00        13\n",
      "          SIANG EAST       0.00      0.00      0.00        13\n",
      "         SIANG UPPER       0.00      0.00      0.00        13\n",
      "          SIANG WEST       0.00      0.00      0.00        13\n",
      "            SIBSAGAR       0.00      0.00      0.00        13\n",
      "       SIDHARTHNAGAR       0.00      0.00      0.00        13\n",
      "               SIDHI       0.00      0.00      0.00        13\n",
      "              SIHORE       0.00      0.00      0.00        13\n",
      "               SIKAR       0.00      0.00      0.00        13\n",
      "     SILIGURI G.R.P.       0.00      0.00      0.00        13\n",
      "         SILIGURI_PC       0.00      0.00      0.00         2\n",
      "             SIMDEGA       0.00      0.00      0.00        13\n",
      "          SINDHUDURG       0.00      0.00      0.00        13\n",
      "           SINGRAULI       0.00      0.00      0.00         6\n",
      "          SIPAHIJALA       0.00      0.00      0.00         2\n",
      "             SIRMAUR       0.00      0.00      0.00        13\n",
      "              SIROHI       0.00      0.00      0.00        13\n",
      "               SIRSA       0.00      0.00      0.00        13\n",
      "           SITAMARHI       0.00      0.00      0.00        13\n",
      "             SITAPUR       0.00      0.00      0.00        13\n",
      "          SIVAGANGAI       0.00      0.00      0.00        13\n",
      "               SIWAN       0.00      0.00      0.00        13\n",
      "               SOLAN       0.00      0.00      0.00        13\n",
      "      SOLAPUR COMMR.       0.00      0.00      0.00        13\n",
      "       SOLAPUR RURAL       0.00      0.00      0.00        13\n",
      "           SONBHADRA       0.00      0.00      0.00        13\n",
      "             SONEPUR       0.00      0.00      0.00        13\n",
      "             SONIPAT       0.00      0.00      0.00        13\n",
      "            SONITPUR       0.00      0.00      0.00        13\n",
      "              SOPORE       0.00      0.00      0.00         4\n",
      "               SOUTH       0.16      0.24      0.19        41\n",
      "           SOUTH GOA       0.00      0.00      0.00        13\n",
      "          SOUTH WEST       0.00      0.00      0.00         2\n",
      "          SOUTH-EAST       0.00      0.00      0.00         6\n",
      "          SOUTH-WEST       0.00      0.00      0.00        11\n",
      "            SPL CELL       0.00      0.00      0.00         2\n",
      "        SPL NARCOTIC       0.00      0.00      0.00         1\n",
      "          SRIKAKULAM       0.00      0.00      0.00        13\n",
      "            SRINAGAR       0.00      0.00      0.00        13\n",
      "        SRP(CUTTACK)       0.00      0.00      0.00        13\n",
      "       SRP(ROURKELA)       0.00      0.00      0.00        13\n",
      "     ST.RAVIDASNAGAR       0.00      0.00      0.00        13\n",
      "                 STF       0.00      0.00      0.00        11\n",
      "     SUBANSIRI LOWER       0.00      0.00      0.00        13\n",
      "     SUBANSIRI UPPER       0.00      0.00      0.00        13\n",
      "               SUKMA       0.00      0.00      0.00         2\n",
      "           SULTANPUR       0.00      0.00      0.00        13\n",
      "          SUNDARGARH       0.00      0.00      0.00        13\n",
      "              SUPAUL       0.00      0.00      0.00        13\n",
      "            SURAJPUR       0.00      0.00      0.00         9\n",
      "        SURAT COMMR.       0.00      0.00      0.00        13\n",
      "         SURAT RURAL       0.00      0.00      0.00        13\n",
      "       SURENDRANAGAR       0.00      0.00      0.00        13\n",
      "          TAMENGLONG       0.00      0.00      0.00        13\n",
      "                TAPI       0.00      0.00      0.00         6\n",
      "          TARN TARAN       0.00      0.00      0.00        13\n",
      "              TAWANG       0.00      0.00      0.00        13\n",
      "       TEHRI GARHWAL       0.00      0.00      0.00        13\n",
      "        THANE COMMR.       0.00      0.00      0.00        13\n",
      "         THANE RURAL       0.00      0.00      0.00        13\n",
      "           THANJAVUR       0.00      0.00      0.00        13\n",
      "               THENI       0.00      0.00      0.00        13\n",
      "  THIRUNELVELI RURAL       0.00      0.00      0.00        13\n",
      "  THIRUNELVELI URBAN       0.00      0.00      0.00        13\n",
      "         THIRUVALLUR       0.00      0.00      0.00        13\n",
      "     THIRUVANNAMALAI       0.00      0.00      0.00        13\n",
      "          THIRUVARUR       0.00      0.00      0.00        13\n",
      "         THOOTHUGUDI       0.00      0.00      0.00        13\n",
      "             THOUBAL       0.00      0.00      0.00        13\n",
      "            THRISSUR       0.00      0.00      0.00        10\n",
      "     THRISSUR COMMR.       0.00      0.00      0.00         3\n",
      "      THRISSUR RURAL       0.00      0.00      0.00         3\n",
      "           TIKAMGARH       0.00      0.00      0.00        13\n",
      "            TINSUKIA       0.00      0.00      0.00        13\n",
      "               TIRAP       0.00      0.00      0.00        13\n",
      "     TIRUPATHI URBAN       0.00      0.00      0.00         4\n",
      "            TIRUPPUR       0.00      0.00      0.00         5\n",
      "                TONK       0.00      0.00      0.00        13\n",
      "               TOTAL       0.04      0.79      0.08       428\n",
      "          TRAFFIC PS       0.00      0.00      0.00         1\n",
      "         TRICHY RLY.       0.00      0.00      0.00        13\n",
      "        TRICHY RURAL       0.00      0.00      0.00        13\n",
      "        TRICHY URBAN       0.00      0.00      0.00        13\n",
      "          TRIVANDRUM       0.00      0.00      0.00         2\n",
      "   TRIVANDRUM COMMR.       0.00      0.00      0.00        11\n",
      "    TRIVANDRUM RURAL       0.00      0.00      0.00        11\n",
      "            TUENSANG       0.00      0.00      0.00        13\n",
      "              TUMKUR       0.00      0.00      0.00        13\n",
      "             UDAIPUR       0.00      0.00      0.00        13\n",
      "            UDALGURI       0.00      0.00      0.00         9\n",
      "            UDHAMPUR       0.00      0.00      0.00        13\n",
      "    UDHAMSINGH NAGAR       0.00      0.00      0.00        13\n",
      "               UDUPI       0.00      0.00      0.00        13\n",
      "              UJJAIN       0.00      0.00      0.00        13\n",
      "              UKHRUL       0.00      0.00      0.00        13\n",
      "             UMARIYA       0.00      0.00      0.00        13\n",
      "                 UNA       0.00      0.00      0.00        13\n",
      "             UNAKOTI       0.00      0.00      0.00         2\n",
      "               UNNAO       0.00      0.00      0.00        13\n",
      " UPPER DIBANG VALLEY       0.00      0.00      0.00        11\n",
      "      UTTAR DINAJPUR       0.00      0.00      0.00        13\n",
      "       UTTAR KANNADA       0.00      0.00      0.00        13\n",
      "          UTTARKASHI       0.00      0.00      0.00        13\n",
      "     VADODARA COMMR.       0.00      0.00      0.00        13\n",
      "      VADODARA RURAL       0.00      0.00      0.00        13\n",
      "            VAISHALI       0.00      0.00      0.00        13\n",
      "              VALSAD       0.00      0.00      0.00        13\n",
      "            VARANASI       0.00      0.00      0.00        13\n",
      "             VELLORE       0.00      0.00      0.00        13\n",
      "             VIDISHA       0.00      0.00      0.00        13\n",
      "          VIJAYAWADA       0.00      0.00      0.00         5\n",
      "     VIJAYAWADA CITY       0.00      0.00      0.00         8\n",
      "     VIJAYAWADA RLY.       0.00      0.00      0.00        13\n",
      "          VILLUPURAM       0.00      0.00      0.00        12\n",
      "          VILUPPURAM       0.00      0.00      0.00         1\n",
      "        VIRUDHUNAGAR       0.00      0.00      0.00        13\n",
      "       VISAKHA RURAL       0.00      0.00      0.00        13\n",
      "       VISAKHAPATNAM       0.00      0.00      0.00        13\n",
      "        VIZIANAGARAM       0.00      0.00      0.00        13\n",
      "               W.RLY       0.00      0.00      0.00        10\n",
      "     W.RLY AHMEDABAD       0.00      0.00      0.00         3\n",
      "      W.RLY VADODARA       0.00      0.00      0.00         3\n",
      "            WARANGAL       0.00      0.00      0.00        13\n",
      "      WARANGAL URBAN       0.00      0.00      0.00         4\n",
      "              WARDHA       0.00      0.00      0.00        13\n",
      "              WASHIM       0.00      0.00      0.00        13\n",
      "            WAYANADU       0.00      0.00      0.00        13\n",
      "                WEST       0.02      0.03      0.02        39\n",
      "       WEST GODAVARI       0.00      0.00      0.00        13\n",
      "               WOKHA       0.00      0.00      0.00        13\n",
      "             YADGIRI       0.00      0.00      0.00         4\n",
      "         YAMUNANAGAR       0.00      0.00      0.00        13\n",
      "            YAVATMAL       0.00      0.00      0.00        13\n",
      "           ZUNHEBOTO       0.00      0.00      0.00        13\n",
      "            ZZ TOTAL       0.00      0.00      0.00        21\n",
      "\n",
      "            accuracy                           0.04      9839\n",
      "           macro avg       0.00      0.00      0.00      9839\n",
      "        weighted avg       0.00      0.04      0.01      9839\n",
      "\n",
      "\n",
      "🔍 Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "🎲 Sample Predictions with Confidence:\n",
      "\n",
      "Sample 3169:\n",
      "Text: 'uttarakhand...'\n",
      "True Label: UDHAMSINGH NAGAR\n",
      "Predicted: TOTAL (Confidence: 0.065)\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 9137:\n",
      "Text: 'karnataka...'\n",
      "True Label: DHARWAD COMMR.\n",
      "Predicted: TOTAL (Confidence: 0.030)\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 8506:\n",
      "Text: 'maharashtra...'\n",
      "True Label: SOLAPUR COMMR.\n",
      "Predicted: TOTAL (Confidence: 0.021)\n",
      "--------------------------------------------------\n",
      "\n",
      "🔮 Testing model on custom case descriptions:\n",
      "============================================================\n",
      "\n",
      "🔍 Test Case 1:\n",
      "Input: 'A person broke into a house at night and stole valuable items including jewelry and electronics.'\n",
      "Predicted Crime: TOTAL\n",
      "Confidence: 0.309\n",
      "Top 3 predictions:\n",
      "  1. TOTAL: 0.309\n",
      "  2. ZZ TOTAL: 0.014\n",
      "  3. SOUTH: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 2:\n",
      "Input: 'The defendant was found driving under the influence of alcohol with a blood alcohol level of 0.12.'\n",
      "Predicted Crime: TOTAL\n",
      "Confidence: 0.309\n",
      "Top 3 predictions:\n",
      "  1. TOTAL: 0.309\n",
      "  2. ZZ TOTAL: 0.014\n",
      "  3. SOUTH: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 3:\n",
      "Input: 'An individual was caught selling illegal drugs to minors near a school playground.'\n",
      "Predicted Crime: TOTAL\n",
      "Confidence: 0.309\n",
      "Top 3 predictions:\n",
      "  1. TOTAL: 0.309\n",
      "  2. ZZ TOTAL: 0.014\n",
      "  3. SOUTH: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 4:\n",
      "Input: 'The accused physically attacked another person during an argument, causing serious injuries.'\n",
      "Predicted Crime: TOTAL\n",
      "Confidence: 0.309\n",
      "Top 3 predictions:\n",
      "  1. TOTAL: 0.309\n",
      "  2. ZZ TOTAL: 0.014\n",
      "  3. SOUTH: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 5:\n",
      "Input: 'Someone created fake documents to claim insurance money for a car accident that never happened.'\n",
      "Predicted Crime: TOTAL\n",
      "Confidence: 0.309\n",
      "Top 3 predictions:\n",
      "  1. TOTAL: 0.309\n",
      "  2. ZZ TOTAL: 0.014\n",
      "  3. SOUTH: 0.005\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Crime Classification Pipeline Completed!\n",
      "📊 Final Model Summary:\n",
      "   - Dataset Size: 49195 cases\n",
      "   - Crime Categories: 839\n",
      "   - Model Accuracy: 0.0408\n",
      "   - TF-IDF Features: 51\n"
     ]
    }
   ],
   "source": [
    "# Crime Classification using TF-IDF and Logistic Regression\n",
    "# Complete script for data.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Starting Crime Classification Pipeline...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: READ AND MERGE ALL CSV FILES FROM crime/ FOLDER\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_merge_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Read all CSV files from the specified folder and merge them into one DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"📂 Loading CSV files from: {folder_path}\")\n",
    "    \n",
    "    # Get all CSV files in the crime folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    print(f\"📄 Found {len(csv_files)} CSV files:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"   - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Read and combine all CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"   ✅ Loaded {file}: {len(df)} rows\")\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error loading {file}: {e}\")\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"🔗 Combined dataset shape: {combined_df.shape}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Load the data - Update this path to match your system\n",
    "crime_folder = r\"C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\"\n",
    "df = load_and_merge_csv_files(crime_folder)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\n📊 Dataset Overview:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['STATE/UT', 'DISTRICT']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' not found in dataset\")\n",
    "\n",
    "# Display label distribution\n",
    "print(f\"\\n🏷️ Crime Category Distribution:\")\n",
    "print(df['DISTRICT'].value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DATA PREPROCESSING AND CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and preprocess text data\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters and digits (keep only letters and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"\\n🧹 Cleaning and preprocessing text data...\")\n",
    "\n",
    "# Clean the text column\n",
    "df['text_cleaned'] = df['STATE/UT'].apply(clean_text)\n",
    "\n",
    "# Remove rows with missing values in key columns\n",
    "print(f\"🔍 Before cleaning - Total samples: {len(df)}\")\n",
    "print(f\"Missing values in STATE/UT: {df['STATE/UT'].isnull().sum()}\")\n",
    "print(f\"Missing values in DISTRICT: {df['DISTRICT'].isnull().sum()}\")\n",
    "\n",
    "# Drop rows where either STATE/UT or DISTRICT is missing\n",
    "df = df.dropna(subset=['STATE/UT', 'DISTRICT']).reset_index(drop=True)\n",
    "\n",
    "# Remove empty text entries after cleaning\n",
    "df = df[df['text_cleaned'].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ After cleaning: {len(df)} samples remaining\")\n",
    "\n",
    "# Check if we still have enough data\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"No valid data remaining after cleaning!\")\n",
    "\n",
    "# Check class distribution after cleaning\n",
    "print(f\"📊 Districts after cleaning: {df['DISTRICT'].nunique()} unique districts\")\n",
    "district_counts = df['DISTRICT'].value_counts()\n",
    "print(f\"District distribution:\\n{district_counts}\")\n",
    "\n",
    "# Filter out districts with very few samples (less than 2) to avoid stratify issues\n",
    "min_samples = 2\n",
    "districts_to_keep = district_counts[district_counts >= min_samples].index\n",
    "df = df[df['DISTRICT'].isin(districts_to_keep)].reset_index(drop=True)\n",
    "\n",
    "print(f\"📊 After filtering rare districts: {len(df)} samples with {df['DISTRICT'].nunique()} districts\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n📝 Sample data after cleaning:\")\n",
    "print(df[['text_cleaned', 'DISTRICT']].head(3).to_string())\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: SPLIT DATASET INTO TRAINING AND TESTING SETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n✂️ Splitting dataset into training and testing sets...\")\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df['text_cleaned']  # Using STATE/UT as the text feature\n",
    "y = df['DISTRICT']      # Using DISTRICT as the target label\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"🔍 Final check - Missing values in X: {X.isnull().sum()}\")\n",
    "print(f\"🔍 Final check - Missing values in y: {y.isnull().sum()}\")\n",
    "\n",
    "# Check if we have enough samples for each class for stratified split\n",
    "y_counts = y.value_counts()\n",
    "min_class_count = y_counts.min()\n",
    "print(f\"📊 Minimum samples per district: {min_class_count}\")\n",
    "\n",
    "# Adjust stratify parameter based on minimum class count\n",
    "if min_class_count >= 2:\n",
    "    stratify_param = y\n",
    "    print(\"✅ Using stratified split\")\n",
    "else:\n",
    "    stratify_param = None\n",
    "    print(\"⚠️ Using random split (some districts have too few samples for stratified split)\")\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=stratify_param  # Use stratified split only if possible\n",
    ")\n",
    "\n",
    "print(f\"📈 Training set size: {len(X_train)} samples\")\n",
    "print(f\"📉 Testing set size: {len(X_test)} samples\")\n",
    "print(f\"🎯 Number of unique districts: {len(y.unique())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: TEXT VECTORIZATION USING TF-IDF\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔤 Vectorizing text data using TF-IDF...\")\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,     # Limit to top 10,000 features\n",
    "    ngram_range=(1, 2),     # Use both unigrams and bigrams\n",
    "    min_df=2,               # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.95,            # Ignore terms that appear in more than 95% of documents\n",
    "    stop_words='english'    # Remove common English stop words\n",
    ")\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform test data (don't fit again!)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"✅ TF-IDF vectorization completed\")\n",
    "print(f\"📊 Training features shape: {X_train_tfidf.shape}\")\n",
    "print(f\"📊 Testing features shape: {X_test_tfidf.shape}\")\n",
    "print(f\"📚 Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: TRAIN LOGISTIC REGRESSION CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🤖 Training Logistic Regression classifier...\")\n",
    "\n",
    "# Initialize and train the classifier\n",
    "lr_classifier = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,          # Increase max iterations for convergence\n",
    "    C=1.0                   # Regularization strength\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lr_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"✅ Model training completed!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n📈 Evaluating model performance...\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = lr_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Generate detailed classification report\n",
    "print(f\"\\n📋 Detailed Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(f\"\\n🔍 Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Show prediction probabilities for a few test samples\n",
    "print(f\"\\n🎲 Sample Predictions with Confidence:\")\n",
    "sample_indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "for idx in sample_indices:\n",
    "    sample_text = X_test.iloc[idx]\n",
    "    true_label = y_test.iloc[idx]\n",
    "    predicted_label = y_pred[idx]\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = lr_classifier.predict_proba(X_test_tfidf[idx])\n",
    "    max_prob = np.max(probabilities)\n",
    "    \n",
    "    print(f\"\\nSample {idx + 1}:\")\n",
    "    print(f\"Text: '{sample_text[:100]}...'\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {predicted_label} (Confidence: {max_prob:.3f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: TEST MODEL ON CUSTOM CASE DESCRIPTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def predict_crime_category(text_input, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict crime category for a custom text input\n",
    "    \"\"\"\n",
    "    # Clean the input text\n",
    "    cleaned_text = clean_text(text_input)\n",
    "    \n",
    "    # Vectorize the text\n",
    "    text_tfidf = vectorizer.transform([cleaned_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(text_tfidf)[0]\n",
    "    probabilities = model.predict_proba(text_tfidf)[0]\n",
    "    confidence = np.max(probabilities)\n",
    "    \n",
    "    # Get all class probabilities\n",
    "    classes = model.classes_\n",
    "    prob_dict = dict(zip(classes, probabilities))\n",
    "    \n",
    "    return prediction, confidence, prob_dict\n",
    "\n",
    "print(\"\\n🔮 Testing model on custom case descriptions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample custom case descriptions for testing\n",
    "test_cases = [\n",
    "    \"A person broke into a house at night and stole valuable items including jewelry and electronics.\",\n",
    "    \"The defendant was found driving under the influence of alcohol with a blood alcohol level of 0.12.\",\n",
    "    \"An individual was caught selling illegal drugs to minors near a school playground.\",\n",
    "    \"The accused physically attacked another person during an argument, causing serious injuries.\",\n",
    "    \"Someone created fake documents to claim insurance money for a car accident that never happened.\"\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n🔍 Test Case {i}:\")\n",
    "    print(f\"Input: '{test_case}'\")\n",
    "    \n",
    "    prediction, confidence, probabilities = predict_crime_category(\n",
    "        test_case, lr_classifier, tfidf\n",
    "    )\n",
    "    \n",
    "    print(f\"Predicted Crime: {prediction}\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    # Show top 3 most likely categories\n",
    "    sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Top 3 predictions:\")\n",
    "    for j, (crime_type, prob) in enumerate(sorted_probs[:3], 1):\n",
    "        print(f\"  {j}. {crime_type}: {prob:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: INTERACTIVE PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def interactive_crime_prediction():\n",
    "    \"\"\"\n",
    "    Interactive function to test custom inputs\n",
    "    \"\"\"\n",
    "    print(\"\\n🎯 Interactive Crime Prediction\")\n",
    "    print(\"Enter a case description (or 'quit' to exit):\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n📝 Case Description: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"👋 Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if len(user_input.strip()) == 0:\n",
    "            print(\"❌ Please enter a valid case description.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            prediction, confidence, probabilities = predict_crime_category(\n",
    "                user_input, lr_classifier, tfidf\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n🎯 Prediction Results:\")\n",
    "            print(f\"Predicted Crime Category: {prediction}\")\n",
    "            print(f\"Confidence Score: {confidence:.3f}\")\n",
    "            \n",
    "            # Show all probabilities\n",
    "            print(f\"\\nAll Category Probabilities:\")\n",
    "            sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "            for crime_type, prob in sorted_probs:\n",
    "                print(f\"  {crime_type}: {prob:.3f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error making prediction: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Crime Classification Pipeline Completed!\")\n",
    "print(f\"📊 Final Model Summary:\")\n",
    "print(f\"   - Dataset Size: {len(df)} cases\")\n",
    "print(f\"   - Crime Categories: {len(y.unique())}\")\n",
    "print(f\"   - Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   - TF-IDF Features: {len(tfidf.vocabulary_)}\")\n",
    "\n",
    "# Uncomment the line below to run interactive predictions\n",
    "# interactive_crime_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba22d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting Crime Classification Pipeline...\n",
      "📊 This script will predict STATE/UT based on district crime patterns\n",
      "======================================================================\n",
      "📂 Loading CSV files from: C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\n",
      "📄 Found 57 CSV files:\n",
      "   - 01_District_wise_crimes_committed_IPC_2001_2012.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2013.csv\n",
      "   - 01_District_wise_crimes_committed_IPC_2014.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2001_2012.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2013.csv\n",
      "   - 02_01_District_wise_crimes_committed_against_SC_2014.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2001_2012.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2013.csv\n",
      "   - 02_District_wise_crimes_committed_against_ST_2014.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2001_2012.csv\n",
      "   - 03_District_wise_crimes_committed_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv\n",
      "   - 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv\n",
      "   - 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv\n",
      "   - 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv\n",
      "   - 07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv\n",
      "   - 07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv\n",
      "   - 08_01_Juvenile_apprehended_state_IPC.csv\n",
      "   - 08_02_Juvenile_apprehended_state_SLL.csv\n",
      "   - 09_Juveniles_arrested_and_their_disposal.csv\n",
      "   - 11_Property_stolen_and_recovered_nature_of_property.csv\n",
      "   - 12_Police_strength_actual_and_sanctioned.csv\n",
      "   - 13_Police_killed_or_injured_on_duty.csv\n",
      "   - 14_Age_profile_of_police_personnel_killed_on_duty.csv\n",
      "   - 15_Police_natural_death_and_suicide.csv\n",
      "   - 16_Casualties_under_police_firing_and_lathi_charge.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2001_2012.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2013.csv\n",
      "   - 17_Crime_by_place_of_occurrence_2014.csv\n",
      "   - 18_01_Juveniles_arrested_Education.csv\n",
      "   - 18_02_Juveniles_arrested_Economic_setup.csv\n",
      "   - 18_03_Juveniles_arrested_Family_background.csv\n",
      "   - 18_04_Juveniles_arrested_Recidivism.csv\n",
      "   - 19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv\n",
      "   - 21_Offenders_known_to_the_victim.csv\n",
      "   - 22_Persons_arrested_under_recidivism.csv\n",
      "   - 23_Anti_corruprion_cases.csv\n",
      "   - 24_Anti_corruption_arrests.csv\n",
      "   - 27_Nature_of_complaints_received_by_police.csv\n",
      "   - 34_Use_of_fire_arms_in_murder_cases.csv\n",
      "   - 37_Home_guards_and_auxilliary_force.csv\n",
      "   - 38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv\n",
      "   - 41_Escapes_from_police_custody.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2001_2012.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2013.csv\n",
      "   - 42_District_wise_crimes_committed_against_women_2014.csv\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\01_District_wise_crimes_committed_IPC_2014.csv: 838 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_01_District_wise_crimes_committed_against_SC_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\02_District_wise_crimes_committed_against_ST_2014.csv: 837 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2001_2012.csv: 9015 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_District_wise_crimes_committed_against_children_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv: 494 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv: 2028 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv: 418 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv: 1140 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv: 3432 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv: 1026 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv: 2730 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_01_Juvenile_apprehended_state_IPC.csv: 10500 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\08_02_Juvenile_apprehended_state_SLL.csv: 9450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\09_Juveniles_arrested_and_their_disposal.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\11_Property_stolen_and_recovered_nature_of_property.csv: 4550 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\12_Police_strength_actual_and_sanctioned.csv: 4188 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\13_Police_killed_or_injured_on_duty.csv: 2450 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\14_Age_profile_of_police_personnel_killed_on_duty.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\15_Police_natural_death_and_suicide.csv: 700 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\16_Casualties_under_police_firing_and_lathi_charge.csv: 1749 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv: 4344 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv: 385 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2001_2012.csv: 456 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2013.csv: 38 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\17_Crime_by_place_of_occurrence_2014.csv: 39 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_01_Juveniles_arrested_Education.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_02_Juveniles_arrested_Economic_setup.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_03_Juveniles_arrested_Family_background.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\18_04_Juveniles_arrested_Recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\21_Offenders_known_to_the_victim.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\22_Persons_arrested_under_recidivism.csv: 350 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\23_Anti_corruprion_cases.csv: 346 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\24_Anti_corruption_arrests.csv: 347 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\27_Nature_of_complaints_received_by_police.csv: 349 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\34_Use_of_fire_arms_in_murder_cases.csv: 284 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\37_Home_guards_and_auxilliary_force.csv: 333 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv: 314 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\41_Escapes_from_police_custody.csv: 311 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2013.csv: 823 rows\n",
      "   ✅ Loaded C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\\42_District_wise_crimes_committed_against_women_2014.csv: 837 rows\n",
      "🔗 Combined dataset shape: (120227, 659)\n",
      "\n",
      "📊 Dataset Overview:\n",
      "Total samples: 120227\n",
      "Columns: ['STATE/UT', 'DISTRICT', 'YEAR', 'MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE', 'OTHER RAPE', 'KIDNAPPING & ABDUCTION', 'KIDNAPPING AND ABDUCTION OF WOMEN AND GIRLS', 'KIDNAPPING AND ABDUCTION OF OTHERS', 'DACOITY', 'PREPARATION AND ASSEMBLY FOR DACOITY', 'ROBBERY', 'BURGLARY', 'THEFT', 'AUTO THEFT', 'OTHER THEFT', 'RIOTS', 'CRIMINAL BREACH OF TRUST', 'CHEATING', 'COUNTERFIETING', 'ARSON', 'HURT/GREVIOUS HURT', 'DOWRY DEATHS', 'ASSAULT ON WOMEN WITH INTENT TO OUTRAGE HER MODESTY', 'INSULT TO MODESTY OF WOMEN', 'CRUELTY BY HUSBAND OR HIS RELATIVES', 'IMPORTATION OF GIRLS FROM FOREIGN COUNTRIES', 'CAUSING DEATH BY NEGLIGENCE', 'OTHER IPC CRIMES', 'TOTAL IPC CRIMES', 'States/UTs', 'District', 'Year', 'Murder', 'Attempt to commit Murder', 'Culpable Homicide not amounting to Murder', 'Attempt to commit Culpable Homicide', 'Rape', 'Custodial Rape', 'Custodial_Gang Rape', 'Custodial_Other Rape', 'Rape other than Custodial', 'Rape_Gang Rape', 'Rape_Others', 'Attempt to commit Rape', 'Kidnapping & Abduction_Total', 'Kidnapping & Abduction', 'Kidnapping & Abduction in order to Murder', 'Kidnapping for Ransom', 'Kidnapping & Abduction of Women to compel her for marriage', 'Other Kidnapping', 'Dacoity', 'Dacoity with Murder', 'Other Dacoity', 'Making Preparation and Assembly for committing Dacoity', 'Robbery', 'Criminal Trespass/Burglary', 'Criminal Trespass or Burglary', 'House Trespass & House Breaking', 'Theft', 'Auto Theft', 'Other Thefts', 'Unlawful Assembly', 'Riots', 'Riots_Communal', 'Riots_Industrial', 'Riots_Political', 'Riots_Caste Conflict', 'Riots_SC/STs Vs Non-SCs/STs', 'Riots_Other Caste Conflict', 'Riots_Agrarian', 'Riots_Students', 'Riots_Sectarian', 'Riots_Others', 'Criminal Breach of Trust', 'Cheating', 'Forgery', 'Counterfeiting', 'Counterfeit Offences related to Counterfeit Coin', 'Counterfeiting Government Stamp', 'Counterfeit currency & Bank notes', 'Counterfeiting currency notes/Bank notes', 'Using forged or counterfeiting currency/Bank notes', 'Possession of forged or counterfeiting currency/Bank notes', 'Making or Possessing materials for forged currency/Bank notes', 'Making or Using documents resembling currency', 'Arson', 'Grievous Hurt', 'Hurt', 'Acid attack', 'Attempt to Acid Attack', 'Dowry Deaths', 'Assault on Women with intent to outrage her Modesty', 'Sexual Harassment', 'Assault or use of criminal force to women with intent to Disrobe', 'Voyeurism', 'Stalking', 'Other Assault on Women', 'Insult to the Modesty of Women', 'At Office premises', 'Other places related to work', 'In Public Transport system', 'Places other than 231, 232 & 233', 'Cruelty by Husband or his Relatives', 'Importation of Girls from Foreign Country', 'Causing Death by Negligence', 'Deaths due to negligent driving/act', 'Deaths due to Other Causes', 'Offences against State', 'Sedition', 'Other offences against State', 'Offences promoting enmity between different groups', 'Promoting enmity between different groups', 'Imputation, assertions prejudicial to national integration', 'Extortion', 'Disclosure of Identity of Victims', 'Incidence of Rash Driving', 'HumanTrafficking', 'Unnatural Offence', 'Other IPC crimes', 'Total Cognizable IPC crimes', 'Kidnapping and Abduction', 'Prevention of atrocities (POA) Act', 'Protection of Civil Rights (PCR) Act', 'Other Crimes Against SCs', 'Protection of Civil Rights Act, 1955', 'POA_Murder', 'POA_Attempt to commit Murder', 'POA_Rape', 'POA_Attempt to commit Rape', 'POA_Assault on women with intent to outrage her Modesty', 'POA_Sexual Harassment', 'POA_Assault on women with intent to Disrobe', 'POA_Voyeurism', 'POA_Stalking', 'POA_Other Sexual Harassment', 'POA_Insult to the Modesty of women', 'POA_Kidnapping & Abduction_GrandTotal', 'POA_Kidnaping & Abduction_Total', 'POA_Kidnaping & Abduction in order to Murder', 'POA_Kidnapping for Ransom', 'POA_Kidnapping & Abduction of Women to compel her for marriage', 'POA_Other Kidnapping', 'POA_Dacoity', 'POA_Dacoity with Murder', 'POA_Other Dacoity', 'POA_Robbery', 'POA_Arson', 'POA_Grievous Hurt', 'POA_Hurt', 'POA_Acid attack', 'POA_Attempt to Acid Attack', 'POA_Riots', 'POA_Other IPC crimes', 'POA_SC / ST (Prevention of Atrocities) Act only', 'Total of SC/ST (Prevention of Atrocities) Act ,1989', 'IPC_Murder', 'IPC_Attempt to commit Murder', 'IPC_Rape', 'IPC_Attempt to commit Rape', 'IPC_Assault on women with intent to outrage her Modesty', 'IPC_Sexual Harassment', 'IPC_Assault on women with intent to Disrobe', 'IPC_Voyeurism', 'IPC_Stalking', 'IPC_Other Sexual Harassment', 'IPC_Insult to the Modesty of women', 'IPC_Kidnapping & Abduction', 'IPC_Kidnaping & Abduction', 'IPC_Kidnaping & Abduction in order to Murder', 'IPC_Kidnapping for Ransom', 'IPC_Kidnapping & Abduction of Women to compel her for marriage', 'IPC_Other Kidnapping', 'IPC_Dacoity', 'IPC_Dacoity with Murder', 'IPC_Other Dacoity', 'IPC_Robbery', 'IPC_Arson', 'IPC_Grievous Hurt', 'IPC_Hurt', 'IPC_Acid attack', 'IPC_Attempt to Acid Attack', 'IPC_Riots', 'IPC_Other IPC crimes', 'Total IPC Crimes against SCs', 'Manual Scavengers and Construction of Dry Latrines (P) Act, 1993', 'Other SLL Crime against SCs', 'Total crimes against SCs', 'Kidnapping Abduction', 'Other Crimes Against STs', 'Total IPC Crimes against STs', 'Other SLL Crime against STs', 'Total crimes against STs', 'Foeticide', 'Abetment of suicide', 'Exposure and abandonment', 'Procuration of minor girls', 'Buying of girls for prostitution', 'Selling of girls for prostitution', 'Prohibition of child marriage act', 'Other Crimes', 'Total', 'Infanticid', 'Other murder', 'CRIME HEAD', 'Persons in custody or on bail during the stage of investigation at the beginning of the year', 'Persons arrested during the year', 'Persons released or freed by Police or Magistrate before trial for want of evidence or any other reason', 'Persons in custody or on bail during the stage of investigation at the end of the year', 'Persons in whose cases charge sheets were laid during the year', 'Persons under trial at the beginning of the year', 'Total number of persons under trial during the year', 'Persons against whom cases were compounded or withdrawn', 'Persons in custody or on bail during the stage of trial at the end of the year', 'Persons in whose cases trials were completed during the year', 'Persons convicted', 'Persons acquitted', 'Crime Head', 'Persons in custody during inv stage at beginning of Year_Male', 'Persons in custody during inv stage at beginning of Year_Female', 'Persons in custody during inv stage at beginning of Year_Total', 'Persons on bail during inv stage at beginning of Year_Male', 'Persons on bail during inv stage at beginning of Year_Female', 'Persons on bail during inv stage at beginning of Year_Total', 'Persons arrested during the year_Male', 'Persons arrested during the year_Female', 'Persons arrested during the year_Total', 'Persons released or freed before trial for want of evidence_Male', 'Persons released or freed before trial for want of evidence_Fem', 'Persons released or freed before trial for want of evidence_Tot', 'Persons in custody during inv stage at year end_Male', 'Persons in custody during inv stage at year end_Female', 'Persons in custody during inv stage at year end_Total', 'Persons on Bail during inv stage at year end_Male', 'Persons on Bail during inv stage at Year end_Female', 'Persons on Bail during inv stage at year end_Total', 'Persons charge sheeted_Male', 'Persons charge sheeted_Female', 'Persons charge sheeted_Total', 'Persons in custody during trial stage at begin of year_Male', 'Persons in custody during trial stage at begin of year_Female', 'Persons in custody during trial stage at begin of year_Total', 'Persons on Bail during trial stage at begin of year_Male', 'Persons on Bail during trial stage at begin of year_Female', 'Persons on Bail during trial stage at begin of year_Total', 'Total number of persons under Trial_Male', 'Total number of persons under Trial_Female', 'Total number of persons under Trial_Total', 'Persons against whom cases were compounded by Courts_Male', 'Persons against whom cases were compounded by Courts_Female', 'Persons against whom cases were compounded by Courts_Total', 'Persons against whom cases were withdrawn_Male', 'Persons against whom cases were withdrawn_Female', 'Persons against whom cases were withdrawn_Total', 'Persons in custody during trial stage at Year end_Male', 'Persons in custody during trial stage at Year end_Female', 'Persons in custody during trial stage at Year end_Total', 'Persons on bail during trial stage at Year End_Male', 'Persons on bail during trial stage at Year End_Female', 'Persons on bail during trial stage at Year End_Total', 'Persons whose cases trials were completed during the year_Male', 'Persons whose cases trials were completed during the year_Female', 'Persons whose cases trials were completed during the year_Total', 'Persons convicted_Male', 'Persons convicted_Female', 'Persons convicted_Total', 'Persons acquitted_Male', 'Persons acquitted_Female', 'Persons acquitted_Total', 'Persons Discharged by Court_Male', 'Persons Discharged by Court_Female', 'Persons Discharged by Court_Total', 'Male Below 18 Years', 'Female Below 18 Years', 'Male Between 18-30 Years', 'Female Between 18-30 Years', 'Male Between 30-45 Years', 'Female Between 30-45 Years', 'Male Between 45-60 Years', 'Female Between 45-60 Years', 'Male Above 60 Years', 'Female Above 60 Years', 'Male Total', 'Female Total', 'Grand Total', '18 and above and below 30 years_Male', '18 and above and below 30 years_Female', '18 and above and below 30 years_Total', '30 and above and below 45 years_Male', '30 and above and below 45 years_Female', '30 and above and below 45 years_Total', '45 and above and below 60 years_Male', '45 and above and below 60 years_Female', '45 and above and below 60 years_Total', '60 years and above_Male', '60 years and above_Female', '60 years and above_Total', 'Total Male', 'Total Female', 'Total Persons Arrested by age and Sex', 'CRIME', 'Boys 7-12 Years', 'Girls 7-12 Years', 'Boys 12-16 Years', 'Girls 12-16 Years', 'Boys 16-18 Years', 'Girls 16-18 Years', 'Total for boys all Age Groups', 'Total for girls all Age Groups', 'Grand total', 'Area_Name', 'Juveniles_Acquitted_or_Otherwise_Disposed_of', 'Juveniles_Arrested', 'Juveniles_Dealt_with_Fine', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Fit_Institutions', 'Juveniles_Released_on_Probation_and_placed_under_the_Care_of_Parent_Guardian', 'Juveniles_Sent_Home_after_Advice_or_Admonition', 'Juveniles_Sent_to_Special_Home', 'Juveniles_whose_Cases_Pending_Disposal', 'Group_Name', 'Sub_Group_Name', 'Cases_Property_Recovered', 'Cases_Property_Stolen', 'Value_of_Property_Recovered', 'Value_of_Property_Stolen', 'Rank_All_Ranks_Total', 'Rank_ASI_Equivalent', 'Rank_ASPDySPAssttCommandant', 'Rank_Below_HC_and_Above_Constables', 'Rank_Constables', 'Rank_DGAddl_DG', 'Rank_DIG', 'Rank_Head_Constables', 'Rank_IGSplIG', 'Rank_Inspectors_Equivalent', 'Rank_SI_Equivalent', 'Rank_SSPSPAddlSPCommandant', 'Police_Injured_By_Criminals', 'Police_Injured_By_Riotous_Mobs', 'Police_Injured_In_Accidents', 'Police_Injured_In_Dacoity_OperationsOther_raids', 'Police_Injured_In_TerroristsExtremists_Operations', 'Police_Injured_On_Border_Duties', 'Police_Injured_Total_Policemen', 'Police_Killed_By_Criminals', 'Police_Killed_By_Riotous_Mobs', 'Police_Killed_In_Accidents', 'Police_Killed_In_Dacoity_OperationsOther_raids', 'Police_Killed_In_TerroristsExtremists_Operations', 'Police_Killed_On_Border_Duties', 'Police_Killed_Total_Policemen', 'Age_18_25_Yrs', 'Age_25_35_Yrs', 'Age_35_45_Yrs', 'Age_45_55_Yrs', 'Age_Above_55_Yrs', 'Age_Total', 'Civilians_Injured', 'Civilians_Killed', 'No_of_Firings', 'Policemen_Injured', 'Policemen_Killed', 'Place Of Occurrence', 'Dacoity (Section 395-398 IPC) - Number of cases registered', 'Dacoity (Section 395-398 IPC) - Value Of Property Stolen (in rupees)', 'Robbery(Section 392-394, 397, 398 IPC) - Number of cases registered', 'Robbery(Section 392-394, 397, 398 IPC) - Value Of Property Stolen (in rupees)', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Number of cases registered', 'Burglary(Section 449-452, 454, 455, 457-460 IPC) - Value Of Property Stolen (in rupees)', 'Theft (Section 379-382 IPC) - Number of cases registered', 'Theft (Section 379-382 IPC) - Value Of Property Stolen (in rupees)', 'RESIDENTIAL PREMISES - Dacoity', 'RESIDENTIAL PREMISES - Robbery', 'RESIDENTIAL PREMISES - Burglary', 'RESIDENTIAL PREMISES - Theft', 'HIGHWAYS - Dacoity', 'HIGHWAYS - Robbery', 'HIGHWAYS - Burglary', 'HIGHWAYS - Theft', 'RIVER and SEA - Dacoity', 'RIVER and SEA - Robbery', 'RIVER and SEA - Burglary', 'RIVER and SEA - Theft', 'RAILWAYS - Dacoity', 'RAILWAYS - Robbery', 'RAILWAYS - Burglary', 'RAILWAYS - Theft', 'BANKS - Dacoity', 'BANKS - Robbery', 'BANKS - Burglary', 'BANKS - Theft', 'COMMERCIAL ESTABLISHMENTS - Dacoity', 'COMMERCIAL ESTABLISHMENTS - Robbery', 'COMMERCIAL ESTABLISHMENTS - Burglary', 'COMMERCIAL ESTABLISHMENTS - Theft', 'OTHER PLACES - Dacoity', 'OTHER PLACES - Robbery', 'OTHER PLACES - Burglary', 'OTHER PLACES - Theft', 'TOTAL - Dacoity', 'TOTAL - Robbery', 'TOTAL - Burglary', 'TOTAL - Theft', 'Residence_Dacoity_Cases reported', 'Residence_Dacoity_Value of property stolen', 'Residence_Robbery_Cases reported', 'Residence_Robbery_Value of property stolen', 'Residence_Burglary_Cases reported', 'Residence_Burglary_Value of property stolen', 'Residence_Theft_Cases reported', 'Residence_Theft_Value of property stolen', 'Highways_Dacoity_Cases reported', 'Highways_Dacoity_Value of property stolen', 'Highways_Robbery_Cases reported', 'Highways_Robbery_Value of property stolen', 'Highways_Burglary_Cases reported', 'Highways_Burglary_Value of property stolen', 'Highways_Theft_Cases reported', 'Highways_Theft_Value of property stolen', 'RiverOrSea_Dacoity_Cases reported', 'RiverOrSea_Dacoity_Value of property stolen', 'RiverOrSea_Robbery_Cases reported', 'RiverOrSea_Robbery_Value of property stolen', 'RiverOrSea_Burglary_Cases reported', 'RiverOrSea_Burglary_Value of property stolen', 'RiverOrSea_Theft_Cases reported', 'RiverOrSea_Theft_Value of property stolen', 'Railways_Dacoity_Cases reported', 'Railways_Dacoity_Value of property stolen', 'Railways_Robbery_Cases reported', 'Railways_Robbery_Value of property stolen', 'Railways_Burglary_Cases reported', 'Railways_Burglary_Value of property stolen', 'Railways_Theft_Cases reported', 'Railways_Theft_Value of property stolen', 'Religious Places_Dacoity_Cases reported', 'Religious Places_Dacoity_Value of property stolen', 'Religious Places_Robbery_Cases reported', 'Religious Places_Robbery_Value of property stolen', 'Religious Places_Burglary_Cases reported', 'Religious Places_Burglary_Value of property stolen', 'Religious Places_Theft_Cases reported', 'Religious Places_Theft_Value of property stolen', 'ATM_Dacoity_Cases reported', 'ATM_Dacoity_Value of property stolen', 'ATM_Robbery_Cases reported', 'ATM_Robbery_Value of property stolen', 'ATM_Burglary_Cases reported', 'ATM_Burglary_Value of property stolen', 'ATM_Theft_Cases reported', 'ATM_Theft_Value of property stolen', 'Bank_Dacoity_Cases reported', 'Bank_Dacoity_Value of property stolen', 'Bank_Robbery_Cases reported', 'Bank_Robbery_Value of property stolen', 'Bank_Burglary_Cases reported', 'Bank_Burglary_Value of property stolen', 'Bank_Theft_Cases reported', 'Bank_Theft_Value of property stolen', 'CommEst_Dacoity_Cases reported', 'CommEst_Dacoity_Value of property stolen', 'CommEst_Robbery_Cases reported', 'CommEst_Robbery_Value of property stolen', 'CommEst_Burglary_Cases reported', 'CommEst_Burglary_Value of property stolen', 'CommEst_Theft_Cases reported', 'CommEst_Theft_Value of property stolen', 'OtherPlaces_Dacoity_Cases reported', 'OtherPlaces_Dacoity_Value of property stolen', 'OtherPlaces_Robbery_Cases reported', 'OtherPlaces_Robbery_Value of property stolen', 'OtherPlaces_Burglary_Cases reported', 'OtherPlaces_Burglary_Value of property stolen', 'OtherPlaces_Theft_Cases reported', 'OtherPlaces_Theft_Value of property stolen', 'Total_Dacoity_Cases reported', 'Total_Dacoity_Value of property stolen', 'Total_Robbery_Cases reported', 'Total_Robbery_Value of property stolen', 'Total_Burglary_Cases reported', 'Total_Burglary_Value of property stolen', 'Total_Theft_Cases reported', 'Total_Theft_Value of property stolen', 'Education_Above_Primary_but_below_Matric_or_Higher_Secondary', 'Education_Illiterate', 'Education_Matric_or_Higher_Secondary_&_above', 'Education_Total', 'Education_Upto_primary', 'Economic_Set_up_Annual_Income_250001_to_50000', 'Economic_Set_up_Annual_Income_upto_Rs_25000', 'Economic_Set_up_Middle_income_from_100001_to_200000', 'Economic_Set_up_Middle_income_from_50001_to_100000', 'Economic_Set_up_Total', 'Economic_Set_up_Upper_income_above_Rs_300000', 'Economic_Set_up_Upper_middle_income_from_200001_to_300000', 'Family_back_ground_Homeless', 'Family_back_ground_Living_with_guardian', 'Family_back_ground_Living_with_parents', 'Family_back_ground_Total', 'Recidivism_New_Delinquent', 'Recidivism_Old_Delinquent', 'Recidivism_Total', 'CHNAMurder_Cause_By_TerroristExtremist', 'CHNAMurder_Cause_Casteism', 'CHNAMurder_Cause_Class_Conflict', 'CHNAMurder_Cause_Communalism', 'CHNAMurder_Cause_Dowry', 'CHNAMurder_Cause_For_Political_reason', 'CHNAMurder_Cause_Gain', 'CHNAMurder_Cause_Love_AffairsSexual_Relations', 'CHNAMurder_Cause_Lunacy', 'CHNAMurder_Cause_Other_Causes_or_Motives', 'CHNAMurder_Cause_Personal_Vendetta_or_Enmity', 'CHNAMurder_Cause_Property_Dispute', 'CHNAMurder_Cause_Total', 'CHNAMurder_Cause_Witchcraft', 'Murder_Cause_By_TerroristExtremist', 'Murder_Cause_Casteism', 'Murder_Cause_Class_Conflict', 'Murder_Cause_Communalism', 'Murder_Cause_Dowry', 'Murder_Cause_For_Political_reason', 'Murder_Cause_Gain', 'Murder_Cause_Love_AffairsSexual_Relations', 'Murder_Cause_Lunacy', 'Murder_Cause_Other_Causes_or_Motives', 'Murder_Cause_Personal_Vendetta_or_Enmity', 'Murder_Cause_Property_Dispute', 'Murder_Cause_Total', 'Murder_Cause_Witchcraft', 'No_of_Cases_in_which_offenders_were_known_to_the_Victims', 'No_of_Cases_in_which_offenders_were_Neighbours', 'No_of_Cases_in_which_offenders_were_Other_Known_persons', 'No_of_Cases_in_which_offenders_were_Parentsclose_family_members', 'No_of_Cases_in_which_offenders_were_Relatives', 'Offenders_Arrested', 'Offenders_Arrested_for_the_First_time', 'Offenders_Conviction_in_the_past_Once', 'Offenders_Conviction_in_the_past_Three_times_or_More', 'Offenders_Conviction_in_the_past_Twice', 'AC01_No_of_cases_pending_investigation_from_previous_year', 'AC02_No_of_cases_registered_during_the_year', 'AC03_Total_No_of_cases_for_investigation_during_the_year', 'AC04_No_of_cases_investigated_during_the_year', 'AC05_No_of_cases_not_investigatedor_in_which_investigation_was_dropped_due_to_any_reason_during_the_year', 'AC06_No_of_cases_transferred_to_local_police_during_the_year', 'AC07_No_of_cases_declared_false_mistake_of_fact_or_of_law_or_non_cognizable_or_civil_in_nature', 'AC08_No_of_cases_in_which_charge_sheets_were_laid_during_the_year', 'AC09_No_of_cases_pending_departmental_sanction_for_prosecution_during_the_year', 'AC10_No_of_cases_sent_up_for_trial_and_also_reported_for_departmental_action_during_the_year', 'AC11_No_of_cases_reported_for_regular_departmental_action_during_the_year', 'AC12_No_of_cases_reported_for_suitable_action_during_the_year', 'AC13_No_of_cases_in_which_charge_sheets_were_not_laid_but_final_report_submitted_during_the_year', 'AC14_No_of_cases_pending_investigation_at_the_end_of_the_year', 'AC15_No_of_cases_resulted_in_recoveries_or_seizures_during_the_year', 'AC16_Value_of_property_recoveredseized_during_the_year_in_Rs', 'AC17_Percentage_of_cases_charge_sheeted_to_total_cases_investigated', 'AC18_No_of_cases_pending_trial_from_the_previous_year', 'AC19_No_of_cases_sent_up_for_trial_during_the_year', 'AC20_Total_No_of_cases_for_trial_during_the_year', 'AC21_No_of_cases_withdrawn_or_other_wise_disposed_off_on_account_of_death_of_the_accused_during_the_year', 'AC22_No_of_cases_in_which_trials_were_completed_during_the_year', 'AC23_No_of_cases_convicted_during_the_year', 'AC24_No_of_cases_acquitted_or_discharged_during_the_year', 'AC25_No_of_cases_pending_trial_at_the_end_of_the_year', 'AC26_Percentage_of_cases_convicted_to_cases_in_which_trials_were_completed_during_the_year', 'AC27_Total_amount_of_fine_imposed_during_the_year_in_Rs', 'ACA01_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_beginning_of_the_year', 'ACA02_No_of_persons_arrested_during_the_year', 'ACA04_No_of_persons_in_custody_or_on_bail_during_the_stage_of_investigation_at_the_end_of_the_year', 'ACA05_No_of_persons_in_whose_cases_charge_sheets_were_laid_during_the_year', 'ACA06_No_of_persons_under_trial_at_the_beginning_of_the_year', 'ACA07_Total_No_of_persons_under_trial_during_the_year', 'ACA08_No_of_persons_whose_cases_were_withdrawn_or_otherwise_disposed_off_during_the_year', 'ACA09_No_of_persons_in_custody_or_on_bail_during_the_stage_of_trial_at_the_end_of_the_year', 'ACA10_No_of_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA11_No_of_persons_convicted_during_the_year', 'ACA12_No_of_persons_acquitted_during_the_year', 'ACA13_Percentage_of_persons_convicted_to_total_persons_in_whose_cases_trials_were_completed_during_the_year', 'ACA14_No_of_persons_involved_in_the_cases_reported_for_Regular_Departmental_Action_during_the_year', 'ACA15_No_of_persons_involved_in_the_cases_reported_for_suitable_action_during_the_year', 'ACA16_No_of_persons_punished_departmentally_during_the_year:', 'ACA161_No_of_persons_dismissed_from_Service_during_the_year', 'ACA162_No_of_persons_removed_from_service_during_the_year', 'ACA163_No_of_persons_awarded_other_major_punishments_during_the_year', 'ACA164_No_of_persons_awarded_minor_punishments_during_the_year', \"ACA171_No_of_Group_`A'_Officers_out_of_above\", \"ACA172_No_of_Group_`B'_Officers_out_of_above\", 'ACA19_No_of_private_persons_involved_during_the_year', 'PC1_Oral_Complaints', 'PC2_Written_Complaints', 'PC3_Distress_call_over_phoneNo_100_etc', 'PC4_Complaints_initiated_sue_motto_by_Police', 'PC5_Total_Complaints_Sum_of_1_4_Above', 'PC6_Total_Complaints_as_recorded_in_GD', 'PC7_IPC_Cases_Registered', 'PC8_SLL_Cases_Registered', 'Victims_of_Murder_by_Fire_arms', 'Victims_of_Murder_by_Licensed_arms', 'Victims_of_Murder_by_Un_licensedImprovisedCrudeCountry_made_Arms_Etc', 'HG_Lower_Subordinates_Actual_Strength', 'HG_Lower_Subordinates_Sanctioned_Strength', 'HG_Officers_Actual_Strength', 'HG_Officers_Sanctioned_Strength', 'HG_Upper_Subordinates_Actual_Strength', 'HG_Upper_Subordinates_Sanctioned_Strength', 'Unidentified_Dead_bodies_Recovered_Inquest_Conducted', 'EPC_Cases_Cases_Acquitted', 'EPC_Cases_Cases_Convicted', 'EPC_Cases_Cases_Pending_for_Trial', 'EPC_Cases_Registered', 'EPC_Cases_Trial_Completed', 'EPC_Escapees_Re_Arrested_from_Lockup', 'EPC_Escapees_Re_Arrested_from_Others', 'EPC_FR_Submitted', 'EPC_Persons_Awarded_more_than_3_Years_Imprisonment', 'EPC_Persons_Awarded_upto_3_Years_Imprisonment', 'EPC_Persons_Cases_Acquitted', 'EPC_Persons_Cases_Convicted', 'EPC_Persons_Cases_Pending_for_Trial', 'EPC_Persons_Chargesheeted_for_Escape', 'EPC_Persons_Escaped', 'EPC_Persons_Escaped_from_Lockup', 'EPC_Persons_Escaped_Outside_the_Lockup', 'EPC_Persons_Escaped_Total', 'EPC_Persons_Trial_Completed', 'Assault on women with intent to outrage her modesty', 'Insult to modesty of Women', 'Importation of Girls', 'Kidnaping & Abduction', 'Kidnaping & Abduction in order to Murder', 'Kidnaping & Abduction_Others', 'Assault on Women with intent to outrage her Modesty_Total', 'Assault on women with intent to Disrobe', 'Others', 'Insult to the Modesty of Women_Total', 'In places related to work', 'In other Places', 'Deaths caused with intent to cause miscarriage', 'Causing miscarriage without consent of women', 'Dacoity_Total', 'Abetment of Suicides of Women', 'UnNatural Offences', 'Other IPC Crimes', 'Dowry Prohibition Act, 1961', 'Indecent Representation of Women (P) Act, 1986', 'Commission of Sati Prevention Act, 1987', 'Protection of Women from Domestic Violence Act, 2005', 'Immoral Traffic Prevention Act', 'ITP Under Section 5', 'ITP Under Section 6', 'ITP Under Section 7', 'ITP Under Section 8', 'ITP Under Other Sections', 'Other SLL Crimes against Women', 'Total Crimes against Women']\n",
      "Missing values:\n",
      "STATE/UT                           36810\n",
      "DISTRICT                           71027\n",
      "YEAR                              105164\n",
      "MURDER                            110387\n",
      "ATTEMPT TO MURDER                 110387\n",
      "                                   ...  \n",
      "ITP Under Section 7               119390\n",
      "ITP Under Section 8               119390\n",
      "ITP Under Other Sections          119390\n",
      "Other SLL Crimes against Women    119390\n",
      "Total Crimes against Women        119390\n",
      "Length: 659, dtype: int64\n",
      "\n",
      "🏷️ State Distribution:\n",
      "STATE/UT\n",
      "UTTAR PRADESH        4529\n",
      "MADHYA PRADESH       3279\n",
      "MAHARASHTRA          2899\n",
      "BIHAR                2838\n",
      "TAMIL NADU           2484\n",
      "                     ... \n",
      "TOTAL (UTs)           139\n",
      "TOTAL (ALL-INDIA)     139\n",
      "Total (State)         112\n",
      "Total (UTs)           112\n",
      "Total (All-India)     112\n",
      "Name: count, Length: 77, dtype: int64\n",
      "\n",
      "🏷️ District Distribution (Top 10):\n",
      "DISTRICT\n",
      "TOTAL        2140\n",
      "G.R.P.        245\n",
      "NORTH         205\n",
      "SOUTH         205\n",
      "WEST          195\n",
      "RAILWAYS      182\n",
      "BALRAMPUR     130\n",
      "BILASPUR      130\n",
      "HAMIRPUR      130\n",
      "EAST          130\n",
      "Name: count, dtype: int64\n",
      "\n",
      "📊 Crime Categories Found: 656\n",
      "Sample crime columns: ['MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE']\n",
      "\n",
      "🧹 Preprocessing and preparing features...\n",
      "🔍 Before cleaning - Total samples: 120227\n",
      "Missing values in STATE/UT: 36810\n",
      "Missing values in DISTRICT: 71027\n",
      "✅ After cleaning: 49200 samples remaining\n",
      "🔤 Creating text representations of crime patterns...\n",
      "📊 States after cleaning: 71 unique states\n",
      "State distribution:\n",
      "STATE/UT\n",
      "UTTAR PRADESH     4390\n",
      "MADHYA PRADESH    3140\n",
      "MAHARASHTRA       2760\n",
      "BIHAR             2699\n",
      "TAMIL NADU        2345\n",
      "                  ... \n",
      "Daman & Diu         15\n",
      "Puducherry          15\n",
      "Chandigarh          10\n",
      "D&N Haveli          10\n",
      "Lakshadweep         10\n",
      "Name: count, Length: 71, dtype: int64\n",
      "📊 After filtering: 49200 samples with 71 states\n",
      "\n",
      "📝 Sample crime text representations:\n",
      "State: ANDHRA PRADESH\n",
      "District: ADILABAD\n",
      "Crime Text: district_adilabad murder murder murder murder murder murder murder murder murder murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder culp...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: ANANTAPUR\n",
      "Crime Text: district_anantapur murder murder murder murder murder murder murder murder murder murder murder murder murder murder murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder atte...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: CHITTOOR\n",
      "Crime Text: district_chittoor murder murder murder murder murder murder murder murder murder murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder attempt_to_murder culpable_homicide_not_...\n",
      "--------------------------------------------------\n",
      "\n",
      "✂️ Splitting dataset into training and testing sets...\n",
      "🔍 Final check - Missing values in X: 0\n",
      "🔍 Final check - Missing values in y: 0\n",
      "📊 Minimum samples per state: 10\n",
      "✅ Using stratified split\n",
      "📈 Training set size: 39360 samples\n",
      "📉 Testing set size: 9840 samples\n",
      "🎯 Number of unique states: 71\n",
      "\n",
      "🔤 Vectorizing text data using TF-IDF...\n",
      "✅ TF-IDF vectorization completed\n",
      "📊 Training features shape: (39360, 2894)\n",
      "📊 Testing features shape: (9840, 2894)\n",
      "📚 Vocabulary size: 2894\n",
      "\n",
      "🤖 Training Logistic Regression classifier...\n",
      "✅ Model training completed!\n",
      "\n",
      "📈 Evaluating model performance...\n",
      "🎯 Model Accuracy: 0.5352 (53.52%)\n",
      "\n",
      "📋 Detailed Classification Report:\n",
      "============================================================\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    A & N ISLANDS       1.00      0.03      0.05        36\n",
      "      A&N Islands       0.00      0.00      0.00         4\n",
      "   ANDHRA PRADESH       0.65      0.41      0.50       370\n",
      "ARUNACHAL PRADESH       0.82      0.57      0.67       195\n",
      "            ASSAM       0.81      0.80      0.80       362\n",
      "   Andhra Pradesh       0.00      0.00      0.00        34\n",
      "Arunachal Pradesh       0.00      0.00      0.00        19\n",
      "            Assam       0.00      0.00      0.00        34\n",
      "            BIHAR       0.51      0.83      0.63       540\n",
      "            Bihar       0.00      0.00      0.00        45\n",
      "       CHANDIGARH       0.00      0.00      0.00        24\n",
      "     CHHATTISGARH       0.82      0.12      0.21       265\n",
      "       Chandigarh       0.00      0.00      0.00         2\n",
      "     Chhattisgarh       0.00      0.00      0.00        29\n",
      "     D & N HAVELI       0.00      0.00      0.00        24\n",
      "       D&N Haveli       0.00      0.00      0.00         2\n",
      "      DAMAN & DIU       1.00      0.06      0.11        36\n",
      "            DELHI       0.57      0.25      0.34       146\n",
      "         DELHI UT       0.69      0.68      0.68        37\n",
      "      Daman & Diu       0.00      0.00      0.00         3\n",
      "         Delhi UT       0.00      0.00      0.00        19\n",
      "              GOA       0.00      0.00      0.00        36\n",
      "          GUJARAT       0.84      0.58      0.68       384\n",
      "              Goa       0.00      0.00      0.00         3\n",
      "          Gujarat       0.00      0.00      0.00        35\n",
      "          HARYANA       0.62      0.16      0.26       268\n",
      " HIMACHAL PRADESH       0.96      0.13      0.23       176\n",
      "          Haryana       0.00      0.00      0.00        25\n",
      " Himachal Pradesh       0.00      0.00      0.00        16\n",
      "  JAMMU & KASHMIR       0.60      0.86      0.71       322\n",
      "        JHARKHAND       0.80      0.57      0.67       312\n",
      "  Jammu & Kashmir       0.00      0.00      0.00        31\n",
      "        Jharkhand       0.00      0.00      0.00        27\n",
      "        KARNATAKA       0.72      0.69      0.70       399\n",
      "           KERALA       0.79      0.28      0.41       233\n",
      "        Karnataka       0.00      0.00      0.00        36\n",
      "           Kerala       0.00      0.00      0.00        21\n",
      "      LAKSHADWEEP       1.00      0.21      0.34        24\n",
      "      Lakshadweep       0.00      0.00      0.00         2\n",
      "   MADHYA PRADESH       0.49      0.81      0.61       628\n",
      "      MAHARASHTRA       0.54      0.78      0.64       552\n",
      "          MANIPUR       0.86      0.14      0.25       125\n",
      "        MEGHALAYA       1.00      0.10      0.19        96\n",
      "          MIZORAM       1.00      0.21      0.35       108\n",
      "   Madhya Pradesh       0.00      0.00      0.00        55\n",
      "      Maharashtra       0.00      0.00      0.00        46\n",
      "          Manipur       0.00      0.00      0.00        11\n",
      "        Meghalaya       0.00      0.00      0.00        12\n",
      "          Mizoram       0.00      0.00      0.00        11\n",
      "         NAGALAND       0.86      0.14      0.24       139\n",
      "         Nagaland       0.00      0.00      0.00        12\n",
      "           ODISHA       0.75      0.62      0.68       430\n",
      "           Odisha       0.00      0.00      0.00        37\n",
      "       PUDUCHERRY       0.00      0.00      0.00        31\n",
      "           PUNJAB       0.90      0.50      0.64       314\n",
      "       Puducherry       0.00      0.00      0.00         3\n",
      "           Punjab       0.00      0.00      0.00        29\n",
      "        RAJASTHAN       0.62      0.61      0.62       454\n",
      "        Rajasthan       0.00      0.00      0.00        44\n",
      "           SIKKIM       1.00      0.08      0.15        60\n",
      "           Sikkim       0.00      0.00      0.00         5\n",
      "       TAMIL NADU       0.75      0.68      0.72       469\n",
      "          TRIPURA       0.00      0.00      0.00        67\n",
      "       Tamil Nadu       0.00      0.00      0.00        40\n",
      "          Tripura       0.00      0.00      0.00        10\n",
      "    UTTAR PRADESH       0.28      0.95      0.43       878\n",
      "      UTTARAKHAND       0.86      0.07      0.13       168\n",
      "    Uttar Pradesh       0.50      0.03      0.05        77\n",
      "      Uttarakhand       0.00      0.00      0.00        14\n",
      "      WEST BENGAL       0.76      0.61      0.68       309\n",
      "      West Bengal       0.00      0.00      0.00        30\n",
      "\n",
      "         accuracy                           0.54      9840\n",
      "        macro avg       0.34      0.19      0.20      9840\n",
      "     weighted avg       0.61      0.54      0.50      9840\n",
      "\n",
      "\n",
      "🔍 Confusion Matrix:\n",
      "[[  1   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0 153 ...   0   2   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   8 ...   0 190   0]\n",
      " [  0   0   0 ...   0  13   0]]\n",
      "\n",
      "🎲 Sample Predictions with Confidence:\n",
      "\n",
      "Sample 5152:\n",
      "Text: 'district_cyberabad year year year year year year year year year year year year year year year year y...'\n",
      "True Label: ANDHRA PRADESH\n",
      "Predicted: RAJASTHAN (Confidence: 0.181)\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 9550:\n",
      "Text: 'district_nagpur_commr. year year year year year year year year year year year year year year year ye...'\n",
      "True Label: MAHARASHTRA\n",
      "Predicted: MADHYA PRADESH (Confidence: 0.467)\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 5311:\n",
      "Text: 'district_kalahandi murder murder attempt_to_murder culpable_homicide_not_amounting_to_murder rape ra...'\n",
      "True Label: ODISHA\n",
      "Predicted: ODISHA (Confidence: 0.136)\n",
      "--------------------------------------------------\n",
      "\n",
      "🔮 Testing model on custom crime patterns:\n",
      "============================================================\n",
      "\n",
      "🔍 Test Case 1:\n",
      "Crime Pattern: 'district_mumbai murder murder robbery theft theft burglary cheating fraud'\n",
      "Predicted State: NAGALAND\n",
      "Confidence: 0.154\n",
      "Top 3 predictions:\n",
      "  1. NAGALAND: 0.154\n",
      "  2. MAHARASHTRA: 0.098\n",
      "  3. KERALA: 0.067\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 2:\n",
      "Crime Pattern: 'district_delhi rape kidnapping_abduction assault theft auto_theft riots'\n",
      "Predicted State: KERALA\n",
      "Confidence: 0.130\n",
      "Top 3 predictions:\n",
      "  1. KERALA: 0.130\n",
      "  2. WEST BENGAL: 0.117\n",
      "  3. GUJARAT: 0.057\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 3:\n",
      "Crime Pattern: 'district_chennai dowry_deaths cruelty_by_husband murder hurt_grevious_hurt theft'\n",
      "Predicted State: TAMIL NADU\n",
      "Confidence: 0.495\n",
      "Top 3 predictions:\n",
      "  1. TAMIL NADU: 0.495\n",
      "  2. KARNATAKA: 0.053\n",
      "  3. BIHAR: 0.045\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 4:\n",
      "Crime Pattern: 'district_kolkata theft burglary robbery cheating counterfieting arson'\n",
      "Predicted State: KERALA\n",
      "Confidence: 0.146\n",
      "Top 3 predictions:\n",
      "  1. KERALA: 0.146\n",
      "  2. NAGALAND: 0.117\n",
      "  3. MAHARASHTRA: 0.087\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Test Case 5:\n",
      "Crime Pattern: 'district_bangalore cyber_crimes cheating fraud theft auto_theft riots'\n",
      "Predicted State: KERALA\n",
      "Confidence: 0.225\n",
      "Top 3 predictions:\n",
      "  1. KERALA: 0.225\n",
      "  2. WEST BENGAL: 0.104\n",
      "  3. JAMMU & KASHMIR: 0.078\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Crime Classification Pipeline Completed!\n",
      "📊 Final Model Summary:\n",
      "   - Dataset Size: 49200 records\n",
      "   - States/UTs: 71\n",
      "   - Model Accuracy: 0.5352\n",
      "   - TF-IDF Features: 2894\n",
      "   - Task: Predict State/UT from crime pattern data\n"
     ]
    }
   ],
   "source": [
    "# Crime Classification using TF-IDF and Logistic Regression\n",
    "# Complete script for data.ipynb - Updated for Crime Statistics Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Starting Crime Classification Pipeline...\")\n",
    "print(\"📊 This script will predict STATE/UT based on district crime patterns\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: READ AND MERGE ALL CSV FILES FROM crime/ FOLDER\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_merge_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Read all CSV files from the specified folder and merge them into one DataFrame\n",
    "    \"\"\"\n",
    "    print(f\"📂 Loading CSV files from: {folder_path}\")\n",
    "    \n",
    "    # Get all CSV files in the crime folder\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    print(f\"📄 Found {len(csv_files)} CSV files:\")\n",
    "    for file in csv_files:\n",
    "        print(f\"   - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Read and combine all CSV files\n",
    "    dataframes = []\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"   ✅ Loaded {file}: {len(df)} rows\")\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"   ❌ Error loading {file}: {e}\")\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"🔗 Combined dataset shape: {combined_df.shape}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Load the data - Update this path to match your system\n",
    "crime_folder = r\"C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\"\n",
    "df = load_and_merge_csv_files(crime_folder)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\n📊 Dataset Overview:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['STATE/UT', 'DISTRICT']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Required column '{col}' not found in dataset\")\n",
    "\n",
    "# Display label distribution\n",
    "print(f\"\\n🏷️ State Distribution:\")\n",
    "print(df['STATE/UT'].value_counts())\n",
    "\n",
    "print(f\"\\n🏷️ District Distribution (Top 10):\")\n",
    "print(df['DISTRICT'].value_counts().head(10))\n",
    "\n",
    "# Get all crime-related columns (exclude STATE/UT, DISTRICT, YEAR)\n",
    "crime_columns = [col for col in df.columns if col not in ['STATE/UT', 'DISTRICT', 'YEAR']]\n",
    "print(f\"\\n📊 Crime Categories Found: {len(crime_columns)}\")\n",
    "print(\"Sample crime columns:\", crime_columns[:5])\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: DATA PREPROCESSING AND FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🧹 Preprocessing and preparing features...\")\n",
    "\n",
    "# Remove rows with missing values in key columns\n",
    "print(f\"🔍 Before cleaning - Total samples: {len(df)}\")\n",
    "print(f\"Missing values in STATE/UT: {df['STATE/UT'].isnull().sum()}\")\n",
    "print(f\"Missing values in DISTRICT: {df['DISTRICT'].isnull().sum()}\")\n",
    "\n",
    "# Drop rows where either STATE/UT or DISTRICT is missing\n",
    "df = df.dropna(subset=['STATE/UT', 'DISTRICT']).reset_index(drop=True)\n",
    "\n",
    "# Fill missing values in crime columns with 0 (assuming missing = no crimes reported)\n",
    "for col in crime_columns:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "print(f\"✅ After cleaning: {len(df)} samples remaining\")\n",
    "\n",
    "# Check if we still have enough data\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"No valid data remaining after cleaning!\")\n",
    "\n",
    "# Create a text representation of crime data for each district\n",
    "def create_crime_description(row):\n",
    "    \"\"\"\n",
    "    Create a text description of crime patterns for TF-IDF processing\n",
    "    \"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    # Add district name\n",
    "    descriptions.append(f\"district_{row['DISTRICT'].lower().replace(' ', '_')}\")\n",
    "    \n",
    "    # Add crime patterns - mention each crime type multiple times based on frequency\n",
    "    for col in crime_columns:\n",
    "        crime_count = int(row[col]) if not pd.isna(row[col]) else 0\n",
    "        if crime_count > 0:\n",
    "            # Normalize crime name for text processing\n",
    "            crime_name = col.lower().replace(' ', '_').replace('/', '_').replace('&', 'and')\n",
    "            \n",
    "            # Add crime type multiple times based on scaled frequency\n",
    "            # Scale down large numbers to avoid overwhelming the text\n",
    "            scaled_count = min(max(1, int(crime_count / 10)), 50)  # Scale and cap\n",
    "            descriptions.extend([crime_name] * scaled_count)\n",
    "    \n",
    "    return ' '.join(descriptions)\n",
    "\n",
    "print(\"🔤 Creating text representations of crime patterns...\")\n",
    "df['crime_text'] = df.apply(create_crime_description, axis=1)\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"📊 States after cleaning: {df['STATE/UT'].nunique()} unique states\")\n",
    "state_counts = df['STATE/UT'].value_counts()\n",
    "print(f\"State distribution:\\n{state_counts}\")\n",
    "\n",
    "# Filter out states with very few samples (less than 2) to avoid stratify issues\n",
    "min_samples = 2\n",
    "states_to_keep = state_counts[state_counts >= min_samples].index\n",
    "df = df[df['STATE/UT'].isin(states_to_keep)].reset_index(drop=True)\n",
    "\n",
    "print(f\"📊 After filtering: {len(df)} samples with {df['STATE/UT'].nunique()} states\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n📝 Sample crime text representations:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"State: {df.iloc[i]['STATE/UT']}\")\n",
    "    print(f\"District: {df.iloc[i]['DISTRICT']}\")\n",
    "    print(f\"Crime Text: {df.iloc[i]['crime_text'][:200]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: SPLIT DATASET INTO TRAINING AND TESTING SETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n✂️ Splitting dataset into training and testing sets...\")\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df['crime_text']    # Using crime pattern text as features\n",
    "y = df['STATE/UT']      # Using STATE/UT as the target label\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"🔍 Final check - Missing values in X: {X.isnull().sum()}\")\n",
    "print(f\"🔍 Final check - Missing values in y: {y.isnull().sum()}\")\n",
    "\n",
    "# Check if we have enough samples for each class for stratified split\n",
    "y_counts = y.value_counts()\n",
    "min_class_count = y_counts.min()\n",
    "print(f\"📊 Minimum samples per state: {min_class_count}\")\n",
    "\n",
    "# Adjust stratify parameter based on minimum class count\n",
    "if min_class_count >= 2:\n",
    "    stratify_param = y\n",
    "    print(\"✅ Using stratified split\")\n",
    "else:\n",
    "    stratify_param = None\n",
    "    print(\"⚠️ Using random split (some states have too few samples for stratified split)\")\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=stratify_param  # Use stratified split only if possible\n",
    ")\n",
    "\n",
    "print(f\"📈 Training set size: {len(X_train)} samples\")\n",
    "print(f\"📉 Testing set size: {len(X_test)} samples\")\n",
    "print(f\"🎯 Number of unique states: {len(y.unique())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: TEXT VECTORIZATION USING TF-IDF\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔤 Vectorizing text data using TF-IDF...\")\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,     # Limit to top 10,000 features\n",
    "    ngram_range=(1, 2),     # Use both unigrams and bigrams\n",
    "    min_df=2,               # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.95,            # Ignore terms that appear in more than 95% of documents\n",
    "    stop_words='english'    # Remove common English stop words\n",
    ")\n",
    "\n",
    "# Fit and transform training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform test data (don't fit again!)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"✅ TF-IDF vectorization completed\")\n",
    "print(f\"📊 Training features shape: {X_train_tfidf.shape}\")\n",
    "print(f\"📊 Testing features shape: {X_test_tfidf.shape}\")\n",
    "print(f\"📚 Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: TRAIN LOGISTIC REGRESSION CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🤖 Training Logistic Regression classifier...\")\n",
    "\n",
    "# Initialize and train the classifier\n",
    "lr_classifier = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,          # Increase max iterations for convergence\n",
    "    C=1.0                   # Regularization strength\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lr_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"✅ Model training completed!\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n📈 Evaluating model performance...\")\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = lr_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 Model Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Generate detailed classification report\n",
    "print(f\"\\n📋 Detailed Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(f\"\\n🔍 Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Show prediction probabilities for a few test samples\n",
    "print(f\"\\n🎲 Sample Predictions with Confidence:\")\n",
    "sample_indices = np.random.choice(len(X_test), 3, replace=False)\n",
    "for idx in sample_indices:\n",
    "    sample_text = X_test.iloc[idx]\n",
    "    true_label = y_test.iloc[idx]\n",
    "    predicted_label = y_pred[idx]\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = lr_classifier.predict_proba(X_test_tfidf[idx])\n",
    "    max_prob = np.max(probabilities)\n",
    "    \n",
    "    print(f\"\\nSample {idx + 1}:\")\n",
    "    print(f\"Text: '{sample_text[:100]}...'\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {predicted_label} (Confidence: {max_prob:.3f})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: TEST MODEL ON CUSTOM CRIME PATTERNS\n",
    "# ============================================================================\n",
    "\n",
    "def predict_state_from_crimes(crime_pattern_text, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Predict state from a crime pattern description\n",
    "    \"\"\"\n",
    "    # Vectorize the text\n",
    "    text_tfidf = vectorizer.transform([crime_pattern_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(text_tfidf)[0]\n",
    "    probabilities = model.predict_proba(text_tfidf)[0]\n",
    "    confidence = np.max(probabilities)\n",
    "    \n",
    "    # Get all class probabilities\n",
    "    classes = model.classes_\n",
    "    prob_dict = dict(zip(classes, probabilities))\n",
    "    \n",
    "    return prediction, confidence, prob_dict\n",
    "\n",
    "print(\"\\n🔮 Testing model on custom crime patterns:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample custom crime patterns for testing\n",
    "test_cases = [\n",
    "    \"district_mumbai murder murder robbery theft theft burglary cheating fraud\",\n",
    "    \"district_delhi rape kidnapping_abduction assault theft auto_theft riots\",\n",
    "    \"district_chennai dowry_deaths cruelty_by_husband murder hurt_grevious_hurt theft\",\n",
    "    \"district_kolkata theft burglary robbery cheating counterfieting arson\",\n",
    "    \"district_bangalore cyber_crimes cheating fraud theft auto_theft riots\"\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n🔍 Test Case {i}:\")\n",
    "    print(f\"Crime Pattern: '{test_case}'\")\n",
    "    \n",
    "    prediction, confidence, probabilities = predict_state_from_crimes(\n",
    "        test_case, lr_classifier, tfidf\n",
    "    )\n",
    "    \n",
    "    print(f\"Predicted State: {prediction}\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    # Show top 3 most likely states\n",
    "    sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(\"Top 3 predictions:\")\n",
    "    for j, (state, prob) in enumerate(sorted_probs[:3], 1):\n",
    "        print(f\"  {j}. {state}: {prob:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: INTERACTIVE PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def interactive_state_prediction():\n",
    "    \"\"\"\n",
    "    Interactive function to test custom crime patterns\n",
    "    \"\"\"\n",
    "    print(\"\\n🎯 Interactive State Prediction from Crime Patterns\")\n",
    "    print(\"Enter crime types and counts (e.g., 'murder theft robbery burglary') or 'quit' to exit:\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n📝 Crime Pattern: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"👋 Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if len(user_input.strip()) == 0:\n",
    "            print(\"❌ Please enter a valid crime pattern.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            prediction, confidence, probabilities = predict_state_from_crimes(\n",
    "                user_input, lr_classifier, tfidf\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n🎯 Prediction Results:\")\n",
    "            print(f\"Predicted State: {prediction}\")\n",
    "            print(f\"Confidence Score: {confidence:.3f}\")\n",
    "            \n",
    "            # Show all probabilities\n",
    "            print(f\"\\nAll State Probabilities:\")\n",
    "            sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "            for state, prob in sorted_probs[:10]:  # Show top 10\n",
    "                print(f\"  {state}: {prob:.3f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error making prediction: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Crime Classification Pipeline Completed!\")\n",
    "print(f\"📊 Final Model Summary:\")\n",
    "print(f\"   - Dataset Size: {len(df)} records\")\n",
    "print(f\"   - States/UTs: {len(y.unique())}\")\n",
    "print(f\"   - Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   - TF-IDF Features: {len(tfidf.vocabulary_)}\")\n",
    "print(f\"   - Task: Predict State/UT from crime pattern data\")\n",
    "\n",
    "# Uncomment the line below to run interactive predictions\n",
    "# interactive_state_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5392dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this after loading data to standardize state names\n",
    "df['STATE/UT'] = df['STATE/UT'].str.upper().str.strip()\n",
    "df = df[~df['STATE/UT'].str.contains('TOTAL|Total', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad80fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on major crime categories instead of all 656 columns\n",
    "major_crimes = ['MURDER', 'RAPE', 'KIDNAPPING & ABDUCTION', 'DACOITY', \n",
    "                'ROBBERY', 'BURGLARY', 'THEFT', 'RIOTS', 'CHEATING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb309a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "lr_classifier = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589339bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac877b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Interactive State Prediction from Crime Patterns\n",
      "Enter crime types and counts (e.g., 'murder theft robbery burglary') or 'quit' to exit:\n",
      "❌ Error making prediction: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.\n"
     ]
    }
   ],
   "source": [
    "interactive_state_prediction(\n",
    ")\n",
    "# Then test with: \"murder theft robbery burglary riots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1f2c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Enhanced Crime Classification Pipeline...\n",
      "📊 Improvements: Data cleaning, Feature selection, Model comparison\n",
      "======================================================================\n",
      "📂 Loading CSV files from: C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\n",
      "📄 Found 57 CSV files\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2013.csv: 823 rows\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2014.csv: 838 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2013.csv: 823 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2014.csv: 837 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2013.csv: 823 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2014.csv: 837 rows\n",
      "   ✅ Loaded 03_District_wise_crimes_committed_against_children_2001_2012.csv: 9015 rows\n",
      "   ✅ Loaded 03_District_wise_crimes_committed_against_children_2013.csv: 823 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv: 494 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv: 494 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv: 2028 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv: 1026 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv: 418 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv: 2730 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv: 1140 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv: 1140 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv: 3432 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv: 1140 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv: 1140 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv: 3432 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv: 1026 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv: 1026 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv: 2730 rows\n",
      "   ✅ Loaded 08_01_Juvenile_apprehended_state_IPC.csv: 10500 rows\n",
      "   ✅ Loaded 08_02_Juvenile_apprehended_state_SLL.csv: 9450 rows\n",
      "   ✅ Loaded 09_Juveniles_arrested_and_their_disposal.csv: 349 rows\n",
      "   ✅ Loaded 11_Property_stolen_and_recovered_nature_of_property.csv: 4550 rows\n",
      "   ✅ Loaded 12_Police_strength_actual_and_sanctioned.csv: 4188 rows\n",
      "   ✅ Loaded 13_Police_killed_or_injured_on_duty.csv: 2450 rows\n",
      "   ✅ Loaded 14_Age_profile_of_police_personnel_killed_on_duty.csv: 350 rows\n",
      "   ✅ Loaded 15_Police_natural_death_and_suicide.csv: 700 rows\n",
      "   ✅ Loaded 16_Casualties_under_police_firing_and_lathi_charge.csv: 1749 rows\n",
      "   ✅ Loaded 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv: 4344 rows\n",
      "   ✅ Loaded 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv: 385 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2001_2012.csv: 456 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2013.csv: 38 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2014.csv: 39 rows\n",
      "   ✅ Loaded 18_01_Juveniles_arrested_Education.csv: 350 rows\n",
      "   ✅ Loaded 18_02_Juveniles_arrested_Economic_setup.csv: 350 rows\n",
      "   ✅ Loaded 18_03_Juveniles_arrested_Family_background.csv: 350 rows\n",
      "   ✅ Loaded 18_04_Juveniles_arrested_Recidivism.csv: 350 rows\n",
      "   ✅ Loaded 19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv: 350 rows\n",
      "   ✅ Loaded 21_Offenders_known_to_the_victim.csv: 350 rows\n",
      "   ✅ Loaded 22_Persons_arrested_under_recidivism.csv: 350 rows\n",
      "   ✅ Loaded 23_Anti_corruprion_cases.csv: 346 rows\n",
      "   ✅ Loaded 24_Anti_corruption_arrests.csv: 347 rows\n",
      "   ✅ Loaded 27_Nature_of_complaints_received_by_police.csv: 349 rows\n",
      "   ✅ Loaded 34_Use_of_fire_arms_in_murder_cases.csv: 284 rows\n",
      "   ✅ Loaded 37_Home_guards_and_auxilliary_force.csv: 333 rows\n",
      "   ✅ Loaded 38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv: 314 rows\n",
      "   ✅ Loaded 41_Escapes_from_police_custody.csv: 311 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2013.csv: 823 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2014.csv: 837 rows\n",
      "🔗 Combined dataset: (120227, 659)\n",
      "\n",
      "🧹 Enhanced data cleaning and standardization...\n",
      "📊 Removed 0 rows with missing STATE/DISTRICT\n",
      "📊 Remaining samples: 117198\n",
      "\n",
      "📊 Data Quality Check:\n",
      "Unique states: 39\n",
      "Unique districts: 841\n",
      "📊 After filtering (min 50 samples): 117198 samples, 39 states\n",
      "Top states: ['NAN', 'UTTAR PRADESH', 'MADHYA PRADESH', 'MAHARASHTRA', 'BIHAR']\n",
      "\n",
      "🔧 Enhanced feature engineering...\n",
      "\n",
      "🎯 Selecting major crime features...\n",
      "📋 Selected 243 major crime columns\n",
      "Sample columns: ['MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE']\n",
      "🔤 Creating enhanced text representations...\n",
      "📊 Final dataset: 117198 samples\n",
      "\n",
      "📝 Sample enhanced crime descriptions:\n",
      "State: ANDHRA PRADESH\n",
      "District: ADILABAD\n",
      "Enhanced Text: district_adilabad period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_gr...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: ANANTAPUR\n",
      "Enhanced Text: district_anantapur period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_g...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: CHITTOOR\n",
      "Enhanced Text: district_chittoor period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_gr...\n",
      "--------------------------------------------------\n",
      "\n",
      "✂️ Enhanced data splitting...\n",
      "📊 Class distribution stats:\n",
      "   Most samples: 36810 (NAN)\n",
      "   Least samples: 199 (D & N HAVELI)\n",
      "   Mean samples per state: 3005.1\n",
      "📈 Training set: 93758 samples\n",
      "📉 Test set: 23440 samples\n",
      "🎯 States to predict: 39\n",
      "\n",
      "🔤 Optimized TF-IDF vectorization...\n",
      "✅ TF-IDF completed\n",
      "📊 Feature matrix: (93758, 5000)\n",
      "📚 Vocabulary size: 5000\n",
      "\n",
      "🤖 Training and comparing multiple models...\n",
      "\n",
      "🔄 Training Logistic Regression...\n",
      "✅ Logistic Regression Accuracy: 0.6936 (69.36%)\n",
      "\n",
      "🔄 Training Random Forest...\n",
      "✅ Random Forest Accuracy: 0.2372 (23.72%)\n",
      "\n",
      "🔄 Training SVM (Linear)...\n",
      "✅ SVM (Linear) Accuracy: 0.7003 (70.03%)\n",
      "\n",
      "🏆 Best Model: SVM (Linear) with 0.7003 accuracy\n",
      "\n",
      "📈 Detailed evaluation of best model (SVM (Linear))...\n",
      "\n",
      "📋 Classification Report:\n",
      "============================================================\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    A & N ISLANDS       0.78      0.35      0.48        52\n",
      "      A&N ISLANDS       0.03      0.10      0.04       167\n",
      "   ANDHRA PRADESH       0.99      0.69      0.81       582\n",
      "ARUNACHAL PRADESH       0.98      0.49      0.66       392\n",
      "            ASSAM       0.94      0.62      0.75       574\n",
      "            BIHAR       0.99      0.74      0.85       763\n",
      "       CHANDIGARH       1.00      0.06      0.11       204\n",
      "     CHHATTISGARH       0.93      0.54      0.68       472\n",
      "     D & N HAVELI       0.88      0.35      0.50        40\n",
      "       D&N HAVELI       0.02      0.04      0.03       164\n",
      "      DAMAN & DIU       1.00      0.12      0.21       217\n",
      "            DELHI       0.53      0.79      0.63       165\n",
      "         DELHI UT       0.89      0.14      0.25       216\n",
      "              GOA       0.90      0.12      0.21       217\n",
      "          GUJARAT       0.97      0.65      0.78       598\n",
      "          HARYANA       0.93      0.54      0.68       471\n",
      " HIMACHAL PRADESH       0.82      0.48      0.60       370\n",
      "  JAMMU & KASHMIR       0.97      0.60      0.74       532\n",
      "        JHARKHAND       1.00      0.64      0.78       517\n",
      "        KARNATAKA       0.99      0.66      0.79       613\n",
      "           KERALA       0.93      0.50      0.65       432\n",
      "      LAKSHADWEEP       1.00      0.08      0.15       204\n",
      "   MADHYA PRADESH       0.95      0.77      0.85       861\n",
      "      MAHARASHTRA       0.98      0.74      0.84       777\n",
      "          MANIPUR       1.00      0.41      0.58       314\n",
      "        MEGHALAYA       1.00      0.32      0.48       286\n",
      "          MIZORAM       0.98      0.41      0.57       297\n",
      "         NAGALAND       1.00      0.48      0.65       328\n",
      "              NAN       0.57      1.00      0.72      7362\n",
      "           ODISHA       0.99      0.68      0.81       646\n",
      "       PUDUCHERRY       0.88      0.11      0.19       212\n",
      "           PUNJAB       0.99      0.56      0.72       521\n",
      "        RAJASTHAN       0.96      0.67      0.79       677\n",
      "           SIKKIM       0.66      0.17      0.27       244\n",
      "       TAMIL NADU       0.98      0.72      0.83       688\n",
      "          TRIPURA       0.84      0.11      0.19       255\n",
      "    UTTAR PRADESH       0.94      0.82      0.88      1133\n",
      "      UTTARAKHAND       1.00      0.43      0.60       360\n",
      "      WEST BENGAL       0.99      0.62      0.76       517\n",
      "\n",
      "         accuracy                           0.70     23440\n",
      "        macro avg       0.88      0.47      0.57     23440\n",
      "     weighted avg       0.82      0.70      0.69     23440\n",
      "\n",
      "\n",
      "🔍 Model Performance Analysis:\n",
      "📊 Top 5 Best Predicted States:\n",
      "   1. UTTAR PRADESH: F1-Score = 0.878\n",
      "   2. MADHYA PRADESH: F1-Score = 0.852\n",
      "   3. BIHAR: F1-Score = 0.846\n",
      "   4. MAHARASHTRA: F1-Score = 0.843\n",
      "   5. TAMIL NADU: F1-Score = 0.832\n",
      "\n",
      "📊 Bottom 5 States (Need Improvement):\n",
      "   1. TRIPURA: F1-Score = 0.188\n",
      "   2. LAKSHADWEEP: F1-Score = 0.145\n",
      "   3. CHANDIGARH: F1-Score = 0.111\n",
      "   4. A&N ISLANDS: F1-Score = 0.043\n",
      "   5. D&N HAVELI: F1-Score = 0.027\n",
      "\n",
      "🔮 Testing enhanced model with realistic crime patterns:\n",
      "============================================================\n",
      "\n",
      "🔍 Enhanced Test Case 1:\n",
      "Pattern: 'district_mumbai crime_theft crime_theft crime_burglary crime_cheating crime_fraud period_recent'\n",
      "Predicted State: JAMMU & KASHMIR\n",
      "Confidence: 0.348\n",
      "Top 3 predictions:\n",
      "  1. MAHARASHTRA: 0.348\n",
      "  2. UTTAR PRADESH: 0.114\n",
      "  3. JAMMU & KASHMIR: 0.063\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Enhanced Test Case 2:\n",
      "Pattern: 'district_delhi crime_murder crime_rape crime_kidnapping crime_theft crime_riots period_recent'\n",
      "Predicted State: JAMMU & KASHMIR\n",
      "Confidence: 0.206\n",
      "Top 3 predictions:\n",
      "  1. UTTAR PRADESH: 0.206\n",
      "  2. BIHAR: 0.149\n",
      "  3. MADHYA PRADESH: 0.081\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Enhanced Test Case 3:\n",
      "Pattern: 'district_chennai crime_dowry_deaths crime_assault crime_theft period_recent'\n",
      "Predicted State: TAMIL NADU\n",
      "Confidence: 0.904\n",
      "Top 3 predictions:\n",
      "  1. TAMIL NADU: 0.904\n",
      "  2. RAJASTHAN: 0.010\n",
      "  3. UTTAR PRADESH: 0.010\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Enhanced Test Case 4:\n",
      "Pattern: 'district_kolkata crime_theft crime_burglary crime_hurt period_mid_2000s'\n",
      "Predicted State: WEST BENGAL\n",
      "Confidence: 0.299\n",
      "Top 3 predictions:\n",
      "  1. WEST BENGAL: 0.299\n",
      "  2. MADHYA PRADESH: 0.106\n",
      "  3. UTTAR PRADESH: 0.075\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Enhanced Test Case 5:\n",
      "Pattern: 'district_patna crime_murder crime_kidnapping crime_dacoity crime_riots period_recent'\n",
      "Predicted State: BIHAR\n",
      "Confidence: 0.844\n",
      "Top 3 predictions:\n",
      "  1. BIHAR: 0.844\n",
      "  2. ASSAM: 0.020\n",
      "  3. MAHARASHTRA: 0.020\n",
      "--------------------------------------------------\n",
      "\n",
      "🔍 Enhanced Test Case 6:\n",
      "Pattern: 'district_jaipur crime_theft crime_cheating crime_burglary period_recent'\n",
      "Predicted State: RAJASTHAN\n",
      "Confidence: 0.599\n",
      "Top 3 predictions:\n",
      "  1. RAJASTHAN: 0.599\n",
      "  2. UTTAR PRADESH: 0.058\n",
      "  3. PUNJAB: 0.047\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Enhanced Crime Classification Pipeline Completed!\n",
      "📊 Enhanced Model Summary:\n",
      "   - Dataset Size: 117198 records\n",
      "   - States/UTs: 39\n",
      "   - Best Model: SVM (Linear)\n",
      "   - Best Accuracy: 0.7003 (70.03%)\n",
      "   - TF-IDF Features: 5000\n",
      "   - Crime Features Used: 243\n",
      "\n",
      "🔧 Key Improvements Made:\n",
      "   ✅ Enhanced data cleaning and standardization\n",
      "   ✅ Focus on major crime categories only\n",
      "   ✅ Balanced class weights for better performance\n",
      "   ✅ Multiple model comparison\n",
      "   ✅ Optimized TF-IDF parameters\n",
      "   ✅ Better feature engineering with time periods\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Crime Classification using TF-IDF and Multiple Models\n",
    "# Improved version addressing data quality and performance issues\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Enhanced Crime Classification Pipeline...\")\n",
    "print(\"📊 Improvements: Data cleaning, Feature selection, Model comparison\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: IMPROVED DATA LOADING AND CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_merge_csv_files(folder_path):\n",
    "    \"\"\"Enhanced CSV loading with better error handling\"\"\"\n",
    "    print(f\"📂 Loading CSV files from: {folder_path}\")\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    print(f\"📄 Found {len(csv_files)} CSV files\")\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            if len(df) > 0:  # Only add non-empty dataframes\n",
    "                dataframes.append(df)\n",
    "                print(f\"   ✅ Loaded {os.path.basename(file)}: {len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Skipped {os.path.basename(file)}: {e}\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No valid dataframes loaded\")\n",
    "    \n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"🔗 Combined dataset: {combined_df.shape}\")\n",
    "    return combined_df\n",
    "\n",
    "def clean_and_standardize_data(df):\n",
    "    \"\"\"Enhanced data cleaning with standardization\"\"\"\n",
    "    print(\"\\n🧹 Enhanced data cleaning and standardization...\")\n",
    "    \n",
    "    # Standardize state names\n",
    "    if 'STATE/UT' in df.columns:\n",
    "        df['STATE/UT'] = df['STATE/UT'].astype(str).str.upper().str.strip()\n",
    "        # Remove totals and summary rows\n",
    "        df = df[~df['STATE/UT'].str.contains('TOTAL|Total|ALL-INDIA|All-India', na=False)]\n",
    "    \n",
    "    # Standardize district names\n",
    "    if 'DISTRICT' in df.columns:\n",
    "        df['DISTRICT'] = df['DISTRICT'].astype(str).str.upper().str.strip()\n",
    "        df = df[~df['DISTRICT'].str.contains('TOTAL|Total', na=False)]\n",
    "    \n",
    "    # Remove rows with missing key columns\n",
    "    before_count = len(df)\n",
    "    df = df.dropna(subset=['STATE/UT', 'DISTRICT']).reset_index(drop=True)\n",
    "    after_count = len(df)\n",
    "    \n",
    "    print(f\"📊 Removed {before_count - after_count} rows with missing STATE/DISTRICT\")\n",
    "    print(f\"📊 Remaining samples: {after_count}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_major_crime_features(df):\n",
    "    \"\"\"Select only major crime categories for better feature quality\"\"\"\n",
    "    print(\"\\n🎯 Selecting major crime features...\")\n",
    "    \n",
    "    # Define major crime categories (most common and interpretable)\n",
    "    major_crime_patterns = [\n",
    "        'MURDER', 'RAPE', 'KIDNAPPING', 'DACOITY', 'ROBBERY', \n",
    "        'BURGLARY', 'THEFT', 'RIOTS', 'CHEATING', 'ARSON',\n",
    "        'HURT', 'DOWRY', 'ASSAULT', 'FRAUD', 'EXTORTION'\n",
    "    ]\n",
    "    \n",
    "    # Find columns that match major crime patterns\n",
    "    selected_columns = []\n",
    "    for col in df.columns:\n",
    "        col_upper = col.upper()\n",
    "        if any(crime in col_upper for crime in major_crime_patterns):\n",
    "            # Skip very specific subcategories to reduce noise\n",
    "            if not any(skip in col_upper for skip in ['TOTAL', 'GRAND', 'SECTION']):\n",
    "                selected_columns.append(col)\n",
    "    \n",
    "    print(f\"📋 Selected {len(selected_columns)} major crime columns\")\n",
    "    print(f\"Sample columns: {selected_columns[:5]}\")\n",
    "    \n",
    "    return selected_columns\n",
    "\n",
    "# Load and clean data\n",
    "crime_folder = r\"C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\"\n",
    "df = load_and_merge_csv_files(crime_folder)\n",
    "df = clean_and_standardize_data(df)\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\n📊 Data Quality Check:\")\n",
    "print(f\"Unique states: {df['STATE/UT'].nunique()}\")\n",
    "print(f\"Unique districts: {df['DISTRICT'].nunique()}\")\n",
    "\n",
    "# Filter out states with too few samples for reliable training\n",
    "min_samples_per_state = 50  # Increased threshold\n",
    "state_counts = df['STATE/UT'].value_counts()\n",
    "valid_states = state_counts[state_counts >= min_samples_per_state].index\n",
    "df = df[df['STATE/UT'].isin(valid_states)].reset_index(drop=True)\n",
    "\n",
    "print(f\"📊 After filtering (min {min_samples_per_state} samples): {len(df)} samples, {df['STATE/UT'].nunique()} states\")\n",
    "print(f\"Top states: {list(df['STATE/UT'].value_counts().head().index)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: ENHANCED FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔧 Enhanced feature engineering...\")\n",
    "\n",
    "# Select major crime features\n",
    "crime_columns = select_major_crime_features(df)\n",
    "\n",
    "# Fill missing values with 0 for crime counts\n",
    "for col in crime_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "def create_enhanced_crime_description(row):\n",
    "    \"\"\"Create more sophisticated crime pattern descriptions\"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    # Add district identifier\n",
    "    district = str(row['DISTRICT']).lower().replace(' ', '_').replace('.', '').replace('(', '').replace(')', '')\n",
    "    descriptions.append(f\"district_{district}\")\n",
    "    \n",
    "    # Add year if available\n",
    "    if 'YEAR' in row and not pd.isna(row['YEAR']):\n",
    "        year = int(row['YEAR'])\n",
    "        if year < 2005:\n",
    "            descriptions.append(\"period_early_2000s\")\n",
    "        elif year < 2010:\n",
    "            descriptions.append(\"period_mid_2000s\")\n",
    "        else:\n",
    "            descriptions.append(\"period_recent\")\n",
    "    \n",
    "    # Process crime counts with better scaling\n",
    "    crime_totals = []\n",
    "    for col in crime_columns:\n",
    "        if col in row and not pd.isna(row[col]):\n",
    "            count = max(0, int(row[col]))\n",
    "            if count > 0:\n",
    "                crime_totals.append((col, count))\n",
    "    \n",
    "    # Sort crimes by frequency to emphasize major patterns\n",
    "    crime_totals.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Add crime patterns with intelligent scaling\n",
    "    total_crimes = sum(count for _, count in crime_totals) or 1\n",
    "    \n",
    "    for crime_type, count in crime_totals:\n",
    "        if count > 0:\n",
    "            # Normalize crime name\n",
    "            crime_name = crime_type.lower().replace(' ', '_').replace('/', '_').replace('&', 'and')\n",
    "            \n",
    "            # Calculate relative frequency\n",
    "            frequency_ratio = count / total_crimes\n",
    "            \n",
    "            # Scale based on both absolute count and relative frequency\n",
    "            if frequency_ratio > 0.3:  # Very dominant crime\n",
    "                repetitions = min(20, max(5, int(count / 50)))\n",
    "            elif frequency_ratio > 0.1:  # Significant crime\n",
    "                repetitions = min(10, max(2, int(count / 100)))\n",
    "            elif count > 10:  # Notable crime\n",
    "                repetitions = min(5, max(1, int(count / 200)))\n",
    "            else:  # Minor crime\n",
    "                repetitions = 1\n",
    "            \n",
    "            descriptions.extend([f\"crime_{crime_name}\"] * repetitions)\n",
    "    \n",
    "    return ' '.join(descriptions)\n",
    "\n",
    "print(\"🔤 Creating enhanced text representations...\")\n",
    "df['crime_text'] = df.apply(create_enhanced_crime_description, axis=1)\n",
    "\n",
    "# Remove empty crime descriptions\n",
    "df = df[df['crime_text'].str.len() > 10].reset_index(drop=True)\n",
    "print(f\"📊 Final dataset: {len(df)} samples\")\n",
    "\n",
    "# Display sample enhanced descriptions\n",
    "print(f\"\\n📝 Sample enhanced crime descriptions:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"State: {df.iloc[i]['STATE/UT']}\")\n",
    "    print(f\"District: {df.iloc[i]['DISTRICT']}\")\n",
    "    print(f\"Enhanced Text: {df.iloc[i]['crime_text'][:150]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: BALANCED DATA SPLITTING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n✂️ Enhanced data splitting...\")\n",
    "\n",
    "X = df['crime_text']\n",
    "y = df['STATE/UT']\n",
    "\n",
    "# Check class distribution\n",
    "y_counts = y.value_counts()\n",
    "print(f\"📊 Class distribution stats:\")\n",
    "print(f\"   Most samples: {y_counts.iloc[0]} ({y_counts.index[0]})\")\n",
    "print(f\"   Least samples: {y_counts.iloc[-1]} ({y_counts.index[-1]})\")\n",
    "print(f\"   Mean samples per state: {y_counts.mean():.1f}\")\n",
    "\n",
    "# Split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"📈 Training set: {len(X_train)} samples\")\n",
    "print(f\"📉 Test set: {len(X_test)} samples\")\n",
    "print(f\"🎯 States to predict: {len(y.unique())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: OPTIMIZED TF-IDF VECTORIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n🔤 Optimized TF-IDF vectorization...\")\n",
    "\n",
    "# Optimized TF-IDF parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,      # Increased feature limit\n",
    "    ngram_range=(1, 3),     # Include trigrams for better patterns\n",
    "    min_df=3,               # Require terms in at least 3 documents\n",
    "    max_df=0.8,             # Remove very common terms\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,      # Use sublinear term frequency\n",
    "    norm='l2'               # L2 normalization\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"✅ TF-IDF completed\")\n",
    "print(f\"📊 Feature matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"📚 Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: MODEL COMPARISON WITH HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n🤖 Training and comparing multiple models...\")\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42, max_iter=1000, class_weight='balanced', C=1.0\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42, n_estimators=100, class_weight='balanced', max_depth=20\n",
    "    ),\n",
    "    'SVM (Linear)': SVC(\n",
    "        random_state=42, kernel='linear', class_weight='balanced', probability=True\n",
    "    )\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n🔄 Training {model_name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"✅ {model_name} Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "best_accuracy = model_results[best_model_name]['accuracy']\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {best_model_name} with {best_accuracy:.4f} accuracy\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: ENHANCED EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n📈 Detailed evaluation of best model ({best_model_name})...\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\n📋 Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Top performing states analysis\n",
    "print(f\"\\n🔍 Model Performance Analysis:\")\n",
    "report_dict = classification_report(y_test, best_predictions, output_dict=True)\n",
    "\n",
    "# Get F1 scores for each state\n",
    "state_f1_scores = [(state, scores['f1-score']) for state, scores in report_dict.items() \n",
    "                   if isinstance(scores, dict) and 'f1-score' in scores]\n",
    "state_f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"📊 Top 5 Best Predicted States:\")\n",
    "for i, (state, f1) in enumerate(state_f1_scores[:5], 1):\n",
    "    print(f\"   {i}. {state}: F1-Score = {f1:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Bottom 5 States (Need Improvement):\")\n",
    "for i, (state, f1) in enumerate(state_f1_scores[-5:], 1):\n",
    "    print(f\"   {i}. {state}: F1-Score = {f1:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: ENHANCED TESTING WITH REALISTIC EXAMPLES\n",
    "# ============================================================================\n",
    "\n",
    "def predict_state_from_crime_pattern(crime_text, model, vectorizer):\n",
    "    \"\"\"Enhanced prediction function\"\"\"\n",
    "    text_tfidf = vectorizer.transform([crime_text])\n",
    "    prediction = model.predict(text_tfidf)[0]\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(text_tfidf)[0]\n",
    "        confidence = np.max(probabilities)\n",
    "        classes = model.classes_\n",
    "        prob_dict = dict(zip(classes, probabilities))\n",
    "    else:\n",
    "        confidence = 1.0  # For models without probability support\n",
    "        prob_dict = {prediction: 1.0}\n",
    "    \n",
    "    return prediction, confidence, prob_dict\n",
    "\n",
    "print(f\"\\n🔮 Testing enhanced model with realistic crime patterns:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# More realistic test cases based on actual data patterns\n",
    "enhanced_test_cases = [\n",
    "    \"district_mumbai crime_theft crime_theft crime_burglary crime_cheating crime_fraud period_recent\",\n",
    "    \"district_delhi crime_murder crime_rape crime_kidnapping crime_theft crime_riots period_recent\", \n",
    "    \"district_chennai crime_dowry_deaths crime_assault crime_theft period_recent\",\n",
    "    \"district_kolkata crime_theft crime_burglary crime_hurt period_mid_2000s\",\n",
    "    \"district_patna crime_murder crime_kidnapping crime_dacoity crime_riots period_recent\",\n",
    "    \"district_jaipur crime_theft crime_cheating crime_burglary period_recent\"\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(enhanced_test_cases, 1):\n",
    "    print(f\"\\n🔍 Enhanced Test Case {i}:\")\n",
    "    print(f\"Pattern: '{test_case}'\")\n",
    "    \n",
    "    prediction, confidence, probabilities = predict_state_from_crime_pattern(\n",
    "        test_case, best_model, tfidf\n",
    "    )\n",
    "    \n",
    "    print(f\"Predicted State: {prediction}\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    # Show top 3 predictions\n",
    "    if len(probabilities) > 1:\n",
    "        sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"Top 3 predictions:\")\n",
    "        for j, (state, prob) in enumerate(sorted_probs[:3], 1):\n",
    "            print(f\"  {j}. {state}: {prob:.3f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: INTERACTIVE ENHANCED PREDICTION\n",
    "# ============================================================================\n",
    "\n",
    "def interactive_enhanced_prediction():\n",
    "    \"\"\"Enhanced interactive prediction with better guidance\"\"\"\n",
    "    print(f\"\\n🎯 Interactive Enhanced Crime Pattern Prediction\")\n",
    "    print(\"Tips for better predictions:\")\n",
    "    print(\"- Include district name: district_[name]\")\n",
    "    print(\"- Add crime types: crime_murder crime_theft crime_robbery\")\n",
    "    print(\"- Optionally add time period: period_recent period_early_2000s\")\n",
    "    print(\"- Example: 'district_bangalore crime_theft crime_cheating crime_fraud period_recent'\")\n",
    "    print(\"\\nEnter pattern or 'quit':\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\n📝 Enhanced Pattern: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"👋 Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if len(user_input.strip()) == 0:\n",
    "            print(\"❌ Please enter a valid pattern.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            prediction, confidence, probabilities = predict_state_from_crime_pattern(\n",
    "                user_input, best_model, tfidf\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n🎯 Enhanced Prediction Results:\")\n",
    "            print(f\"Predicted State: {prediction}\")\n",
    "            print(f\"Confidence: {confidence:.3f}\")\n",
    "            \n",
    "            if len(probabilities) > 1:\n",
    "                print(f\"\\nTop 5 State Probabilities:\")\n",
    "                sorted_probs = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "                for state, prob in sorted_probs[:5]:\n",
    "                    print(f\"  {state}: {prob:.3f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n✅ Enhanced Crime Classification Pipeline Completed!\")\n",
    "print(f\"📊 Enhanced Model Summary:\")\n",
    "print(f\"   - Dataset Size: {len(df)} records\")\n",
    "print(f\"   - States/UTs: {len(y.unique())}\")\n",
    "print(f\"   - Best Model: {best_model_name}\")\n",
    "print(f\"   - Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"   - TF-IDF Features: {len(tfidf.vocabulary_)}\")\n",
    "print(f\"   - Crime Features Used: {len(crime_columns)}\")\n",
    "\n",
    "print(f\"\\n🔧 Key Improvements Made:\")\n",
    "print(f\"   ✅ Enhanced data cleaning and standardization\")\n",
    "print(f\"   ✅ Focus on major crime categories only\")\n",
    "print(f\"   ✅ Balanced class weights for better performance\")\n",
    "print(f\"   ✅ Multiple model comparison\")\n",
    "print(f\"   ✅ Optimized TF-IDF parameters\")\n",
    "print(f\"   ✅ Better feature engineering with time periods\")\n",
    "\n",
    "# Uncomment to run interactive predictions\n",
    "# interactive_enhanced_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922cbe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Enhanced Crime Classification Pipeline...\n",
      "📊 Improvements: Data cleaning, Feature selection, Model comparison, Model Saving\n",
      "======================================================================\n",
      "📂 Loading CSV files from: C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\n",
      "📄 Found 57 CSV files\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2013.csv: 823 rows\n",
      "   ✅ Loaded 01_District_wise_crimes_committed_IPC_2014.csv: 838 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2013.csv: 823 rows\n",
      "   ✅ Loaded 02_01_District_wise_crimes_committed_against_SC_2014.csv: 837 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2001_2012.csv: 9018 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2013.csv: 823 rows\n",
      "   ✅ Loaded 02_District_wise_crimes_committed_against_ST_2014.csv: 837 rows\n",
      "   ✅ Loaded 03_District_wise_crimes_committed_against_children_2001_2012.csv: 9015 rows\n",
      "   ✅ Loaded 03_District_wise_crimes_committed_against_children_2013.csv: 823 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2012.csv: 494 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2013.csv: 494 rows\n",
      "   ✅ Loaded 03_Persons_arrested_and_their_disposal_by_police_and_court_under_crime_against_children_2014.csv: 2028 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2012.csv: 1026 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2013.csv: 418 rows\n",
      "   ✅ Loaded 04_01_Person_arrested_and_their_disposal_by_police_and_court_SLL_crime_2014.csv: 2730 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2012.csv: 1140 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2013.csv: 1140 rows\n",
      "   ✅ Loaded 04_02_Person_arrested_and_their_disposal_by_police_and_court_IPC_crime_2014.csv: 3432 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2012.csv: 1140 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2013.csv: 1140 rows\n",
      "   ✅ Loaded 07_01_Persons_arrested_by_sex_and_age_group_IPC_2014.csv: 3432 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2012.csv: 1026 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2013.csv: 1026 rows\n",
      "   ✅ Loaded 07_02_Persons_arrested_by_sex_and_age_group_SLL_2014.csv: 2730 rows\n",
      "   ✅ Loaded 08_01_Juvenile_apprehended_state_IPC.csv: 10500 rows\n",
      "   ✅ Loaded 08_02_Juvenile_apprehended_state_SLL.csv: 9450 rows\n",
      "   ✅ Loaded 09_Juveniles_arrested_and_their_disposal.csv: 349 rows\n",
      "   ✅ Loaded 11_Property_stolen_and_recovered_nature_of_property.csv: 4550 rows\n",
      "   ✅ Loaded 12_Police_strength_actual_and_sanctioned.csv: 4188 rows\n",
      "   ✅ Loaded 13_Police_killed_or_injured_on_duty.csv: 2450 rows\n",
      "   ✅ Loaded 14_Age_profile_of_police_personnel_killed_on_duty.csv: 350 rows\n",
      "   ✅ Loaded 15_Police_natural_death_and_suicide.csv: 700 rows\n",
      "   ✅ Loaded 16_Casualties_under_police_firing_and_lathi_charge.csv: 1749 rows\n",
      "   ✅ Loaded 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2001_2012.csv: 4344 rows\n",
      "   ✅ Loaded 17_Case_reported_and_value_of_property_taken_away_by_place_of_occurrence_2013.csv: 385 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2001_2012.csv: 456 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2013.csv: 38 rows\n",
      "   ✅ Loaded 17_Crime_by_place_of_occurrence_2014.csv: 39 rows\n",
      "   ✅ Loaded 18_01_Juveniles_arrested_Education.csv: 350 rows\n",
      "   ✅ Loaded 18_02_Juveniles_arrested_Economic_setup.csv: 350 rows\n",
      "   ✅ Loaded 18_03_Juveniles_arrested_Family_background.csv: 350 rows\n",
      "   ✅ Loaded 18_04_Juveniles_arrested_Recidivism.csv: 350 rows\n",
      "   ✅ Loaded 19_Motive_or_cause_of_murder_and_culpable_homicide_not_amounting_to_murder.csv: 350 rows\n",
      "   ✅ Loaded 21_Offenders_known_to_the_victim.csv: 350 rows\n",
      "   ✅ Loaded 22_Persons_arrested_under_recidivism.csv: 350 rows\n",
      "   ✅ Loaded 23_Anti_corruprion_cases.csv: 346 rows\n",
      "   ✅ Loaded 24_Anti_corruption_arrests.csv: 347 rows\n",
      "   ✅ Loaded 27_Nature_of_complaints_received_by_police.csv: 349 rows\n",
      "   ✅ Loaded 34_Use_of_fire_arms_in_murder_cases.csv: 284 rows\n",
      "   ✅ Loaded 37_Home_guards_and_auxilliary_force.csv: 333 rows\n",
      "   ✅ Loaded 38_Unidentified_dead_bodies_recovered_and_inquest_conducted.csv: 314 rows\n",
      "   ✅ Loaded 41_Escapes_from_police_custody.csv: 311 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2001_2012.csv: 9017 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2013.csv: 823 rows\n",
      "   ✅ Loaded 42_District_wise_crimes_committed_against_women_2014.csv: 837 rows\n",
      "🔗 Combined dataset: (120227, 659)\n",
      "\n",
      "🧹 Enhanced data cleaning and standardization...\n",
      "📊 Removed 0 rows with missing STATE/DISTRICT\n",
      "📊 Remaining samples: 117198\n",
      "\n",
      "📊 Data Quality Check:\n",
      "Unique states: 39\n",
      "Unique districts: 841\n",
      "📊 After filtering (min 50 samples): 117198 samples, 39 states\n",
      "Top states: ['NAN', 'UTTAR PRADESH', 'MADHYA PRADESH', 'MAHARASHTRA', 'BIHAR']\n",
      "\n",
      "🔧 Enhanced feature engineering...\n",
      "\n",
      "🎯 Selecting major crime features...\n",
      "📋 Selected 243 major crime columns\n",
      "Sample columns: ['MURDER', 'ATTEMPT TO MURDER', 'CULPABLE HOMICIDE NOT AMOUNTING TO MURDER', 'RAPE', 'CUSTODIAL RAPE']\n",
      "🔤 Creating enhanced text representations...\n",
      "📊 Final dataset: 117198 samples\n",
      "\n",
      "📝 Sample enhanced crime descriptions:\n",
      "State: ANDHRA PRADESH\n",
      "District: ADILABAD\n",
      "Enhanced Text: district_adilabad period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_gr...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: ANANTAPUR\n",
      "Enhanced Text: district_anantapur period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_g...\n",
      "--------------------------------------------------\n",
      "State: ANDHRA PRADESH\n",
      "District: CHITTOOR\n",
      "Enhanced Text: district_chittoor period_early_2000s crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_grevious_hurt crime_hurt_gr...\n",
      "--------------------------------------------------\n",
      "\n",
      "✂️ Enhanced data splitting...\n",
      "📊 Class distribution stats:\n",
      "   Most samples: 36810 (NAN)\n",
      "   Least samples: 199 (D & N HAVELI)\n",
      "   Mean samples per state: 3005.1\n",
      "📈 Training set: 93758 samples\n",
      "📉 Test set: 23440 samples\n",
      "🎯 States to predict: 39\n",
      "\n",
      "🔤 Optimized TF-IDF vectorization...\n",
      "✅ TF-IDF completed\n",
      "📊 Feature matrix: (93758, 5000)\n",
      "📚 Vocabulary size: 5000\n",
      "\n",
      "🤖 Training and comparing multiple models...\n",
      "\n",
      "🔄 Training Logistic Regression...\n",
      "✅ Logistic Regression Accuracy: 0.6936 (69.36%)\n",
      "\n",
      "🔄 Training Random Forest...\n",
      "✅ Random Forest Accuracy: 0.2372 (23.72%)\n",
      "\n",
      "🔄 Training SVM (Linear)...\n",
      "✅ SVM (Linear) Accuracy: 0.7003 (70.03%)\n",
      "\n",
      "🏆 Best Model: SVM (Linear) with 0.7003 accuracy\n",
      "\n",
      "💾 Saving model components...\n",
      "✅ Model saved: saved_models\\svm_(linear)_20250921_165628\\model.pkl\n",
      "✅ Vectorizer saved: saved_models\\svm_(linear)_20250921_165628\\vectorizer.pkl\n",
      "✅ Metadata saved: saved_models\\svm_(linear)_20250921_165628\\metadata.pkl\n",
      "✅ Model info saved: saved_models\\svm_(linear)_20250921_165628\\model_info.txt\n",
      "\n",
      "🎉 Model successfully saved to: saved_models\\svm_(linear)_20250921_165628\n",
      "\n",
      "🔄 Testing model loading and prediction...\n",
      "\n",
      "📥 Loading model from: saved_models\\svm_(linear)_20250921_165628\n",
      "✅ Model loaded: saved_models\\svm_(linear)_20250921_165628\\model.pkl\n",
      "✅ Vectorizer loaded: saved_models\\svm_(linear)_20250921_165628\\vectorizer.pkl\n",
      "✅ Metadata loaded: saved_models\\svm_(linear)_20250921_165628\\metadata.pkl\n",
      "\n",
      "🧪 Testing loaded model with sample cases:\n",
      "\n",
      "Test Case 1: district_mumbai crime_theft crime_theft crime_burglary crime...\n",
      "Prediction: JAMMU & KASHMIR (Confidence: 0.348)\n",
      "\n",
      "Test Case 2: district_delhi crime_murder crime_rape crime_kidnapping crim...\n",
      "Prediction: JAMMU & KASHMIR (Confidence: 0.206)\n",
      "\n",
      "Test Case 3: district_chennai crime_dowry_deaths crime_assault crime_thef...\n",
      "Prediction: TAMIL NADU (Confidence: 0.904)\n",
      "\n",
      "📈 Detailed evaluation of best model (SVM (Linear))...\n",
      "\n",
      "📋 Classification Report:\n",
      "============================================================\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    A & N ISLANDS       0.78      0.35      0.48        52\n",
      "      A&N ISLANDS       0.03      0.10      0.04       167\n",
      "   ANDHRA PRADESH       0.99      0.69      0.81       582\n",
      "ARUNACHAL PRADESH       0.98      0.49      0.66       392\n",
      "            ASSAM       0.94      0.62      0.75       574\n",
      "            BIHAR       0.99      0.74      0.85       763\n",
      "       CHANDIGARH       1.00      0.06      0.11       204\n",
      "     CHHATTISGARH       0.93      0.54      0.68       472\n",
      "     D & N HAVELI       0.88      0.35      0.50        40\n",
      "       D&N HAVELI       0.02      0.04      0.03       164\n",
      "      DAMAN & DIU       1.00      0.12      0.21       217\n",
      "            DELHI       0.53      0.79      0.63       165\n",
      "         DELHI UT       0.89      0.14      0.25       216\n",
      "              GOA       0.90      0.12      0.21       217\n",
      "          GUJARAT       0.97      0.65      0.78       598\n",
      "          HARYANA       0.93      0.54      0.68       471\n",
      " HIMACHAL PRADESH       0.82      0.48      0.60       370\n",
      "  JAMMU & KASHMIR       0.97      0.60      0.74       532\n",
      "        JHARKHAND       1.00      0.64      0.78       517\n",
      "        KARNATAKA       0.99      0.66      0.79       613\n",
      "           KERALA       0.93      0.50      0.65       432\n",
      "      LAKSHADWEEP       1.00      0.08      0.15       204\n",
      "   MADHYA PRADESH       0.95      0.77      0.85       861\n",
      "      MAHARASHTRA       0.98      0.74      0.84       777\n",
      "          MANIPUR       1.00      0.41      0.58       314\n",
      "        MEGHALAYA       1.00      0.32      0.48       286\n",
      "          MIZORAM       0.98      0.41      0.57       297\n",
      "         NAGALAND       1.00      0.48      0.65       328\n",
      "              NAN       0.57      1.00      0.72      7362\n",
      "           ODISHA       0.99      0.68      0.81       646\n",
      "       PUDUCHERRY       0.88      0.11      0.19       212\n",
      "           PUNJAB       0.99      0.56      0.72       521\n",
      "        RAJASTHAN       0.96      0.67      0.79       677\n",
      "           SIKKIM       0.66      0.17      0.27       244\n",
      "       TAMIL NADU       0.98      0.72      0.83       688\n",
      "          TRIPURA       0.84      0.11      0.19       255\n",
      "    UTTAR PRADESH       0.94      0.82      0.88      1133\n",
      "      UTTARAKHAND       1.00      0.43      0.60       360\n",
      "      WEST BENGAL       0.99      0.62      0.76       517\n",
      "\n",
      "         accuracy                           0.70     23440\n",
      "        macro avg       0.88      0.47      0.57     23440\n",
      "     weighted avg       0.82      0.70      0.69     23440\n",
      "\n",
      "\n",
      "🔍 Model Performance Analysis:\n",
      "📊 Top 5 Best Predicted States:\n",
      "   1. UTTAR PRADESH: F1-Score = 0.878\n",
      "   2. MADHYA PRADESH: F1-Score = 0.852\n",
      "   3. BIHAR: F1-Score = 0.846\n",
      "   4. MAHARASHTRA: F1-Score = 0.843\n",
      "   5. TAMIL NADU: F1-Score = 0.832\n",
      "\n",
      "📊 Bottom 5 States (Need Improvement):\n",
      "   1. TRIPURA: F1-Score = 0.188\n",
      "   2. LAKSHADWEEP: F1-Score = 0.145\n",
      "   3. CHANDIGARH: F1-Score = 0.111\n",
      "   4. A&N ISLANDS: F1-Score = 0.043\n",
      "   5. D&N HAVELI: F1-Score = 0.027\n",
      "\n",
      "✅ Enhanced Crime Classification Pipeline with Model Saving Completed!\n",
      "📊 Enhanced Model Summary:\n",
      "   - Dataset Size: 117198 records\n",
      "   - States/UTs: 39\n",
      "   - Best Model: SVM (Linear)\n",
      "   - Best Accuracy: 0.7003 (70.03%)\n",
      "   - TF-IDF Features: 5000\n",
      "   - Crime Features Used: 243\n",
      "   - Model Saved To: saved_models\\svm_(linear)_20250921_165628\n",
      "\n",
      "🔧 Key Features Added:\n",
      "   ✅ Complete model saving with metadata\n",
      "   ✅ Model loading and prediction class\n",
      "   ✅ Batch prediction capability\n",
      "   ✅ Human-readable model information\n",
      "   ✅ Versioned model storage\n",
      "   ✅ Error handling for model I/O\n",
      "\n",
      "📁 Saved Files:\n",
      "   - model.pkl (trained model)\n",
      "   - vectorizer.pkl (TF-IDF vectorizer)\n",
      "   - metadata.pkl (model metadata)\n",
      "   - model_info.txt (human-readable info)\n",
      "\n",
      "🚀 To use the saved model later:\n",
      "   predictor = CrimeClassificationPredictor('saved_models\\svm_(linear)_20250921_165628')\n",
      "   prediction = predictor.predict_state_from_crime_pattern('your_crime_text')\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Crime Classification using TF-IDF and Multiple Models\n",
    "# Improved version addressing data quality and performance issues\n",
    "# Added model saving and loading functionality\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🚀 Enhanced Crime Classification Pipeline...\")\n",
    "print(\"📊 Improvements: Data cleaning, Feature selection, Model comparison, Model Saving\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: IMPROVED DATA LOADING AND CLEANING\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_merge_csv_files(folder_path):\n",
    "    \"\"\"Enhanced CSV loading with better error handling\"\"\"\n",
    "    print(f\"📂 Loading CSV files from: {folder_path}\")\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder_path}\")\n",
    "    \n",
    "    print(f\"📄 Found {len(csv_files)} CSV files\")\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "            if len(df) > 0:  # Only add non-empty dataframes\n",
    "                dataframes.append(df)\n",
    "                print(f\"   ✅ Loaded {os.path.basename(file)}: {len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ⚠️ Skipped {os.path.basename(file)}: {e}\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        raise ValueError(\"No valid dataframes loaded\")\n",
    "    \n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"🔗 Combined dataset: {combined_df.shape}\")\n",
    "    return combined_df\n",
    "\n",
    "def clean_and_standardize_data(df):\n",
    "    \"\"\"Enhanced data cleaning with standardization\"\"\"\n",
    "    print(\"\\n🧹 Enhanced data cleaning and standardization...\")\n",
    "    \n",
    "    # Standardize state names\n",
    "    if 'STATE/UT' in df.columns:\n",
    "        df['STATE/UT'] = df['STATE/UT'].astype(str).str.upper().str.strip()\n",
    "        # Remove totals and summary rows\n",
    "        df = df[~df['STATE/UT'].str.contains('TOTAL|Total|ALL-INDIA|All-India', na=False)]\n",
    "    \n",
    "    # Standardize district names\n",
    "    if 'DISTRICT' in df.columns:\n",
    "        df['DISTRICT'] = df['DISTRICT'].astype(str).str.upper().str.strip()\n",
    "        df = df[~df['DISTRICT'].str.contains('TOTAL|Total', na=False)]\n",
    "    \n",
    "    # Remove rows with missing key columns\n",
    "    before_count = len(df)\n",
    "    df = df.dropna(subset=['STATE/UT', 'DISTRICT']).reset_index(drop=True)\n",
    "    after_count = len(df)\n",
    "    \n",
    "    print(f\"📊 Removed {before_count - after_count} rows with missing STATE/DISTRICT\")\n",
    "    print(f\"📊 Remaining samples: {after_count}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_major_crime_features(df):\n",
    "    \"\"\"Select only major crime categories for better feature quality\"\"\"\n",
    "    print(\"\\n🎯 Selecting major crime features...\")\n",
    "    \n",
    "    # Define major crime categories (most common and interpretable)\n",
    "    major_crime_patterns = [\n",
    "        'MURDER', 'RAPE', 'KIDNAPPING', 'DACOITY', 'ROBBERY', \n",
    "        'BURGLARY', 'THEFT', 'RIOTS', 'CHEATING', 'ARSON',\n",
    "        'HURT', 'DOWRY', 'ASSAULT', 'FRAUD', 'EXTORTION'\n",
    "    ]\n",
    "    \n",
    "    # Find columns that match major crime patterns\n",
    "    selected_columns = []\n",
    "    for col in df.columns:\n",
    "        col_upper = col.upper()\n",
    "        if any(crime in col_upper for crime in major_crime_patterns):\n",
    "            # Skip very specific subcategories to reduce noise\n",
    "            if not any(skip in col_upper for skip in ['TOTAL', 'GRAND', 'SECTION']):\n",
    "                selected_columns.append(col)\n",
    "    \n",
    "    print(f\"📋 Selected {len(selected_columns)} major crime columns\")\n",
    "    print(f\"Sample columns: {selected_columns[:5]}\")\n",
    "    \n",
    "    return selected_columns\n",
    "\n",
    "# Load and clean data\n",
    "crime_folder = r\"C:\\Users\\ssk08\\OneDrive\\Desktop\\NLP Project\\Model 2\\crime\"\n",
    "df = load_and_merge_csv_files(crime_folder)\n",
    "df = clean_and_standardize_data(df)\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\n📊 Data Quality Check:\")\n",
    "print(f\"Unique states: {df['STATE/UT'].nunique()}\")\n",
    "print(f\"Unique districts: {df['DISTRICT'].nunique()}\")\n",
    "\n",
    "# Filter out states with too few samples for reliable training\n",
    "min_samples_per_state = 50  # Increased threshold\n",
    "state_counts = df['STATE/UT'].value_counts()\n",
    "valid_states = state_counts[state_counts >= min_samples_per_state].index\n",
    "df = df[df['STATE/UT'].isin(valid_states)].reset_index(drop=True)\n",
    "\n",
    "print(f\"📊 After filtering (min {min_samples_per_state} samples): {len(df)} samples, {df['STATE/UT'].nunique()} states\")\n",
    "print(f\"Top states: {list(df['STATE/UT'].value_counts().head().index)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: ENHANCED FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n🔧 Enhanced feature engineering...\")\n",
    "\n",
    "# Select major crime features\n",
    "crime_columns = select_major_crime_features(df)\n",
    "\n",
    "# Fill missing values with 0 for crime counts\n",
    "for col in crime_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "def create_enhanced_crime_description(row):\n",
    "    \"\"\"Create more sophisticated crime pattern descriptions\"\"\"\n",
    "    descriptions = []\n",
    "    \n",
    "    # Add district identifier\n",
    "    district = str(row['DISTRICT']).lower().replace(' ', '_').replace('.', '').replace('(', '').replace(')', '')\n",
    "    descriptions.append(f\"district_{district}\")\n",
    "    \n",
    "    # Add year if available\n",
    "    if 'YEAR' in row and not pd.isna(row['YEAR']):\n",
    "        year = int(row['YEAR'])\n",
    "        if year < 2005:\n",
    "            descriptions.append(\"period_early_2000s\")\n",
    "        elif year < 2010:\n",
    "            descriptions.append(\"period_mid_2000s\")\n",
    "        else:\n",
    "            descriptions.append(\"period_recent\")\n",
    "    \n",
    "    # Process crime counts with better scaling\n",
    "    crime_totals = []\n",
    "    for col in crime_columns:\n",
    "        if col in row and not pd.isna(row[col]):\n",
    "            count = max(0, int(row[col]))\n",
    "            if count > 0:\n",
    "                crime_totals.append((col, count))\n",
    "    \n",
    "    # Sort crimes by frequency to emphasize major patterns\n",
    "    crime_totals.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Add crime patterns with intelligent scaling\n",
    "    total_crimes = sum(count for _, count in crime_totals) or 1\n",
    "    \n",
    "    for crime_type, count in crime_totals:\n",
    "        if count > 0:\n",
    "            # Normalize crime name\n",
    "            crime_name = crime_type.lower().replace(' ', '_').replace('/', '_').replace('&', 'and')\n",
    "            \n",
    "            # Calculate relative frequency\n",
    "            frequency_ratio = count / total_crimes\n",
    "            \n",
    "            # Scale based on both absolute count and relative frequency\n",
    "            if frequency_ratio > 0.3:  # Very dominant crime\n",
    "                repetitions = min(20, max(5, int(count / 50)))\n",
    "            elif frequency_ratio > 0.1:  # Significant crime\n",
    "                repetitions = min(10, max(2, int(count / 100)))\n",
    "            elif count > 10:  # Notable crime\n",
    "                repetitions = min(5, max(1, int(count / 200)))\n",
    "            else:  # Minor crime\n",
    "                repetitions = 1\n",
    "            \n",
    "            descriptions.extend([f\"crime_{crime_name}\"] * repetitions)\n",
    "    \n",
    "    return ' '.join(descriptions)\n",
    "\n",
    "print(\"🔤 Creating enhanced text representations...\")\n",
    "df['crime_text'] = df.apply(create_enhanced_crime_description, axis=1)\n",
    "\n",
    "# Remove empty crime descriptions\n",
    "df = df[df['crime_text'].str.len() > 10].reset_index(drop=True)\n",
    "print(f\"📊 Final dataset: {len(df)} samples\")\n",
    "\n",
    "# Display sample enhanced descriptions\n",
    "print(f\"\\n📝 Sample enhanced crime descriptions:\")\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"State: {df.iloc[i]['STATE/UT']}\")\n",
    "    print(f\"District: {df.iloc[i]['DISTRICT']}\")\n",
    "    print(f\"Enhanced Text: {df.iloc[i]['crime_text'][:150]}...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: BALANCED DATA SPLITTING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n✂️ Enhanced data splitting...\")\n",
    "\n",
    "X = df['crime_text']\n",
    "y = df['STATE/UT']\n",
    "\n",
    "# Check class distribution\n",
    "y_counts = y.value_counts()\n",
    "print(f\"📊 Class distribution stats:\")\n",
    "print(f\"   Most samples: {y_counts.iloc[0]} ({y_counts.index[0]})\")\n",
    "print(f\"   Least samples: {y_counts.iloc[-1]} ({y_counts.index[-1]})\")\n",
    "print(f\"   Mean samples per state: {y_counts.mean():.1f}\")\n",
    "\n",
    "# Split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"📈 Training set: {len(X_train)} samples\")\n",
    "print(f\"📉 Test set: {len(X_test)} samples\")\n",
    "print(f\"🎯 States to predict: {len(y.unique())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: OPTIMIZED TF-IDF VECTORIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n🔤 Optimized TF-IDF vectorization...\")\n",
    "\n",
    "# Optimized TF-IDF parameters\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,      # Increased feature limit\n",
    "    ngram_range=(1, 3),     # Include trigrams for better patterns\n",
    "    min_df=3,               # Require terms in at least 3 documents\n",
    "    max_df=0.8,             # Remove very common terms\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,      # Use sublinear term frequency\n",
    "    norm='l2'               # L2 normalization\n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(f\"✅ TF-IDF completed\")\n",
    "print(f\"📊 Feature matrix: {X_train_tfidf.shape}\")\n",
    "print(f\"📚 Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: MODEL COMPARISON WITH HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n🤖 Training and comparing multiple models...\")\n",
    "\n",
    "# Calculate class weights for handling imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42, max_iter=1000, class_weight='balanced', C=1.0\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        random_state=42, n_estimators=100, class_weight='balanced', max_depth=20\n",
    "    ),\n",
    "    'SVM (Linear)': SVC(\n",
    "        random_state=42, kernel='linear', class_weight='balanced', probability=True\n",
    "    )\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n🔄 Training {model_name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    model_results[model_name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"✅ {model_name} Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(model_results.keys(), key=lambda k: model_results[k]['accuracy'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "best_accuracy = model_results[best_model_name]['accuracy']\n",
    "best_predictions = model_results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {best_model_name} with {best_accuracy:.4f} accuracy\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: MODEL SAVING FUNCTIONALITY\n",
    "# ============================================================================\n",
    "\n",
    "def save_model_components(model, vectorizer, model_name, accuracy, metadata=None):\n",
    "    \"\"\"Save all model components with metadata\"\"\"\n",
    "    print(f\"\\n💾 Saving model components...\")\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    models_dir = \"saved_models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Create timestamp for versioning\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Create model-specific directory\n",
    "    model_dir = os.path.join(models_dir, f\"{model_name.replace(' ', '_').lower()}_{timestamp}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"✅ Model saved: {model_path}\")\n",
    "    \n",
    "    # Save vectorizer\n",
    "    vectorizer_path = os.path.join(model_dir, \"vectorizer.pkl\")\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    print(f\"✅ Vectorizer saved: {vectorizer_path}\")\n",
    "    \n",
    "    # Save metadata\n",
    "    model_metadata = {\n",
    "        'model_name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'training_date': datetime.now().isoformat(),\n",
    "        'n_features': len(vectorizer.vocabulary_),\n",
    "        'n_classes': len(model.classes_) if hasattr(model, 'classes_') else 'unknown',\n",
    "        'classes': list(model.classes_) if hasattr(model, 'classes_') else [],\n",
    "        'vectorizer_params': vectorizer.get_params(),\n",
    "        'model_params': model.get_params(),\n",
    "        'dataset_size': len(X_train) + len(X_test),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test)\n",
    "    }\n",
    "    \n",
    "    if metadata:\n",
    "        model_metadata.update(metadata)\n",
    "    \n",
    "    metadata_path = os.path.join(model_dir, \"metadata.pkl\")\n",
    "    with open(metadata_path, 'wb') as f:\n",
    "        pickle.dump(model_metadata, f)\n",
    "    print(f\"✅ Metadata saved: {metadata_path}\")\n",
    "    \n",
    "    # Save human-readable info\n",
    "    info_path = os.path.join(model_dir, \"model_info.txt\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        f.write(f\"Crime Classification Model Information\\n\")\n",
    "        f.write(f\"====================================\\n\\n\")\n",
    "        f.write(f\"Model: {model_name}\\n\")\n",
    "        f.write(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\\n\")\n",
    "        f.write(f\"Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Features: {len(vectorizer.vocabulary_)}\\n\")\n",
    "        f.write(f\"Classes: {len(model.classes_) if hasattr(model, 'classes_') else 'unknown'}\\n\")\n",
    "        f.write(f\"Dataset Size: {len(X_train) + len(X_test)}\\n\\n\")\n",
    "        f.write(f\"Model Parameters:\\n\")\n",
    "        for param, value in model.get_params().items():\n",
    "            f.write(f\"  {param}: {value}\\n\")\n",
    "        f.write(f\"\\nVectorizer Parameters:\\n\")\n",
    "        for param, value in vectorizer.get_params().items():\n",
    "            f.write(f\"  {param}: {value}\\n\")\n",
    "    print(f\"✅ Model info saved: {info_path}\")\n",
    "    \n",
    "    return model_dir\n",
    "\n",
    "def load_model_components(model_dir):\n",
    "    \"\"\"Load saved model components\"\"\"\n",
    "    print(f\"\\n📥 Loading model from: {model_dir}\")\n",
    "    \n",
    "    # Load model\n",
    "    model_path = os.path.join(model_dir, \"model.pkl\")\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"✅ Model loaded: {model_path}\")\n",
    "    \n",
    "    # Load vectorizer\n",
    "    vectorizer_path = os.path.join(model_dir, \"vectorizer.pkl\")\n",
    "    if not os.path.exists(vectorizer_path):\n",
    "        raise FileNotFoundError(f\"Vectorizer file not found: {vectorizer_path}\")\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "    print(f\"✅ Vectorizer loaded: {vectorizer_path}\")\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(model_dir, \"metadata.pkl\")\n",
    "    metadata = None\n",
    "    if os.path.exists(metadata_path):\n",
    "        with open(metadata_path, 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        print(f\"✅ Metadata loaded: {metadata_path}\")\n",
    "    \n",
    "    return model, vectorizer, metadata\n",
    "\n",
    "# Save the best model\n",
    "additional_metadata = {\n",
    "    'crime_columns': crime_columns,\n",
    "    'states_included': list(y.unique()),\n",
    "    'min_samples_per_state': min_samples_per_state,\n",
    "    'test_accuracy_details': classification_report(y_test, best_predictions, output_dict=True)\n",
    "}\n",
    "\n",
    "saved_model_dir = save_model_components(\n",
    "    best_model, \n",
    "    tfidf, \n",
    "    best_model_name, \n",
    "    best_accuracy,\n",
    "    additional_metadata\n",
    ")\n",
    "\n",
    "print(f\"\\n🎉 Model successfully saved to: {saved_model_dir}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: MODEL LOADING AND TESTING FUNCTIONALITY\n",
    "# ============================================================================\n",
    "\n",
    "class CrimeClassificationPredictor:\n",
    "    \"\"\"A class for making predictions with saved models\"\"\"\n",
    "    \n",
    "    def __init__(self, model_dir):\n",
    "        \"\"\"Initialize predictor with saved model\"\"\"\n",
    "        self.model, self.vectorizer, self.metadata = load_model_components(model_dir)\n",
    "        self.model_dir = model_dir\n",
    "        \n",
    "    def predict_state_from_crime_pattern(self, crime_text):\n",
    "        \"\"\"Make prediction from crime pattern text\"\"\"\n",
    "        text_tfidf = self.vectorizer.transform([crime_text])\n",
    "        prediction = self.model.predict(text_tfidf)[0]\n",
    "        \n",
    "        if hasattr(self.model, 'predict_proba'):\n",
    "            probabilities = self.model.predict_proba(text_tfidf)[0]\n",
    "            confidence = np.max(probabilities)\n",
    "            classes = self.model.classes_\n",
    "            prob_dict = dict(zip(classes, probabilities))\n",
    "        else:\n",
    "            confidence = 1.0\n",
    "            prob_dict = {prediction: 1.0}\n",
    "        \n",
    "        return prediction, confidence, prob_dict\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get model information\"\"\"\n",
    "        return self.metadata\n",
    "    \n",
    "    def predict_batch(self, crime_texts):\n",
    "        \"\"\"Make batch predictions\"\"\"\n",
    "        texts_tfidf = self.vectorizer.transform(crime_texts)\n",
    "        predictions = self.model.predict(texts_tfidf)\n",
    "        \n",
    "        if hasattr(self.model, 'predict_proba'):\n",
    "            probabilities = self.model.predict_proba(texts_tfidf)\n",
    "            confidences = np.max(probabilities, axis=1)\n",
    "        else:\n",
    "            confidences = np.ones(len(predictions))\n",
    "        \n",
    "        return predictions, confidences\n",
    "\n",
    "# Demonstrate model loading and prediction\n",
    "print(f\"\\n🔄 Testing model loading and prediction...\")\n",
    "\n",
    "# Load the saved model\n",
    "predictor = CrimeClassificationPredictor(saved_model_dir)\n",
    "\n",
    "# Test with sample crime patterns\n",
    "test_cases = [\n",
    "    \"district_mumbai crime_theft crime_theft crime_burglary crime_cheating crime_fraud period_recent\",\n",
    "    \"district_delhi crime_murder crime_rape crime_kidnapping crime_theft crime_riots period_recent\", \n",
    "    \"district_chennai crime_dowry_deaths crime_assault crime_theft period_recent\",\n",
    "]\n",
    "\n",
    "print(f\"\\n🧪 Testing loaded model with sample cases:\")\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    prediction, confidence, probabilities = predictor.predict_state_from_crime_pattern(test_case)\n",
    "    print(f\"\\nTest Case {i}: {test_case[:60]}...\")\n",
    "    print(f\"Prediction: {prediction} (Confidence: {confidence:.3f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: ENHANCED EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n📈 Detailed evaluation of best model ({best_model_name})...\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\n📋 Classification Report:\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Top performing states analysis\n",
    "print(f\"\\n🔍 Model Performance Analysis:\")\n",
    "report_dict = classification_report(y_test, best_predictions, output_dict=True)\n",
    "\n",
    "# Get F1 scores for each state\n",
    "state_f1_scores = [(state, scores['f1-score']) for state, scores in report_dict.items() \n",
    "                   if isinstance(scores, dict) and 'f1-score' in scores]\n",
    "state_f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"📊 Top 5 Best Predicted States:\")\n",
    "for i, (state, f1) in enumerate(state_f1_scores[:5], 1):\n",
    "    print(f\"   {i}. {state}: F1-Score = {f1:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Bottom 5 States (Need Improvement):\")\n",
    "for i, (state, f1) in enumerate(state_f1_scores[-5:], 1):\n",
    "    print(f\"   {i}. {state}: F1-Score = {f1:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n✅ Enhanced Crime Classification Pipeline with Model Saving Completed!\")\n",
    "print(f\"📊 Enhanced Model Summary:\")\n",
    "print(f\"   - Dataset Size: {len(df)} records\")\n",
    "print(f\"   - States/UTs: {len(y.unique())}\")\n",
    "print(f\"   - Best Model: {best_model_name}\")\n",
    "print(f\"   - Best Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
    "print(f\"   - TF-IDF Features: {len(tfidf.vocabulary_)}\")\n",
    "print(f\"   - Crime Features Used: {len(crime_columns)}\")\n",
    "print(f\"   - Model Saved To: {saved_model_dir}\")\n",
    "\n",
    "print(f\"\\n🔧 Key Features Added:\")\n",
    "print(f\"   ✅ Complete model saving with metadata\")\n",
    "print(f\"   ✅ Model loading and prediction class\")\n",
    "print(f\"   ✅ Batch prediction capability\")\n",
    "print(f\"   ✅ Human-readable model information\")\n",
    "print(f\"   ✅ Versioned model storage\")\n",
    "print(f\"   ✅ Error handling for model I/O\")\n",
    "\n",
    "print(f\"\\n📁 Saved Files:\")\n",
    "print(f\"   - model.pkl (trained model)\")\n",
    "print(f\"   - vectorizer.pkl (TF-IDF vectorizer)\")\n",
    "print(f\"   - metadata.pkl (model metadata)\")\n",
    "print(f\"   - model_info.txt (human-readable info)\")\n",
    "\n",
    "print(f\"\\n🚀 To use the saved model later:\")\n",
    "print(f\"   predictor = CrimeClassificationPredictor('{saved_model_dir}')\")\n",
    "print(f\"   prediction = predictor.predict_state_from_crime_pattern('your_crime_text')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
